{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-08 23:28:20.032454: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "import scipy.io\n",
    "from tensorflow.keras import layers\n",
    "import mne\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10_hard.fif\n",
      "Opening raw data file /mnt/Ryans Study/EEG/10_hard.fif...\n",
      "    Range : 0 ... 162499 =      0.000 ...   649.996 secs\n",
      "Ready.\n",
      "Reading 0 ... 162499  =      0.000 ...   649.996 secs...\n",
      "10_normal.fif\n",
      "Opening raw data file /mnt/Ryans Study/EEG/10_normal.fif...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_723/1090050951.py:16: RuntimeWarning: This filename (/mnt/Ryans Study/EEG/10_hard.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  raw = mne.io.read_raw_fif(filepath, preload=True)\n",
      "/tmp/ipykernel_723/1090050951.py:16: RuntimeWarning: This filename (/mnt/Ryans Study/EEG/10_normal.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  raw = mne.io.read_raw_fif(filepath, preload=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Range : 0 ... 162499 =      0.000 ...   649.996 secs\n",
      "Ready.\n",
      "Reading 0 ... 162499  =      0.000 ...   649.996 secs...\n",
      "11_hard.fif\n",
      "Opening raw data file /mnt/Ryans Study/EEG/11_hard.fif...\n",
      "    Range : 0 ... 162499 =      0.000 ...   649.996 secs\n",
      "Ready.\n",
      "Reading 0 ... 162499  =      0.000 ...   649.996 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_723/1090050951.py:16: RuntimeWarning: This filename (/mnt/Ryans Study/EEG/11_hard.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  raw = mne.io.read_raw_fif(filepath, preload=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11_normal.fif\n",
      "Opening raw data file /mnt/Ryans Study/EEG/11_normal.fif...\n",
      "    Range : 0 ... 162499 =      0.000 ...   649.996 secs\n",
      "Ready.\n",
      "Reading 0 ... 162499  =      0.000 ...   649.996 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_723/1090050951.py:16: RuntimeWarning: This filename (/mnt/Ryans Study/EEG/11_normal.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  raw = mne.io.read_raw_fif(filepath, preload=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11_watching.fif\n",
      "Opening raw data file /mnt/Ryans Study/EEG/11_watching.fif...\n",
      "    Range : 0 ... 160999 =      0.000 ...   643.996 secs\n",
      "Ready.\n",
      "Reading 0 ... 160999  =      0.000 ...   643.996 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_723/1090050951.py:16: RuntimeWarning: This filename (/mnt/Ryans Study/EEG/11_watching.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  raw = mne.io.read_raw_fif(filepath, preload=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12_hard.fif\n",
      "Opening raw data file /mnt/Ryans Study/EEG/12_hard.fif...\n",
      "    Range : 0 ... 162499 =      0.000 ...   649.996 secs\n",
      "Ready.\n",
      "Reading 0 ... 162499  =      0.000 ...   649.996 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_723/1090050951.py:16: RuntimeWarning: This filename (/mnt/Ryans Study/EEG/12_hard.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  raw = mne.io.read_raw_fif(filepath, preload=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12_normal.fif\n",
      "Opening raw data file /mnt/Ryans Study/EEG/12_normal.fif...\n",
      "    Range : 0 ... 157749 =      0.000 ...   630.996 secs\n",
      "Ready.\n",
      "Reading 0 ... 157749  =      0.000 ...   630.996 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_723/1090050951.py:16: RuntimeWarning: This filename (/mnt/Ryans Study/EEG/12_normal.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  raw = mne.io.read_raw_fif(filepath, preload=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12_watching.fif\n",
      "Opening raw data file /mnt/Ryans Study/EEG/12_watching.fif...\n",
      "    Range : 0 ... 160499 =      0.000 ...   641.996 secs\n",
      "Ready.\n",
      "Reading 0 ... 160499  =      0.000 ...   641.996 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_723/1090050951.py:16: RuntimeWarning: This filename (/mnt/Ryans Study/EEG/12_watching.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  raw = mne.io.read_raw_fif(filepath, preload=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13_hard.fif\n",
      "Opening raw data file /mnt/Ryans Study/EEG/13_hard.fif...\n",
      "    Range : 0 ... 162499 =      0.000 ...   649.996 secs\n",
      "Ready.\n",
      "Reading 0 ... 162499  =      0.000 ...   649.996 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_723/1090050951.py:16: RuntimeWarning: This filename (/mnt/Ryans Study/EEG/13_hard.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  raw = mne.io.read_raw_fif(filepath, preload=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13_normal.fif\n",
      "Opening raw data file /mnt/Ryans Study/EEG/13_normal.fif...\n",
      "    Range : 0 ... 151749 =      0.000 ...   606.996 secs\n",
      "Ready.\n",
      "Reading 0 ... 151749  =      0.000 ...   606.996 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_723/1090050951.py:16: RuntimeWarning: This filename (/mnt/Ryans Study/EEG/13_normal.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  raw = mne.io.read_raw_fif(filepath, preload=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13_watching.fif\n",
      "Opening raw data file /mnt/Ryans Study/EEG/13_watching.fif...\n",
      "    Range : 0 ... 158999 =      0.000 ...   635.996 secs\n",
      "Ready.\n",
      "Reading 0 ... 158999  =      0.000 ...   635.996 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_723/1090050951.py:16: RuntimeWarning: This filename (/mnt/Ryans Study/EEG/13_watching.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  raw = mne.io.read_raw_fif(filepath, preload=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14_hard.fif\n",
      "Opening raw data file /mnt/Ryans Study/EEG/14_hard.fif...\n",
      "    Range : 0 ... 162499 =      0.000 ...   649.996 secs\n",
      "Ready.\n",
      "Reading 0 ... 162499  =      0.000 ...   649.996 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_723/1090050951.py:16: RuntimeWarning: This filename (/mnt/Ryans Study/EEG/14_hard.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  raw = mne.io.read_raw_fif(filepath, preload=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14_normal.fif\n",
      "Opening raw data file /mnt/Ryans Study/EEG/14_normal.fif...\n",
      "    Range : 0 ... 162499 =      0.000 ...   649.996 secs\n",
      "Ready.\n",
      "Reading 0 ... 162499  =      0.000 ...   649.996 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_723/1090050951.py:16: RuntimeWarning: This filename (/mnt/Ryans Study/EEG/14_normal.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  raw = mne.io.read_raw_fif(filepath, preload=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14_watching.fif\n",
      "Opening raw data file /mnt/Ryans Study/EEG/14_watching.fif...\n",
      "    Range : 0 ... 119499 =      0.000 ...   477.996 secs\n",
      "Ready.\n",
      "Reading 0 ... 119499  =      0.000 ...   477.996 secs...\n",
      "6_watch.fif\n",
      "Opening raw data file /mnt/Ryans Study/EEG/6_watch.fif...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_723/1090050951.py:16: RuntimeWarning: This filename (/mnt/Ryans Study/EEG/14_watching.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  raw = mne.io.read_raw_fif(filepath, preload=True)\n",
      "/tmp/ipykernel_723/1090050951.py:16: RuntimeWarning: This filename (/mnt/Ryans Study/EEG/6_watch.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  raw = mne.io.read_raw_fif(filepath, preload=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Range : 0 ... 156249 =      0.000 ...   624.996 secs\n",
      "Ready.\n",
      "Reading 0 ... 156249  =      0.000 ...   624.996 secs...\n",
      "15_hard.fif\n",
      "Opening raw data file /mnt/Ryans Study/EEG/15_hard.fif...\n",
      "    Range : 0 ... 162499 =      0.000 ...   649.996 secs\n",
      "Ready.\n",
      "Reading 0 ... 162499  =      0.000 ...   649.996 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_723/1090050951.py:16: RuntimeWarning: This filename (/mnt/Ryans Study/EEG/15_hard.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  raw = mne.io.read_raw_fif(filepath, preload=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15_normal.fif\n",
      "Opening raw data file /mnt/Ryans Study/EEG/15_normal.fif...\n",
      "    Range : 0 ... 162499 =      0.000 ...   649.996 secs\n",
      "Ready.\n",
      "Reading 0 ... 162499  =      0.000 ...   649.996 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_723/1090050951.py:16: RuntimeWarning: This filename (/mnt/Ryans Study/EEG/15_normal.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  raw = mne.io.read_raw_fif(filepath, preload=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15_watching.fif\n",
      "Opening raw data file /mnt/Ryans Study/EEG/15_watching.fif...\n",
      "    Range : 0 ... 158249 =      0.000 ...   632.996 secs\n",
      "Ready.\n",
      "Reading 0 ... 158249  =      0.000 ...   632.996 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_723/1090050951.py:16: RuntimeWarning: This filename (/mnt/Ryans Study/EEG/15_watching.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  raw = mne.io.read_raw_fif(filepath, preload=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16_hard.fif\n",
      "Opening raw data file /mnt/Ryans Study/EEG/16_hard.fif...\n",
      "    Range : 0 ... 162499 =      0.000 ...   649.996 secs\n",
      "Ready.\n",
      "Reading 0 ... 162499  =      0.000 ...   649.996 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_723/1090050951.py:16: RuntimeWarning: This filename (/mnt/Ryans Study/EEG/16_hard.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  raw = mne.io.read_raw_fif(filepath, preload=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7_normal.fif\n",
      "Opening raw data file /mnt/Ryans Study/EEG/7_normal.fif...\n",
      "    Range : 0 ... 162499 =      0.000 ...   649.996 secs\n",
      "Ready.\n",
      "Reading 0 ... 162499  =      0.000 ...   649.996 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_723/1090050951.py:16: RuntimeWarning: This filename (/mnt/Ryans Study/EEG/7_normal.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  raw = mne.io.read_raw_fif(filepath, preload=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7_watch.fif\n",
      "Opening raw data file /mnt/Ryans Study/EEG/7_watch.fif...\n",
      "    Range : 0 ... 155999 =      0.000 ...   623.996 secs\n",
      "Ready.\n",
      "Reading 0 ... 155999  =      0.000 ...   623.996 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_723/1090050951.py:16: RuntimeWarning: This filename (/mnt/Ryans Study/EEG/7_watch.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  raw = mne.io.read_raw_fif(filepath, preload=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16_normal.fif\n",
      "Opening raw data file /mnt/Ryans Study/EEG/16_normal.fif...\n",
      "    Range : 0 ... 162499 =      0.000 ...   649.996 secs\n",
      "Ready.\n",
      "Reading 0 ... 162499  =      0.000 ...   649.996 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_723/1090050951.py:16: RuntimeWarning: This filename (/mnt/Ryans Study/EEG/16_normal.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  raw = mne.io.read_raw_fif(filepath, preload=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16_watching.fif\n",
      "Opening raw data file /mnt/Ryans Study/EEG/16_watching.fif...\n",
      "    Range : 0 ... 161999 =      0.000 ...   647.996 secs\n",
      "Ready.\n",
      "Reading 0 ... 161999  =      0.000 ...   647.996 secs...\n",
      "17_hard.fif\n",
      "Opening raw data file /mnt/Ryans Study/EEG/17_hard.fif...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_723/1090050951.py:16: RuntimeWarning: This filename (/mnt/Ryans Study/EEG/16_watching.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  raw = mne.io.read_raw_fif(filepath, preload=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Range : 0 ... 162499 =      0.000 ...   649.996 secs\n",
      "Ready.\n",
      "Reading 0 ... 162499  =      0.000 ...   649.996 secs...\n",
      "9_watch.fif\n",
      "Opening raw data file /mnt/Ryans Study/EEG/9_watch.fif...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_723/1090050951.py:16: RuntimeWarning: This filename (/mnt/Ryans Study/EEG/17_hard.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  raw = mne.io.read_raw_fif(filepath, preload=True)\n",
      "/tmp/ipykernel_723/1090050951.py:16: RuntimeWarning: This filename (/mnt/Ryans Study/EEG/9_watch.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  raw = mne.io.read_raw_fif(filepath, preload=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Range : 0 ... 156249 =      0.000 ...   624.996 secs\n",
      "Ready.\n",
      "Reading 0 ... 156249  =      0.000 ...   624.996 secs...\n",
      "10_watching.fif\n",
      "Opening raw data file /mnt/Ryans Study/EEG/10_watching.fif...\n",
      "    Range : 0 ... 154749 =      0.000 ...   618.996 secs\n",
      "Ready.\n",
      "Reading 0 ... 154749  =      0.000 ...   618.996 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_723/1090050951.py:16: RuntimeWarning: This filename (/mnt/Ryans Study/EEG/10_watching.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  raw = mne.io.read_raw_fif(filepath, preload=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17_normal.fif\n",
      "Opening raw data file /mnt/Ryans Study/EEG/17_normal.fif...\n",
      "    Range : 0 ... 162499 =      0.000 ...   649.996 secs\n",
      "Ready.\n",
      "Reading 0 ... 162499  =      0.000 ...   649.996 secs...\n",
      "1_hard.fif\n",
      "Opening raw data file /mnt/Ryans Study/EEG/1_hard.fif...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_723/1090050951.py:16: RuntimeWarning: This filename (/mnt/Ryans Study/EEG/17_normal.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  raw = mne.io.read_raw_fif(filepath, preload=True)\n",
      "/tmp/ipykernel_723/1090050951.py:16: RuntimeWarning: This filename (/mnt/Ryans Study/EEG/1_hard.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  raw = mne.io.read_raw_fif(filepath, preload=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Range : 0 ... 162499 =      0.000 ...   649.996 secs\n",
      "Ready.\n",
      "Reading 0 ... 162499  =      0.000 ...   649.996 secs...\n",
      "17_watching.fif\n",
      "Opening raw data file /mnt/Ryans Study/EEG/17_watching.fif...\n",
      "    Range : 0 ... 157249 =      0.000 ...   628.996 secs\n",
      "Ready.\n",
      "Reading 0 ... 157249  =      0.000 ...   628.996 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_723/1090050951.py:16: RuntimeWarning: This filename (/mnt/Ryans Study/EEG/17_watching.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  raw = mne.io.read_raw_fif(filepath, preload=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18_hard.fif\n",
      "Opening raw data file /mnt/Ryans Study/EEG/18_hard.fif...\n",
      "    Range : 0 ... 162499 =      0.000 ...   649.996 secs\n",
      "Ready.\n",
      "Reading 0 ... 162499  =      0.000 ...   649.996 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_723/1090050951.py:16: RuntimeWarning: This filename (/mnt/Ryans Study/EEG/18_hard.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  raw = mne.io.read_raw_fif(filepath, preload=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1_normal.fif\n",
      "Opening raw data file /mnt/Ryans Study/EEG/1_normal.fif...\n",
      "    Range : 0 ... 161249 =      0.000 ...   644.996 secs\n",
      "Ready.\n",
      "Reading 0 ... 161249  =      0.000 ...   644.996 secs...\n",
      "18_normal.fif\n",
      "Opening raw data file /mnt/Ryans Study/EEG/18_normal.fif...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_723/1090050951.py:16: RuntimeWarning: This filename (/mnt/Ryans Study/EEG/1_normal.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  raw = mne.io.read_raw_fif(filepath, preload=True)\n",
      "/tmp/ipykernel_723/1090050951.py:16: RuntimeWarning: This filename (/mnt/Ryans Study/EEG/18_normal.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  raw = mne.io.read_raw_fif(filepath, preload=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Range : 0 ... 162499 =      0.000 ...   649.996 secs\n",
      "Ready.\n",
      "Reading 0 ... 162499  =      0.000 ...   649.996 secs...\n",
      "18_watching.fif\n",
      "Opening raw data file /mnt/Ryans Study/EEG/18_watching.fif...\n",
      "    Range : 0 ... 154249 =      0.000 ...   616.996 secs\n",
      "Ready.\n",
      "Reading 0 ... 154249  =      0.000 ...   616.996 secs...\n",
      "1_watch.fif\n",
      "Opening raw data file /mnt/Ryans Study/EEG/1_watch.fif...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_723/1090050951.py:16: RuntimeWarning: This filename (/mnt/Ryans Study/EEG/18_watching.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  raw = mne.io.read_raw_fif(filepath, preload=True)\n",
      "/tmp/ipykernel_723/1090050951.py:16: RuntimeWarning: This filename (/mnt/Ryans Study/EEG/1_watch.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  raw = mne.io.read_raw_fif(filepath, preload=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Range : 0 ... 148999 =      0.000 ...   595.996 secs\n",
      "Ready.\n",
      "Reading 0 ... 148999  =      0.000 ...   595.996 secs...\n",
      "2_hard.fif\n",
      "Opening raw data file /mnt/Ryans Study/EEG/2_hard.fif...\n",
      "    Range : 0 ... 172499 =      0.000 ...   689.996 secs\n",
      "Ready.\n",
      "Reading 0 ... 172499  =      0.000 ...   689.996 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_723/1090050951.py:16: RuntimeWarning: This filename (/mnt/Ryans Study/EEG/2_hard.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  raw = mne.io.read_raw_fif(filepath, preload=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2_normal.fif\n",
      "Opening raw data file /mnt/Ryans Study/EEG/2_normal.fif...\n",
      "    Range : 0 ... 162499 =      0.000 ...   649.996 secs\n",
      "Ready.\n",
      "Reading 0 ... 162499  =      0.000 ...   649.996 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_723/1090050951.py:16: RuntimeWarning: This filename (/mnt/Ryans Study/EEG/2_normal.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  raw = mne.io.read_raw_fif(filepath, preload=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2_watch.fif\n",
      "Opening raw data file /mnt/Ryans Study/EEG/2_watch.fif...\n",
      "    Range : 0 ... 162499 =      0.000 ...   649.996 secs\n",
      "Ready.\n",
      "Reading 0 ... 162499  =      0.000 ...   649.996 secs...\n",
      "3_hard.fif\n",
      "Opening raw data file /mnt/Ryans Study/EEG/3_hard.fif...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_723/1090050951.py:16: RuntimeWarning: This filename (/mnt/Ryans Study/EEG/2_watch.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  raw = mne.io.read_raw_fif(filepath, preload=True)\n",
      "/tmp/ipykernel_723/1090050951.py:16: RuntimeWarning: This filename (/mnt/Ryans Study/EEG/3_hard.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  raw = mne.io.read_raw_fif(filepath, preload=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Range : 0 ... 162499 =      0.000 ...   649.996 secs\n",
      "Ready.\n",
      "Reading 0 ... 162499  =      0.000 ...   649.996 secs...\n",
      "3_normal.fif\n",
      "Opening raw data file /mnt/Ryans Study/EEG/3_normal.fif...\n",
      "    Range : 0 ... 162499 =      0.000 ...   649.996 secs\n",
      "Ready.\n",
      "Reading 0 ... 162499  =      0.000 ...   649.996 secs...\n",
      "3_watch.fif\n",
      "Opening raw data file /mnt/Ryans Study/EEG/3_watch.fif...\n",
      "    Range : 0 ... 155749 =      0.000 ...   622.996 secs\n",
      "Ready.\n",
      "Reading 0 ... 155749  =      0.000 ...   622.996 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_723/1090050951.py:16: RuntimeWarning: This filename (/mnt/Ryans Study/EEG/3_normal.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  raw = mne.io.read_raw_fif(filepath, preload=True)\n",
      "/tmp/ipykernel_723/1090050951.py:16: RuntimeWarning: This filename (/mnt/Ryans Study/EEG/3_watch.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  raw = mne.io.read_raw_fif(filepath, preload=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4_hard.fif\n",
      "Opening raw data file /mnt/Ryans Study/EEG/4_hard.fif...\n",
      "    Range : 0 ... 162499 =      0.000 ...   649.996 secs\n",
      "Ready.\n",
      "Reading 0 ... 162499  =      0.000 ...   649.996 secs...\n",
      "4_normal.fif\n",
      "Opening raw data file /mnt/Ryans Study/EEG/4_normal.fif...\n",
      "    Range : 0 ... 162499 =      0.000 ...   649.996 secs\n",
      "Ready.\n",
      "Reading 0 ... 162499  =      0.000 ...   649.996 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_723/1090050951.py:16: RuntimeWarning: This filename (/mnt/Ryans Study/EEG/4_hard.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  raw = mne.io.read_raw_fif(filepath, preload=True)\n",
      "/tmp/ipykernel_723/1090050951.py:16: RuntimeWarning: This filename (/mnt/Ryans Study/EEG/4_normal.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  raw = mne.io.read_raw_fif(filepath, preload=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4_watch.fif\n",
      "Opening raw data file /mnt/Ryans Study/EEG/4_watch.fif...\n",
      "    Range : 0 ... 159249 =      0.000 ...   636.996 secs\n",
      "Ready.\n",
      "Reading 0 ... 159249  =      0.000 ...   636.996 secs...\n",
      "5_hard.fif\n",
      "Opening raw data file /mnt/Ryans Study/EEG/5_hard.fif...\n",
      "    Range : 0 ... 152499 =      0.000 ...   609.996 secs\n",
      "Ready.\n",
      "Reading 0 ... 152499  =      0.000 ...   609.996 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_723/1090050951.py:16: RuntimeWarning: This filename (/mnt/Ryans Study/EEG/4_watch.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  raw = mne.io.read_raw_fif(filepath, preload=True)\n",
      "/tmp/ipykernel_723/1090050951.py:16: RuntimeWarning: This filename (/mnt/Ryans Study/EEG/5_hard.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  raw = mne.io.read_raw_fif(filepath, preload=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5_normal.fif\n",
      "Opening raw data file /mnt/Ryans Study/EEG/5_normal.fif...\n",
      "    Range : 0 ... 162499 =      0.000 ...   649.996 secs\n",
      "Ready.\n",
      "Reading 0 ... 162499  =      0.000 ...   649.996 secs...\n",
      "5_watch.fif\n",
      "Opening raw data file /mnt/Ryans Study/EEG/5_watch.fif...\n",
      "    Range : 0 ... 155749 =      0.000 ...   622.996 secs\n",
      "Ready.\n",
      "Reading 0 ... 155749  =      0.000 ...   622.996 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_723/1090050951.py:16: RuntimeWarning: This filename (/mnt/Ryans Study/EEG/5_normal.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  raw = mne.io.read_raw_fif(filepath, preload=True)\n",
      "/tmp/ipykernel_723/1090050951.py:16: RuntimeWarning: This filename (/mnt/Ryans Study/EEG/5_watch.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  raw = mne.io.read_raw_fif(filepath, preload=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6_hard.fif\n",
      "Opening raw data file /mnt/Ryans Study/EEG/6_hard.fif...\n",
      "    Range : 0 ... 162499 =      0.000 ...   649.996 secs\n",
      "Ready.\n",
      "Reading 0 ... 162499  =      0.000 ...   649.996 secs...\n",
      "6_normal.fif\n",
      "Opening raw data file /mnt/Ryans Study/EEG/6_normal.fif...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_723/1090050951.py:16: RuntimeWarning: This filename (/mnt/Ryans Study/EEG/6_hard.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  raw = mne.io.read_raw_fif(filepath, preload=True)\n",
      "/tmp/ipykernel_723/1090050951.py:16: RuntimeWarning: This filename (/mnt/Ryans Study/EEG/6_normal.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  raw = mne.io.read_raw_fif(filepath, preload=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Range : 0 ... 162499 =      0.000 ...   649.996 secs\n",
      "Ready.\n",
      "Reading 0 ... 162499  =      0.000 ...   649.996 secs...\n",
      "7_hard.fif\n",
      "Opening raw data file /mnt/Ryans Study/EEG/7_hard.fif...\n",
      "    Range : 0 ... 162499 =      0.000 ...   649.996 secs\n",
      "Ready.\n",
      "Reading 0 ... 162499  =      0.000 ...   649.996 secs...\n",
      "8_hard.fif\n",
      "Opening raw data file /mnt/Ryans Study/EEG/8_hard.fif...\n",
      "    Range : 0 ... 162499 =      0.000 ...   649.996 secs\n",
      "Ready.\n",
      "Reading 0 ... 162499  =      0.000 ...   649.996 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_723/1090050951.py:16: RuntimeWarning: This filename (/mnt/Ryans Study/EEG/7_hard.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  raw = mne.io.read_raw_fif(filepath, preload=True)\n",
      "/tmp/ipykernel_723/1090050951.py:16: RuntimeWarning: This filename (/mnt/Ryans Study/EEG/8_hard.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  raw = mne.io.read_raw_fif(filepath, preload=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8_normal.fif\n",
      "Opening raw data file /mnt/Ryans Study/EEG/8_normal.fif...\n",
      "    Range : 0 ... 162499 =      0.000 ...   649.996 secs\n",
      "Ready.\n",
      "Reading 0 ... 162499  =      0.000 ...   649.996 secs...\n",
      "8_watch.fif\n",
      "Opening raw data file /mnt/Ryans Study/EEG/8_watch.fif...\n",
      "    Range : 0 ... 157999 =      0.000 ...   631.996 secs\n",
      "Ready.\n",
      "Reading 0 ... 157999  =      0.000 ...   631.996 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_723/1090050951.py:16: RuntimeWarning: This filename (/mnt/Ryans Study/EEG/8_normal.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  raw = mne.io.read_raw_fif(filepath, preload=True)\n",
      "/tmp/ipykernel_723/1090050951.py:16: RuntimeWarning: This filename (/mnt/Ryans Study/EEG/8_watch.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  raw = mne.io.read_raw_fif(filepath, preload=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9_correct.fif\n",
      "Opening raw data file /mnt/Ryans Study/EEG/9_correct.fif...\n",
      "    Range : 0 ... 162499 =      0.000 ...   649.996 secs\n",
      "Ready.\n",
      "Reading 0 ... 162499  =      0.000 ...   649.996 secs...\n",
      "9_hard.fif\n",
      "Opening raw data file /mnt/Ryans Study/EEG/9_hard.fif...\n",
      "    Range : 0 ... 162499 =      0.000 ...   649.996 secs\n",
      "Ready.\n",
      "Reading 0 ... 162499  =      0.000 ...   649.996 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_723/1090050951.py:16: RuntimeWarning: This filename (/mnt/Ryans Study/EEG/9_correct.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  raw = mne.io.read_raw_fif(filepath, preload=True)\n",
      "/tmp/ipykernel_723/1090050951.py:16: RuntimeWarning: This filename (/mnt/Ryans Study/EEG/9_hard.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  raw = mne.io.read_raw_fif(filepath, preload=True)\n",
      "2023-04-08 23:28:58.406339: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-04-08 23:28:58.410612: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-04-08 23:28:58.410797: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-04-08 23:28:58.411893: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-04-08 23:28:58.412042: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-04-08 23:28:58.412165: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-04-08 23:29:03.715399: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-04-08 23:29:03.715582: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-04-08 23:29:03.715716: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-04-08 23:29:03.715828: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15358 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:04:00.0, compute capability: 6.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-08 23:29:06.173822: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape insequential/dropout/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n",
      "2023-04-08 23:29:13.877353: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8600\n",
      "2023-04-08 23:29:21.301186: I tensorflow/compiler/xla/service/service.cc:169] XLA service 0x150ce001f960 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-04-08 23:29:21.301212: I tensorflow/compiler/xla/service/service.cc:177]   StreamExecutor device (0): Tesla P100-PCIE-16GB, Compute Capability 6.0\n",
      "2023-04-08 23:29:21.667277: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2023-04-08 23:29:22.511769: I ./tensorflow/compiler/jit/device_compiler.h:180] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.2244 - accuracy: 0.3850\n",
      "Epoch 1: val_accuracy improved from -inf to 0.36800, saving model to best_model_CNNLSTM.h5\n",
      "10/10 [==============================] - 21s 118ms/step - loss: 0.2244 - accuracy: 0.3859 - val_loss: 0.2221 - val_accuracy: 0.3680\n",
      "Epoch 2/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.2115 - accuracy: 0.4536\n",
      "Epoch 2: val_accuracy improved from 0.36800 to 0.37600, saving model to best_model_CNNLSTM.h5\n",
      "10/10 [==============================] - 1s 54ms/step - loss: 0.2113 - accuracy: 0.4542 - val_loss: 0.2220 - val_accuracy: 0.3760\n",
      "Epoch 3/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.2077 - accuracy: 0.4510\n",
      "Epoch 3: val_accuracy did not improve from 0.37600\n",
      "10/10 [==============================] - 1s 52ms/step - loss: 0.2076 - accuracy: 0.4504 - val_loss: 0.2223 - val_accuracy: 0.3520\n",
      "Epoch 4/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.2066 - accuracy: 0.4735\n",
      "Epoch 4: val_accuracy did not improve from 0.37600\n",
      "10/10 [==============================] - 1s 51ms/step - loss: 0.2066 - accuracy: 0.4731 - val_loss: 0.2223 - val_accuracy: 0.2960\n",
      "Epoch 5/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.2026 - accuracy: 0.5009\n",
      "Epoch 5: val_accuracy did not improve from 0.37600\n",
      "10/10 [==============================] - 0s 48ms/step - loss: 0.2026 - accuracy: 0.5011 - val_loss: 0.2233 - val_accuracy: 0.3040\n",
      "Epoch 6/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.2001 - accuracy: 0.5100\n",
      "Epoch 6: val_accuracy did not improve from 0.37600\n",
      "10/10 [==============================] - 0s 49ms/step - loss: 0.2004 - accuracy: 0.5084 - val_loss: 0.2250 - val_accuracy: 0.3040\n",
      "Epoch 7/500\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1961 - accuracy: 0.5329\n",
      "Epoch 7: val_accuracy did not improve from 0.37600\n",
      "10/10 [==============================] - 1s 51ms/step - loss: 0.1961 - accuracy: 0.5329 - val_loss: 0.2268 - val_accuracy: 0.3040\n",
      "Epoch 8/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1931 - accuracy: 0.5490\n",
      "Epoch 8: val_accuracy did not improve from 0.37600\n",
      "10/10 [==============================] - 0s 49ms/step - loss: 0.1930 - accuracy: 0.5496 - val_loss: 0.2279 - val_accuracy: 0.3040\n",
      "Epoch 9/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1886 - accuracy: 0.5564\n",
      "Epoch 9: val_accuracy did not improve from 0.37600\n",
      "10/10 [==============================] - 0s 47ms/step - loss: 0.1886 - accuracy: 0.5561 - val_loss: 0.2280 - val_accuracy: 0.3040\n",
      "Epoch 10/500\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1874 - accuracy: 0.5655\n",
      "Epoch 10: val_accuracy did not improve from 0.37600\n",
      "10/10 [==============================] - 0s 49ms/step - loss: 0.1874 - accuracy: 0.5655 - val_loss: 0.2279 - val_accuracy: 0.3040\n",
      "Epoch 11/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1863 - accuracy: 0.5595\n",
      "Epoch 11: val_accuracy did not improve from 0.37600\n",
      "10/10 [==============================] - 0s 50ms/step - loss: 0.1860 - accuracy: 0.5599 - val_loss: 0.2273 - val_accuracy: 0.3040\n",
      "Epoch 12/500\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1883 - accuracy: 0.5608\n",
      "Epoch 12: val_accuracy did not improve from 0.37600\n",
      "10/10 [==============================] - 1s 51ms/step - loss: 0.1883 - accuracy: 0.5608 - val_loss: 0.2312 - val_accuracy: 0.3040\n",
      "Epoch 13/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1849 - accuracy: 0.5668\n",
      "Epoch 13: val_accuracy did not improve from 0.37600\n",
      "10/10 [==============================] - 1s 50ms/step - loss: 0.1851 - accuracy: 0.5655 - val_loss: 0.2311 - val_accuracy: 0.2960\n",
      "Epoch 14/500\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1872 - accuracy: 0.5518\n",
      "Epoch 14: val_accuracy did not improve from 0.37600\n",
      "10/10 [==============================] - 0s 50ms/step - loss: 0.1872 - accuracy: 0.5518 - val_loss: 0.2304 - val_accuracy: 0.2800\n",
      "Epoch 15/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1836 - accuracy: 0.5790\n",
      "Epoch 15: val_accuracy did not improve from 0.37600\n",
      "10/10 [==============================] - 1s 50ms/step - loss: 0.1838 - accuracy: 0.5793 - val_loss: 0.2265 - val_accuracy: 0.3360\n",
      "Epoch 16/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1839 - accuracy: 0.5673\n",
      "Epoch 16: val_accuracy did not improve from 0.37600\n",
      "10/10 [==============================] - 0s 49ms/step - loss: 0.1839 - accuracy: 0.5677 - val_loss: 0.2254 - val_accuracy: 0.3440\n",
      "Epoch 17/500\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1839 - accuracy: 0.5655\n",
      "Epoch 17: val_accuracy did not improve from 0.37600\n",
      "10/10 [==============================] - 0s 47ms/step - loss: 0.1839 - accuracy: 0.5655 - val_loss: 0.2284 - val_accuracy: 0.3520\n",
      "Epoch 18/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1837 - accuracy: 0.5777\n",
      "Epoch 18: val_accuracy did not improve from 0.37600\n",
      "10/10 [==============================] - 0s 47ms/step - loss: 0.1835 - accuracy: 0.5789 - val_loss: 0.2282 - val_accuracy: 0.3280\n",
      "Epoch 19/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1806 - accuracy: 0.5838\n",
      "Epoch 19: val_accuracy did not improve from 0.37600\n",
      "10/10 [==============================] - 1s 52ms/step - loss: 0.1804 - accuracy: 0.5844 - val_loss: 0.2289 - val_accuracy: 0.3440\n",
      "Epoch 20/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1828 - accuracy: 0.5690\n",
      "Epoch 20: val_accuracy did not improve from 0.37600\n",
      "10/10 [==============================] - 1s 51ms/step - loss: 0.1825 - accuracy: 0.5698 - val_loss: 0.2271 - val_accuracy: 0.3600\n",
      "Epoch 21/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1823 - accuracy: 0.5716\n",
      "Epoch 21: val_accuracy did not improve from 0.37600\n",
      "10/10 [==============================] - 1s 51ms/step - loss: 0.1822 - accuracy: 0.5707 - val_loss: 0.2230 - val_accuracy: 0.3520\n",
      "Epoch 22/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1842 - accuracy: 0.5573\n",
      "Epoch 22: val_accuracy improved from 0.37600 to 0.40000, saving model to best_model_CNNLSTM.h5\n",
      "10/10 [==============================] - 1s 54ms/step - loss: 0.1844 - accuracy: 0.5569 - val_loss: 0.2219 - val_accuracy: 0.4000\n",
      "Epoch 23/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1858 - accuracy: 0.5538\n",
      "Epoch 23: val_accuracy did not improve from 0.40000\n",
      "10/10 [==============================] - 0s 50ms/step - loss: 0.1864 - accuracy: 0.5518 - val_loss: 0.2243 - val_accuracy: 0.3760\n",
      "Epoch 24/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1834 - accuracy: 0.5612\n",
      "Epoch 24: val_accuracy did not improve from 0.40000\n",
      "10/10 [==============================] - 1s 51ms/step - loss: 0.1837 - accuracy: 0.5595 - val_loss: 0.2225 - val_accuracy: 0.3600\n",
      "Epoch 25/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1808 - accuracy: 0.5816\n",
      "Epoch 25: val_accuracy did not improve from 0.40000\n",
      "10/10 [==============================] - 0s 47ms/step - loss: 0.1809 - accuracy: 0.5806 - val_loss: 0.2265 - val_accuracy: 0.3200\n",
      "Epoch 26/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1813 - accuracy: 0.5851\n",
      "Epoch 26: val_accuracy did not improve from 0.40000\n",
      "10/10 [==============================] - 0s 50ms/step - loss: 0.1813 - accuracy: 0.5840 - val_loss: 0.2248 - val_accuracy: 0.3120\n",
      "Epoch 27/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1805 - accuracy: 0.5833\n",
      "Epoch 27: val_accuracy did not improve from 0.40000\n",
      "10/10 [==============================] - 1s 50ms/step - loss: 0.1808 - accuracy: 0.5819 - val_loss: 0.2269 - val_accuracy: 0.3280\n",
      "Epoch 28/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1777 - accuracy: 0.5929\n",
      "Epoch 28: val_accuracy did not improve from 0.40000\n",
      "10/10 [==============================] - 1s 50ms/step - loss: 0.1779 - accuracy: 0.5917 - val_loss: 0.2249 - val_accuracy: 0.3200\n",
      "Epoch 29/500\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1797 - accuracy: 0.5767\n",
      "Epoch 29: val_accuracy did not improve from 0.40000\n",
      "10/10 [==============================] - 1s 50ms/step - loss: 0.1797 - accuracy: 0.5767 - val_loss: 0.2276 - val_accuracy: 0.3360\n",
      "Epoch 30/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1795 - accuracy: 0.5916\n",
      "Epoch 30: val_accuracy did not improve from 0.40000\n",
      "10/10 [==============================] - 0s 49ms/step - loss: 0.1791 - accuracy: 0.5930 - val_loss: 0.2279 - val_accuracy: 0.3440\n",
      "Epoch 31/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1781 - accuracy: 0.5877\n",
      "Epoch 31: val_accuracy did not improve from 0.40000\n",
      "10/10 [==============================] - 0s 49ms/step - loss: 0.1784 - accuracy: 0.5862 - val_loss: 0.2265 - val_accuracy: 0.3040\n",
      "Epoch 32/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1808 - accuracy: 0.5859\n",
      "Epoch 32: val_accuracy did not improve from 0.40000\n",
      "10/10 [==============================] - 1s 50ms/step - loss: 0.1808 - accuracy: 0.5857 - val_loss: 0.2330 - val_accuracy: 0.3440\n",
      "Epoch 33/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1815 - accuracy: 0.5655\n",
      "Epoch 33: val_accuracy did not improve from 0.40000\n",
      "10/10 [==============================] - 1s 52ms/step - loss: 0.1815 - accuracy: 0.5660 - val_loss: 0.2320 - val_accuracy: 0.2640\n",
      "Epoch 34/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1778 - accuracy: 0.5816\n",
      "Epoch 34: val_accuracy did not improve from 0.40000\n",
      "10/10 [==============================] - 1s 50ms/step - loss: 0.1783 - accuracy: 0.5797 - val_loss: 0.2310 - val_accuracy: 0.2720\n",
      "Epoch 35/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1804 - accuracy: 0.5833\n",
      "Epoch 35: val_accuracy did not improve from 0.40000\n",
      "10/10 [==============================] - 1s 52ms/step - loss: 0.1809 - accuracy: 0.5814 - val_loss: 0.2320 - val_accuracy: 0.3200\n",
      "Epoch 36/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1799 - accuracy: 0.5820\n",
      "Epoch 36: val_accuracy did not improve from 0.40000\n",
      "10/10 [==============================] - 0s 50ms/step - loss: 0.1801 - accuracy: 0.5806 - val_loss: 0.2314 - val_accuracy: 0.2320\n",
      "Epoch 37/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1775 - accuracy: 0.5781\n",
      "Epoch 37: val_accuracy did not improve from 0.40000\n",
      "10/10 [==============================] - 0s 46ms/step - loss: 0.1782 - accuracy: 0.5758 - val_loss: 0.2408 - val_accuracy: 0.2400\n",
      "Epoch 38/500\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1780 - accuracy: 0.5870\n",
      "Epoch 38: val_accuracy did not improve from 0.40000\n",
      "10/10 [==============================] - 1s 51ms/step - loss: 0.1780 - accuracy: 0.5870 - val_loss: 0.2315 - val_accuracy: 0.2640\n",
      "Epoch 39/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1774 - accuracy: 0.5885\n",
      "Epoch 39: val_accuracy did not improve from 0.40000\n",
      "10/10 [==============================] - 1s 50ms/step - loss: 0.1779 - accuracy: 0.5870 - val_loss: 0.2440 - val_accuracy: 0.2960\n",
      "Epoch 40/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1787 - accuracy: 0.5734\n",
      "Epoch 40: val_accuracy did not improve from 0.40000\n",
      "10/10 [==============================] - 0s 49ms/step - loss: 0.1791 - accuracy: 0.5728 - val_loss: 0.2428 - val_accuracy: 0.2480\n",
      "Epoch 41/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1767 - accuracy: 0.5738\n",
      "Epoch 41: val_accuracy did not improve from 0.40000\n",
      "10/10 [==============================] - 1s 51ms/step - loss: 0.1771 - accuracy: 0.5733 - val_loss: 0.2520 - val_accuracy: 0.2240\n",
      "Epoch 42/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1775 - accuracy: 0.5807\n",
      "Epoch 42: val_accuracy did not improve from 0.40000\n",
      "10/10 [==============================] - 1s 51ms/step - loss: 0.1774 - accuracy: 0.5810 - val_loss: 0.2491 - val_accuracy: 0.2400\n",
      "Epoch 43/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1784 - accuracy: 0.5781\n",
      "Epoch 43: val_accuracy did not improve from 0.40000\n",
      "10/10 [==============================] - 0s 49ms/step - loss: 0.1784 - accuracy: 0.5780 - val_loss: 0.2472 - val_accuracy: 0.2400\n",
      "Epoch 44/500\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1767 - accuracy: 0.5853\n",
      "Epoch 44: val_accuracy did not improve from 0.40000\n",
      "10/10 [==============================] - 1s 50ms/step - loss: 0.1767 - accuracy: 0.5853 - val_loss: 0.2450 - val_accuracy: 0.2240\n",
      "Epoch 45/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1774 - accuracy: 0.5812\n",
      "Epoch 45: val_accuracy did not improve from 0.40000\n",
      "10/10 [==============================] - 1s 51ms/step - loss: 0.1775 - accuracy: 0.5806 - val_loss: 0.2531 - val_accuracy: 0.2480\n",
      "Epoch 46/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1791 - accuracy: 0.5729\n",
      "Epoch 46: val_accuracy did not improve from 0.40000\n",
      "10/10 [==============================] - 1s 50ms/step - loss: 0.1790 - accuracy: 0.5746 - val_loss: 0.2479 - val_accuracy: 0.2320\n",
      "Epoch 47/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1765 - accuracy: 0.5977\n",
      "Epoch 47: val_accuracy did not improve from 0.40000\n",
      "10/10 [==============================] - 1s 50ms/step - loss: 0.1765 - accuracy: 0.5969 - val_loss: 0.2503 - val_accuracy: 0.2560\n",
      "Epoch 48/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1773 - accuracy: 0.5881\n",
      "Epoch 48: val_accuracy did not improve from 0.40000\n",
      "10/10 [==============================] - 1s 51ms/step - loss: 0.1768 - accuracy: 0.5896 - val_loss: 0.2555 - val_accuracy: 0.2400\n",
      "Epoch 49/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1777 - accuracy: 0.5777\n",
      "Epoch 49: val_accuracy did not improve from 0.40000\n",
      "10/10 [==============================] - 0s 50ms/step - loss: 0.1775 - accuracy: 0.5776 - val_loss: 0.2567 - val_accuracy: 0.2400\n",
      "Epoch 50/500\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1760 - accuracy: 0.5875\n",
      "Epoch 50: val_accuracy did not improve from 0.40000\n",
      "10/10 [==============================] - 0s 48ms/step - loss: 0.1760 - accuracy: 0.5875 - val_loss: 0.2570 - val_accuracy: 0.3040\n",
      "Epoch 51/500\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1806 - accuracy: 0.5716\n",
      "Epoch 51: val_accuracy did not improve from 0.40000\n",
      "10/10 [==============================] - 0s 48ms/step - loss: 0.1806 - accuracy: 0.5716 - val_loss: 0.2595 - val_accuracy: 0.2640\n",
      "Epoch 52/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1773 - accuracy: 0.5755\n",
      "Epoch 52: val_accuracy did not improve from 0.40000\n",
      "10/10 [==============================] - 0s 46ms/step - loss: 0.1775 - accuracy: 0.5746 - val_loss: 0.2670 - val_accuracy: 0.2800\n",
      "Epoch 53/500\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1746 - accuracy: 0.5930\n",
      "Epoch 53: val_accuracy did not improve from 0.40000\n",
      "10/10 [==============================] - 0s 49ms/step - loss: 0.1746 - accuracy: 0.5930 - val_loss: 0.2538 - val_accuracy: 0.2160\n",
      "Epoch 54/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1773 - accuracy: 0.5881\n",
      "Epoch 54: val_accuracy did not improve from 0.40000\n",
      "10/10 [==============================] - 1s 51ms/step - loss: 0.1771 - accuracy: 0.5879 - val_loss: 0.2545 - val_accuracy: 0.2720\n",
      "Epoch 55/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1748 - accuracy: 0.5781\n",
      "Epoch 55: val_accuracy did not improve from 0.40000\n",
      "10/10 [==============================] - 0s 47ms/step - loss: 0.1746 - accuracy: 0.5793 - val_loss: 0.2555 - val_accuracy: 0.2480\n",
      "Epoch 56/500\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1741 - accuracy: 0.5879\n",
      "Epoch 56: val_accuracy did not improve from 0.40000\n",
      "10/10 [==============================] - 0s 46ms/step - loss: 0.1741 - accuracy: 0.5879 - val_loss: 0.2543 - val_accuracy: 0.2720\n",
      "Epoch 57/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1756 - accuracy: 0.5894\n",
      "Epoch 57: val_accuracy did not improve from 0.40000\n",
      "10/10 [==============================] - 0s 50ms/step - loss: 0.1758 - accuracy: 0.5887 - val_loss: 0.2568 - val_accuracy: 0.2560\n",
      "Epoch 58/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1750 - accuracy: 0.5959\n",
      "Epoch 58: val_accuracy did not improve from 0.40000\n",
      "10/10 [==============================] - 1s 50ms/step - loss: 0.1748 - accuracy: 0.5952 - val_loss: 0.2604 - val_accuracy: 0.2400\n",
      "Epoch 59/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1734 - accuracy: 0.5981\n",
      "Epoch 59: val_accuracy did not improve from 0.40000\n",
      "10/10 [==============================] - 0s 50ms/step - loss: 0.1742 - accuracy: 0.5965 - val_loss: 0.2450 - val_accuracy: 0.2720\n",
      "Epoch 60/500\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1726 - accuracy: 0.6025\n",
      "Epoch 60: val_accuracy did not improve from 0.40000\n",
      "10/10 [==============================] - 0s 47ms/step - loss: 0.1726 - accuracy: 0.6025 - val_loss: 0.2501 - val_accuracy: 0.2960\n",
      "Epoch 61/500\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1752 - accuracy: 0.5844\n",
      "Epoch 61: val_accuracy did not improve from 0.40000\n",
      "10/10 [==============================] - 1s 51ms/step - loss: 0.1752 - accuracy: 0.5844 - val_loss: 0.2529 - val_accuracy: 0.2560\n",
      "Epoch 62/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1762 - accuracy: 0.5816\n",
      "Epoch 62: val_accuracy did not improve from 0.40000\n",
      "10/10 [==============================] - 1s 52ms/step - loss: 0.1761 - accuracy: 0.5819 - val_loss: 0.2632 - val_accuracy: 0.2800\n",
      "Epoch 63/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1727 - accuracy: 0.5898\n",
      "Epoch 63: val_accuracy did not improve from 0.40000\n",
      "10/10 [==============================] - 0s 49ms/step - loss: 0.1726 - accuracy: 0.5905 - val_loss: 0.2762 - val_accuracy: 0.3040\n",
      "Epoch 64/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1736 - accuracy: 0.5942\n",
      "Epoch 64: val_accuracy did not improve from 0.40000\n",
      "10/10 [==============================] - 0s 49ms/step - loss: 0.1734 - accuracy: 0.5956 - val_loss: 0.2659 - val_accuracy: 0.3040\n",
      "Epoch 65/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1713 - accuracy: 0.6115\n",
      "Epoch 65: val_accuracy did not improve from 0.40000\n",
      "10/10 [==============================] - 1s 51ms/step - loss: 0.1715 - accuracy: 0.6111 - val_loss: 0.2620 - val_accuracy: 0.2080\n",
      "Epoch 66/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1743 - accuracy: 0.5868\n",
      "Epoch 66: val_accuracy did not improve from 0.40000\n",
      "10/10 [==============================] - 1s 51ms/step - loss: 0.1743 - accuracy: 0.5870 - val_loss: 0.2553 - val_accuracy: 0.2560\n",
      "Epoch 67/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1732 - accuracy: 0.5955\n",
      "Epoch 67: val_accuracy did not improve from 0.40000\n",
      "10/10 [==============================] - 0s 46ms/step - loss: 0.1733 - accuracy: 0.5960 - val_loss: 0.2576 - val_accuracy: 0.2400\n",
      "Epoch 68/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1718 - accuracy: 0.5994\n",
      "Epoch 68: val_accuracy did not improve from 0.40000\n",
      "10/10 [==============================] - 1s 51ms/step - loss: 0.1719 - accuracy: 0.5986 - val_loss: 0.2565 - val_accuracy: 0.2560\n",
      "Epoch 69/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1721 - accuracy: 0.5951\n",
      "Epoch 69: val_accuracy did not improve from 0.40000\n",
      "10/10 [==============================] - 0s 50ms/step - loss: 0.1722 - accuracy: 0.5952 - val_loss: 0.2493 - val_accuracy: 0.2960\n",
      "Epoch 70/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1728 - accuracy: 0.5929\n",
      "Epoch 70: val_accuracy did not improve from 0.40000\n",
      "10/10 [==============================] - 0s 49ms/step - loss: 0.1729 - accuracy: 0.5926 - val_loss: 0.2625 - val_accuracy: 0.2880\n",
      "Epoch 71/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1734 - accuracy: 0.5929\n",
      "Epoch 71: val_accuracy did not improve from 0.40000\n",
      "10/10 [==============================] - 0s 49ms/step - loss: 0.1734 - accuracy: 0.5930 - val_loss: 0.2559 - val_accuracy: 0.3120\n",
      "Epoch 72/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1723 - accuracy: 0.5920\n",
      "Epoch 72: val_accuracy did not improve from 0.40000\n",
      "10/10 [==============================] - 0s 49ms/step - loss: 0.1726 - accuracy: 0.5913 - val_loss: 0.2482 - val_accuracy: 0.2160\n",
      "Epoch 1/500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-08 23:30:02.692879: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape insequential_1/dropout_2/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.2245 - accuracy: 0.3759\n",
      "Epoch 1: val_accuracy improved from -inf to 0.35616, saving model to best_model_CNNLSTM.h5\n",
      "10/10 [==============================] - 2s 68ms/step - loss: 0.2245 - accuracy: 0.3760 - val_loss: 0.2222 - val_accuracy: 0.3562\n",
      "Epoch 2/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.2136 - accuracy: 0.4327\n",
      "Epoch 2: val_accuracy did not improve from 0.35616\n",
      "10/10 [==============================] - 0s 50ms/step - loss: 0.2136 - accuracy: 0.4324 - val_loss: 0.2219 - val_accuracy: 0.3493\n",
      "Epoch 3/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.2115 - accuracy: 0.4462\n",
      "Epoch 3: val_accuracy did not improve from 0.35616\n",
      "10/10 [==============================] - 1s 52ms/step - loss: 0.2116 - accuracy: 0.4458 - val_loss: 0.2220 - val_accuracy: 0.3493\n",
      "Epoch 4/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.2129 - accuracy: 0.4457\n",
      "Epoch 4: val_accuracy did not improve from 0.35616\n",
      "10/10 [==============================] - 1s 51ms/step - loss: 0.2129 - accuracy: 0.4458 - val_loss: 0.2219 - val_accuracy: 0.3493\n",
      "Epoch 5/500\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2100 - accuracy: 0.4527\n",
      "Epoch 5: val_accuracy did not improve from 0.35616\n",
      "10/10 [==============================] - 0s 49ms/step - loss: 0.2100 - accuracy: 0.4527 - val_loss: 0.2220 - val_accuracy: 0.3493\n",
      "Epoch 6/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.2092 - accuracy: 0.4696\n",
      "Epoch 6: val_accuracy did not improve from 0.35616\n",
      "10/10 [==============================] - 1s 50ms/step - loss: 0.2092 - accuracy: 0.4692 - val_loss: 0.2224 - val_accuracy: 0.3493\n",
      "Epoch 7/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.2072 - accuracy: 0.4779\n",
      "Epoch 7: val_accuracy did not improve from 0.35616\n",
      "10/10 [==============================] - 1s 51ms/step - loss: 0.2072 - accuracy: 0.4779 - val_loss: 0.2222 - val_accuracy: 0.3562\n",
      "Epoch 8/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.2073 - accuracy: 0.4644\n",
      "Epoch 8: val_accuracy did not improve from 0.35616\n",
      "10/10 [==============================] - 0s 48ms/step - loss: 0.2074 - accuracy: 0.4640 - val_loss: 0.2224 - val_accuracy: 0.3493\n",
      "Epoch 9/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.2072 - accuracy: 0.4722\n",
      "Epoch 9: val_accuracy did not improve from 0.35616\n",
      "10/10 [==============================] - 1s 51ms/step - loss: 0.2073 - accuracy: 0.4718 - val_loss: 0.2231 - val_accuracy: 0.3288\n",
      "Epoch 10/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.2083 - accuracy: 0.4740\n",
      "Epoch 10: val_accuracy improved from 0.35616 to 0.36301, saving model to best_model_CNNLSTM.h5\n",
      "10/10 [==============================] - 1s 53ms/step - loss: 0.2083 - accuracy: 0.4740 - val_loss: 0.2219 - val_accuracy: 0.3630\n",
      "Epoch 11/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.2059 - accuracy: 0.4692\n",
      "Epoch 11: val_accuracy did not improve from 0.36301\n",
      "10/10 [==============================] - 0s 47ms/step - loss: 0.2059 - accuracy: 0.4692 - val_loss: 0.2220 - val_accuracy: 0.3493\n",
      "Epoch 12/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.2062 - accuracy: 0.4779\n",
      "Epoch 12: val_accuracy did not improve from 0.36301\n",
      "10/10 [==============================] - 1s 50ms/step - loss: 0.2061 - accuracy: 0.4783 - val_loss: 0.2214 - val_accuracy: 0.3493\n",
      "Epoch 13/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.2028 - accuracy: 0.5043\n",
      "Epoch 13: val_accuracy improved from 0.36301 to 0.36986, saving model to best_model_CNNLSTM.h5\n",
      "10/10 [==============================] - 1s 54ms/step - loss: 0.2028 - accuracy: 0.5043 - val_loss: 0.2215 - val_accuracy: 0.3699\n",
      "Epoch 14/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.2026 - accuracy: 0.4948\n",
      "Epoch 14: val_accuracy improved from 0.36986 to 0.42466, saving model to best_model_CNNLSTM.h5\n",
      "10/10 [==============================] - 1s 54ms/step - loss: 0.2026 - accuracy: 0.4948 - val_loss: 0.2211 - val_accuracy: 0.4247\n",
      "Epoch 15/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1997 - accuracy: 0.5221\n",
      "Epoch 15: val_accuracy did not improve from 0.42466\n",
      "10/10 [==============================] - 1s 51ms/step - loss: 0.1997 - accuracy: 0.5221 - val_loss: 0.2244 - val_accuracy: 0.3630\n",
      "Epoch 16/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.2008 - accuracy: 0.4983\n",
      "Epoch 16: val_accuracy did not improve from 0.42466\n",
      "10/10 [==============================] - 1s 52ms/step - loss: 0.2008 - accuracy: 0.4983 - val_loss: 0.2190 - val_accuracy: 0.3425\n",
      "Epoch 17/500\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2001 - accuracy: 0.5165\n",
      "Epoch 17: val_accuracy did not improve from 0.42466\n",
      "10/10 [==============================] - 1s 51ms/step - loss: 0.2001 - accuracy: 0.5165 - val_loss: 0.2224 - val_accuracy: 0.3356\n",
      "Epoch 18/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1994 - accuracy: 0.5091\n",
      "Epoch 18: val_accuracy did not improve from 0.42466\n",
      "10/10 [==============================] - 0s 49ms/step - loss: 0.1994 - accuracy: 0.5091 - val_loss: 0.2214 - val_accuracy: 0.3699\n",
      "Epoch 19/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1986 - accuracy: 0.5174\n",
      "Epoch 19: val_accuracy did not improve from 0.42466\n",
      "10/10 [==============================] - 1s 50ms/step - loss: 0.1986 - accuracy: 0.5173 - val_loss: 0.2182 - val_accuracy: 0.3562\n",
      "Epoch 20/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1991 - accuracy: 0.5278\n",
      "Epoch 20: val_accuracy did not improve from 0.42466\n",
      "10/10 [==============================] - 1s 50ms/step - loss: 0.1991 - accuracy: 0.5278 - val_loss: 0.2164 - val_accuracy: 0.3562\n",
      "Epoch 21/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1972 - accuracy: 0.5234\n",
      "Epoch 21: val_accuracy did not improve from 0.42466\n",
      "10/10 [==============================] - 1s 50ms/step - loss: 0.1973 - accuracy: 0.5230 - val_loss: 0.2194 - val_accuracy: 0.3562\n",
      "Epoch 22/500\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1986 - accuracy: 0.5082\n",
      "Epoch 22: val_accuracy did not improve from 0.42466\n",
      "10/10 [==============================] - 0s 49ms/step - loss: 0.1986 - accuracy: 0.5082 - val_loss: 0.2231 - val_accuracy: 0.3493\n",
      "Epoch 23/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.2020 - accuracy: 0.4935\n",
      "Epoch 23: val_accuracy did not improve from 0.42466\n",
      "10/10 [==============================] - 0s 49ms/step - loss: 0.2020 - accuracy: 0.4931 - val_loss: 0.2153 - val_accuracy: 0.3630\n",
      "Epoch 24/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1984 - accuracy: 0.5200\n",
      "Epoch 24: val_accuracy did not improve from 0.42466\n",
      "10/10 [==============================] - 1s 52ms/step - loss: 0.1985 - accuracy: 0.5195 - val_loss: 0.2180 - val_accuracy: 0.3493\n",
      "Epoch 25/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1974 - accuracy: 0.5135\n",
      "Epoch 25: val_accuracy did not improve from 0.42466\n",
      "10/10 [==============================] - 1s 52ms/step - loss: 0.1975 - accuracy: 0.5134 - val_loss: 0.2242 - val_accuracy: 0.3493\n",
      "Epoch 26/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.2010 - accuracy: 0.4987\n",
      "Epoch 26: val_accuracy did not improve from 0.42466\n",
      "10/10 [==============================] - 1s 51ms/step - loss: 0.2011 - accuracy: 0.4983 - val_loss: 0.2170 - val_accuracy: 0.3836\n",
      "Epoch 27/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.2002 - accuracy: 0.4987\n",
      "Epoch 27: val_accuracy did not improve from 0.42466\n",
      "10/10 [==============================] - 1s 50ms/step - loss: 0.2001 - accuracy: 0.4987 - val_loss: 0.2218 - val_accuracy: 0.3767\n",
      "Epoch 28/500\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1997 - accuracy: 0.5108\n",
      "Epoch 28: val_accuracy did not improve from 0.42466\n",
      "10/10 [==============================] - 0s 49ms/step - loss: 0.1997 - accuracy: 0.5108 - val_loss: 0.2245 - val_accuracy: 0.3836\n",
      "Epoch 29/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1974 - accuracy: 0.5109\n",
      "Epoch 29: val_accuracy did not improve from 0.42466\n",
      "10/10 [==============================] - 1s 50ms/step - loss: 0.1974 - accuracy: 0.5113 - val_loss: 0.2235 - val_accuracy: 0.4110\n",
      "Epoch 30/500\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1968 - accuracy: 0.5121\n",
      "Epoch 30: val_accuracy improved from 0.42466 to 0.43151, saving model to best_model_CNNLSTM.h5\n",
      "10/10 [==============================] - 1s 54ms/step - loss: 0.1968 - accuracy: 0.5121 - val_loss: 0.2242 - val_accuracy: 0.4315\n",
      "Epoch 31/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1983 - accuracy: 0.5143\n",
      "Epoch 31: val_accuracy improved from 0.43151 to 0.43836, saving model to best_model_CNNLSTM.h5\n",
      "10/10 [==============================] - 1s 52ms/step - loss: 0.1983 - accuracy: 0.5139 - val_loss: 0.2225 - val_accuracy: 0.4384\n",
      "Epoch 32/500\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1977 - accuracy: 0.5134\n",
      "Epoch 32: val_accuracy did not improve from 0.43836\n",
      "10/10 [==============================] - 0s 48ms/step - loss: 0.1977 - accuracy: 0.5134 - val_loss: 0.2212 - val_accuracy: 0.3836\n",
      "Epoch 33/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1960 - accuracy: 0.5217\n",
      "Epoch 33: val_accuracy improved from 0.43836 to 0.52055, saving model to best_model_CNNLSTM.h5\n",
      "10/10 [==============================] - 1s 53ms/step - loss: 0.1960 - accuracy: 0.5217 - val_loss: 0.2314 - val_accuracy: 0.5205\n",
      "Epoch 34/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1933 - accuracy: 0.5425\n",
      "Epoch 34: val_accuracy did not improve from 0.52055\n",
      "10/10 [==============================] - 0s 47ms/step - loss: 0.1932 - accuracy: 0.5425 - val_loss: 0.2318 - val_accuracy: 0.3836\n",
      "Epoch 35/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1977 - accuracy: 0.5273\n",
      "Epoch 35: val_accuracy did not improve from 0.52055\n",
      "10/10 [==============================] - 1s 50ms/step - loss: 0.1977 - accuracy: 0.5273 - val_loss: 0.2316 - val_accuracy: 0.4658\n",
      "Epoch 36/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1942 - accuracy: 0.5260\n",
      "Epoch 36: val_accuracy did not improve from 0.52055\n",
      "10/10 [==============================] - 0s 49ms/step - loss: 0.1943 - accuracy: 0.5256 - val_loss: 0.2166 - val_accuracy: 0.4452\n",
      "Epoch 37/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1942 - accuracy: 0.5421\n",
      "Epoch 37: val_accuracy did not improve from 0.52055\n",
      "10/10 [==============================] - 0s 49ms/step - loss: 0.1942 - accuracy: 0.5421 - val_loss: 0.2270 - val_accuracy: 0.4178\n",
      "Epoch 38/500\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1929 - accuracy: 0.5473\n",
      "Epoch 38: val_accuracy did not improve from 0.52055\n",
      "10/10 [==============================] - 0s 50ms/step - loss: 0.1929 - accuracy: 0.5473 - val_loss: 0.2274 - val_accuracy: 0.4932\n",
      "Epoch 39/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1964 - accuracy: 0.5269\n",
      "Epoch 39: val_accuracy did not improve from 0.52055\n",
      "10/10 [==============================] - 1s 51ms/step - loss: 0.1963 - accuracy: 0.5269 - val_loss: 0.2226 - val_accuracy: 0.4589\n",
      "Epoch 40/500\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1946 - accuracy: 0.5252\n",
      "Epoch 40: val_accuracy did not improve from 0.52055\n",
      "10/10 [==============================] - 0s 49ms/step - loss: 0.1946 - accuracy: 0.5252 - val_loss: 0.2324 - val_accuracy: 0.4932\n",
      "Epoch 41/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1962 - accuracy: 0.5217\n",
      "Epoch 41: val_accuracy did not improve from 0.52055\n",
      "10/10 [==============================] - 0s 49ms/step - loss: 0.1961 - accuracy: 0.5221 - val_loss: 0.2193 - val_accuracy: 0.3904\n",
      "Epoch 42/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1923 - accuracy: 0.5469\n",
      "Epoch 42: val_accuracy did not improve from 0.52055\n",
      "10/10 [==============================] - 0s 49ms/step - loss: 0.1924 - accuracy: 0.5468 - val_loss: 0.2238 - val_accuracy: 0.4315\n",
      "Epoch 43/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1950 - accuracy: 0.5169\n",
      "Epoch 43: val_accuracy did not improve from 0.52055\n",
      "10/10 [==============================] - 1s 52ms/step - loss: 0.1950 - accuracy: 0.5169 - val_loss: 0.2292 - val_accuracy: 0.4863\n",
      "Epoch 44/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1966 - accuracy: 0.5156\n",
      "Epoch 44: val_accuracy did not improve from 0.52055\n",
      "10/10 [==============================] - 1s 51ms/step - loss: 0.1966 - accuracy: 0.5152 - val_loss: 0.2291 - val_accuracy: 0.4658\n",
      "Epoch 45/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.2001 - accuracy: 0.4970\n",
      "Epoch 45: val_accuracy did not improve from 0.52055\n",
      "10/10 [==============================] - 1s 52ms/step - loss: 0.2001 - accuracy: 0.4974 - val_loss: 0.2355 - val_accuracy: 0.4726\n",
      "Epoch 46/500\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1960 - accuracy: 0.5225\n",
      "Epoch 46: val_accuracy did not improve from 0.52055\n",
      "10/10 [==============================] - 0s 48ms/step - loss: 0.1960 - accuracy: 0.5225 - val_loss: 0.2492 - val_accuracy: 0.4726\n",
      "Epoch 47/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1943 - accuracy: 0.5326\n",
      "Epoch 47: val_accuracy improved from 0.52055 to 0.58219, saving model to best_model_CNNLSTM.h5\n",
      "10/10 [==============================] - 1s 53ms/step - loss: 0.1943 - accuracy: 0.5330 - val_loss: 0.2384 - val_accuracy: 0.5822\n",
      "Epoch 48/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1930 - accuracy: 0.5352\n",
      "Epoch 48: val_accuracy did not improve from 0.58219\n",
      "10/10 [==============================] - 1s 50ms/step - loss: 0.1930 - accuracy: 0.5351 - val_loss: 0.2305 - val_accuracy: 0.5342\n",
      "Epoch 49/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1955 - accuracy: 0.5156\n",
      "Epoch 49: val_accuracy did not improve from 0.58219\n",
      "10/10 [==============================] - 1s 52ms/step - loss: 0.1955 - accuracy: 0.5156 - val_loss: 0.2319 - val_accuracy: 0.5068\n",
      "Epoch 50/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1952 - accuracy: 0.5273\n",
      "Epoch 50: val_accuracy did not improve from 0.58219\n",
      "10/10 [==============================] - 1s 52ms/step - loss: 0.1951 - accuracy: 0.5278 - val_loss: 0.2494 - val_accuracy: 0.5548\n",
      "Epoch 51/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1927 - accuracy: 0.5399\n",
      "Epoch 51: val_accuracy did not improve from 0.58219\n",
      "10/10 [==============================] - 0s 49ms/step - loss: 0.1928 - accuracy: 0.5399 - val_loss: 0.2439 - val_accuracy: 0.5822\n",
      "Epoch 52/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1909 - accuracy: 0.5386\n",
      "Epoch 52: val_accuracy did not improve from 0.58219\n",
      "10/10 [==============================] - 1s 50ms/step - loss: 0.1910 - accuracy: 0.5382 - val_loss: 0.2337 - val_accuracy: 0.5274\n",
      "Epoch 53/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1908 - accuracy: 0.5291\n",
      "Epoch 53: val_accuracy did not improve from 0.58219\n",
      "10/10 [==============================] - 1s 51ms/step - loss: 0.1908 - accuracy: 0.5286 - val_loss: 0.2293 - val_accuracy: 0.5411\n",
      "Epoch 54/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1936 - accuracy: 0.5182\n",
      "Epoch 54: val_accuracy did not improve from 0.58219\n",
      "10/10 [==============================] - 1s 51ms/step - loss: 0.1936 - accuracy: 0.5182 - val_loss: 0.2387 - val_accuracy: 0.5685\n",
      "Epoch 55/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.2004 - accuracy: 0.4961\n",
      "Epoch 55: val_accuracy did not improve from 0.58219\n",
      "10/10 [==============================] - 1s 50ms/step - loss: 0.2005 - accuracy: 0.4961 - val_loss: 0.2456 - val_accuracy: 0.5274\n",
      "Epoch 56/500\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2022 - accuracy: 0.4814\n",
      "Epoch 56: val_accuracy did not improve from 0.58219\n",
      "10/10 [==============================] - 1s 51ms/step - loss: 0.2022 - accuracy: 0.4814 - val_loss: 0.2451 - val_accuracy: 0.5616\n",
      "Epoch 57/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1965 - accuracy: 0.5104\n",
      "Epoch 57: val_accuracy did not improve from 0.58219\n",
      "10/10 [==============================] - 0s 47ms/step - loss: 0.1964 - accuracy: 0.5108 - val_loss: 0.2593 - val_accuracy: 0.4863\n",
      "Epoch 58/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1954 - accuracy: 0.5213\n",
      "Epoch 58: val_accuracy did not improve from 0.58219\n",
      "10/10 [==============================] - 1s 50ms/step - loss: 0.1954 - accuracy: 0.5217 - val_loss: 0.2497 - val_accuracy: 0.5342\n",
      "Epoch 59/500\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1920 - accuracy: 0.5395\n",
      "Epoch 59: val_accuracy did not improve from 0.58219\n",
      "10/10 [==============================] - 0s 49ms/step - loss: 0.1920 - accuracy: 0.5395 - val_loss: 0.2427 - val_accuracy: 0.5479\n",
      "Epoch 60/500\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1907 - accuracy: 0.5382\n",
      "Epoch 60: val_accuracy did not improve from 0.58219\n",
      "10/10 [==============================] - 0s 48ms/step - loss: 0.1907 - accuracy: 0.5382 - val_loss: 0.2129 - val_accuracy: 0.5137\n",
      "Epoch 61/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1924 - accuracy: 0.5265\n",
      "Epoch 61: val_accuracy did not improve from 0.58219\n",
      "10/10 [==============================] - 0s 49ms/step - loss: 0.1924 - accuracy: 0.5260 - val_loss: 0.2257 - val_accuracy: 0.5342\n",
      "Epoch 62/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1962 - accuracy: 0.5035\n",
      "Epoch 62: val_accuracy did not improve from 0.58219\n",
      "10/10 [==============================] - 1s 50ms/step - loss: 0.1962 - accuracy: 0.5039 - val_loss: 0.2391 - val_accuracy: 0.4658\n",
      "Epoch 63/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1946 - accuracy: 0.5165\n",
      "Epoch 63: val_accuracy did not improve from 0.58219\n",
      "10/10 [==============================] - 1s 50ms/step - loss: 0.1947 - accuracy: 0.5165 - val_loss: 0.2295 - val_accuracy: 0.5137\n",
      "Epoch 64/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1952 - accuracy: 0.5217\n",
      "Epoch 64: val_accuracy did not improve from 0.58219\n",
      "10/10 [==============================] - 0s 50ms/step - loss: 0.1951 - accuracy: 0.5217 - val_loss: 0.2208 - val_accuracy: 0.5137\n",
      "Epoch 65/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1919 - accuracy: 0.5356\n",
      "Epoch 65: val_accuracy did not improve from 0.58219\n",
      "10/10 [==============================] - 1s 51ms/step - loss: 0.1919 - accuracy: 0.5356 - val_loss: 0.2131 - val_accuracy: 0.5479\n",
      "Epoch 66/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1965 - accuracy: 0.5104\n",
      "Epoch 66: val_accuracy did not improve from 0.58219\n",
      "10/10 [==============================] - 0s 48ms/step - loss: 0.1965 - accuracy: 0.5104 - val_loss: 0.2281 - val_accuracy: 0.5068\n",
      "Epoch 67/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1896 - accuracy: 0.5551\n",
      "Epoch 67: val_accuracy did not improve from 0.58219\n",
      "10/10 [==============================] - 0s 48ms/step - loss: 0.1896 - accuracy: 0.5555 - val_loss: 0.2245 - val_accuracy: 0.4589\n",
      "Epoch 68/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1900 - accuracy: 0.5443\n",
      "Epoch 68: val_accuracy did not improve from 0.58219\n",
      "10/10 [==============================] - 1s 50ms/step - loss: 0.1900 - accuracy: 0.5438 - val_loss: 0.2158 - val_accuracy: 0.5548\n",
      "Epoch 69/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1897 - accuracy: 0.5408\n",
      "Epoch 69: val_accuracy did not improve from 0.58219\n",
      "10/10 [==============================] - 1s 51ms/step - loss: 0.1897 - accuracy: 0.5408 - val_loss: 0.2120 - val_accuracy: 0.5822\n",
      "Epoch 70/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1929 - accuracy: 0.5382\n",
      "Epoch 70: val_accuracy did not improve from 0.58219\n",
      "10/10 [==============================] - 1s 52ms/step - loss: 0.1929 - accuracy: 0.5386 - val_loss: 0.2394 - val_accuracy: 0.5753\n",
      "Epoch 71/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1936 - accuracy: 0.5321\n",
      "Epoch 71: val_accuracy improved from 0.58219 to 0.59589, saving model to best_model_CNNLSTM.h5\n",
      "10/10 [==============================] - 1s 51ms/step - loss: 0.1935 - accuracy: 0.5325 - val_loss: 0.2611 - val_accuracy: 0.5959\n",
      "Epoch 72/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1903 - accuracy: 0.5408\n",
      "Epoch 72: val_accuracy improved from 0.59589 to 0.60959, saving model to best_model_CNNLSTM.h5\n",
      "10/10 [==============================] - 1s 51ms/step - loss: 0.1904 - accuracy: 0.5403 - val_loss: 0.2463 - val_accuracy: 0.6096\n",
      "Epoch 73/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1902 - accuracy: 0.5286\n",
      "Epoch 73: val_accuracy did not improve from 0.60959\n",
      "10/10 [==============================] - 1s 52ms/step - loss: 0.1903 - accuracy: 0.5282 - val_loss: 0.2302 - val_accuracy: 0.4726\n",
      "Epoch 74/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1961 - accuracy: 0.5187\n",
      "Epoch 74: val_accuracy did not improve from 0.60959\n",
      "10/10 [==============================] - 1s 50ms/step - loss: 0.1961 - accuracy: 0.5186 - val_loss: 0.2512 - val_accuracy: 0.5205\n",
      "Epoch 75/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1908 - accuracy: 0.5312\n",
      "Epoch 75: val_accuracy did not improve from 0.60959\n",
      "10/10 [==============================] - 0s 49ms/step - loss: 0.1908 - accuracy: 0.5312 - val_loss: 0.2406 - val_accuracy: 0.5616\n",
      "Epoch 76/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1913 - accuracy: 0.5208\n",
      "Epoch 76: val_accuracy did not improve from 0.60959\n",
      "10/10 [==============================] - 0s 48ms/step - loss: 0.1914 - accuracy: 0.5208 - val_loss: 0.2380 - val_accuracy: 0.5890\n",
      "Epoch 77/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1890 - accuracy: 0.5516\n",
      "Epoch 77: val_accuracy did not improve from 0.60959\n",
      "10/10 [==============================] - 0s 49ms/step - loss: 0.1890 - accuracy: 0.5520 - val_loss: 0.2270 - val_accuracy: 0.5342\n",
      "Epoch 78/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1878 - accuracy: 0.5569\n",
      "Epoch 78: val_accuracy did not improve from 0.60959\n",
      "10/10 [==============================] - 1s 50ms/step - loss: 0.1877 - accuracy: 0.5572 - val_loss: 0.2526 - val_accuracy: 0.4589\n",
      "Epoch 79/500\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1892 - accuracy: 0.5542\n",
      "Epoch 79: val_accuracy did not improve from 0.60959\n",
      "10/10 [==============================] - 0s 49ms/step - loss: 0.1892 - accuracy: 0.5542 - val_loss: 0.2569 - val_accuracy: 0.4452\n",
      "Epoch 80/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1863 - accuracy: 0.5664\n",
      "Epoch 80: val_accuracy did not improve from 0.60959\n",
      "10/10 [==============================] - 0s 47ms/step - loss: 0.1864 - accuracy: 0.5659 - val_loss: 0.2235 - val_accuracy: 0.4521\n",
      "Epoch 81/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1865 - accuracy: 0.5599\n",
      "Epoch 81: val_accuracy did not improve from 0.60959\n",
      "10/10 [==============================] - 1s 51ms/step - loss: 0.1866 - accuracy: 0.5594 - val_loss: 0.2418 - val_accuracy: 0.3562\n",
      "Epoch 82/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1891 - accuracy: 0.5438\n",
      "Epoch 82: val_accuracy did not improve from 0.60959\n",
      "10/10 [==============================] - 0s 49ms/step - loss: 0.1891 - accuracy: 0.5442 - val_loss: 0.2238 - val_accuracy: 0.4521\n",
      "Epoch 83/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1882 - accuracy: 0.5503\n",
      "Epoch 83: val_accuracy did not improve from 0.60959\n",
      "10/10 [==============================] - 1s 50ms/step - loss: 0.1882 - accuracy: 0.5503 - val_loss: 0.2338 - val_accuracy: 0.5000\n",
      "Epoch 84/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1892 - accuracy: 0.5482\n",
      "Epoch 84: val_accuracy did not improve from 0.60959\n",
      "10/10 [==============================] - 1s 51ms/step - loss: 0.1892 - accuracy: 0.5477 - val_loss: 0.2550 - val_accuracy: 0.5411\n",
      "Epoch 85/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1871 - accuracy: 0.5560\n",
      "Epoch 85: val_accuracy did not improve from 0.60959\n",
      "10/10 [==============================] - 0s 47ms/step - loss: 0.1870 - accuracy: 0.5564 - val_loss: 0.2224 - val_accuracy: 0.5205\n",
      "Epoch 86/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1866 - accuracy: 0.5599\n",
      "Epoch 86: val_accuracy did not improve from 0.60959\n",
      "10/10 [==============================] - 1s 52ms/step - loss: 0.1866 - accuracy: 0.5598 - val_loss: 0.2489 - val_accuracy: 0.4863\n",
      "Epoch 87/500\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1877 - accuracy: 0.5616\n",
      "Epoch 87: val_accuracy did not improve from 0.60959\n",
      "10/10 [==============================] - 1s 50ms/step - loss: 0.1877 - accuracy: 0.5616 - val_loss: 0.2485 - val_accuracy: 0.4041\n",
      "Epoch 88/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1885 - accuracy: 0.5508\n",
      "Epoch 88: val_accuracy did not improve from 0.60959\n",
      "10/10 [==============================] - 1s 51ms/step - loss: 0.1885 - accuracy: 0.5507 - val_loss: 0.2379 - val_accuracy: 0.4315\n",
      "Epoch 89/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1890 - accuracy: 0.5477\n",
      "Epoch 89: val_accuracy did not improve from 0.60959\n",
      "10/10 [==============================] - 1s 50ms/step - loss: 0.1890 - accuracy: 0.5473 - val_loss: 0.2369 - val_accuracy: 0.4041\n",
      "Epoch 90/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1880 - accuracy: 0.5516\n",
      "Epoch 90: val_accuracy did not improve from 0.60959\n",
      "10/10 [==============================] - 1s 50ms/step - loss: 0.1881 - accuracy: 0.5516 - val_loss: 0.2324 - val_accuracy: 0.5000\n",
      "Epoch 91/500\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1908 - accuracy: 0.5551\n",
      "Epoch 91: val_accuracy did not improve from 0.60959\n",
      "10/10 [==============================] - 0s 50ms/step - loss: 0.1908 - accuracy: 0.5551 - val_loss: 0.2613 - val_accuracy: 0.4521\n",
      "Epoch 92/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1924 - accuracy: 0.5321\n",
      "Epoch 92: val_accuracy did not improve from 0.60959\n",
      "10/10 [==============================] - 0s 50ms/step - loss: 0.1923 - accuracy: 0.5325 - val_loss: 0.2422 - val_accuracy: 0.4452\n",
      "Epoch 93/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1869 - accuracy: 0.5577\n",
      "Epoch 93: val_accuracy did not improve from 0.60959\n",
      "10/10 [==============================] - 1s 51ms/step - loss: 0.1870 - accuracy: 0.5572 - val_loss: 0.2349 - val_accuracy: 0.4658\n",
      "Epoch 94/500\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1909 - accuracy: 0.5421\n",
      "Epoch 94: val_accuracy did not improve from 0.60959\n",
      "10/10 [==============================] - 0s 48ms/step - loss: 0.1909 - accuracy: 0.5421 - val_loss: 0.2471 - val_accuracy: 0.4110\n",
      "Epoch 95/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1893 - accuracy: 0.5660\n",
      "Epoch 95: val_accuracy did not improve from 0.60959\n",
      "10/10 [==============================] - 1s 50ms/step - loss: 0.1894 - accuracy: 0.5655 - val_loss: 0.2217 - val_accuracy: 0.4110\n",
      "Epoch 96/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1904 - accuracy: 0.5399\n",
      "Epoch 96: val_accuracy did not improve from 0.60959\n",
      "10/10 [==============================] - 1s 51ms/step - loss: 0.1905 - accuracy: 0.5399 - val_loss: 0.2348 - val_accuracy: 0.4041\n",
      "Epoch 97/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1891 - accuracy: 0.5473\n",
      "Epoch 97: val_accuracy did not improve from 0.60959\n",
      "10/10 [==============================] - 0s 50ms/step - loss: 0.1891 - accuracy: 0.5473 - val_loss: 0.2491 - val_accuracy: 0.3836\n",
      "Epoch 98/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1857 - accuracy: 0.5599\n",
      "Epoch 98: val_accuracy did not improve from 0.60959\n",
      "10/10 [==============================] - 1s 51ms/step - loss: 0.1857 - accuracy: 0.5603 - val_loss: 0.2283 - val_accuracy: 0.3904\n",
      "Epoch 99/500\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1895 - accuracy: 0.5299\n",
      "Epoch 99: val_accuracy did not improve from 0.60959\n",
      "10/10 [==============================] - 0s 49ms/step - loss: 0.1895 - accuracy: 0.5299 - val_loss: 0.2733 - val_accuracy: 0.3973\n",
      "Epoch 100/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1867 - accuracy: 0.5616\n",
      "Epoch 100: val_accuracy did not improve from 0.60959\n",
      "10/10 [==============================] - 1s 50ms/step - loss: 0.1868 - accuracy: 0.5616 - val_loss: 0.2668 - val_accuracy: 0.3425\n",
      "Epoch 101/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1876 - accuracy: 0.5668\n",
      "Epoch 101: val_accuracy did not improve from 0.60959\n",
      "10/10 [==============================] - 1s 52ms/step - loss: 0.1877 - accuracy: 0.5668 - val_loss: 0.2177 - val_accuracy: 0.3630\n",
      "Epoch 102/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1898 - accuracy: 0.5260\n",
      "Epoch 102: val_accuracy did not improve from 0.60959\n",
      "10/10 [==============================] - 1s 50ms/step - loss: 0.1899 - accuracy: 0.5260 - val_loss: 0.2369 - val_accuracy: 0.3767\n",
      "Epoch 103/500\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1884 - accuracy: 0.5447\n",
      "Epoch 103: val_accuracy did not improve from 0.60959\n",
      "10/10 [==============================] - 1s 51ms/step - loss: 0.1884 - accuracy: 0.5447 - val_loss: 0.2520 - val_accuracy: 0.3767\n",
      "Epoch 104/500\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1874 - accuracy: 0.5481\n",
      "Epoch 104: val_accuracy did not improve from 0.60959\n",
      "10/10 [==============================] - 1s 50ms/step - loss: 0.1874 - accuracy: 0.5481 - val_loss: 0.2584 - val_accuracy: 0.4041\n",
      "Epoch 105/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1863 - accuracy: 0.5521\n",
      "Epoch 105: val_accuracy did not improve from 0.60959\n",
      "10/10 [==============================] - 0s 49ms/step - loss: 0.1862 - accuracy: 0.5525 - val_loss: 0.2806 - val_accuracy: 0.3904\n",
      "Epoch 106/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1822 - accuracy: 0.5816\n",
      "Epoch 106: val_accuracy did not improve from 0.60959\n",
      "10/10 [==============================] - 1s 51ms/step - loss: 0.1822 - accuracy: 0.5820 - val_loss: 0.2588 - val_accuracy: 0.4247\n",
      "Epoch 107/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1831 - accuracy: 0.5712\n",
      "Epoch 107: val_accuracy did not improve from 0.60959\n",
      "10/10 [==============================] - 1s 51ms/step - loss: 0.1831 - accuracy: 0.5707 - val_loss: 0.2498 - val_accuracy: 0.3562\n",
      "Epoch 108/500\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1849 - accuracy: 0.5759\n",
      "Epoch 108: val_accuracy did not improve from 0.60959\n",
      "10/10 [==============================] - 1s 50ms/step - loss: 0.1849 - accuracy: 0.5759 - val_loss: 0.2455 - val_accuracy: 0.3288\n",
      "Epoch 109/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1873 - accuracy: 0.5608\n",
      "Epoch 109: val_accuracy did not improve from 0.60959\n",
      "10/10 [==============================] - 1s 50ms/step - loss: 0.1872 - accuracy: 0.5611 - val_loss: 0.2567 - val_accuracy: 0.3973\n",
      "Epoch 110/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1865 - accuracy: 0.5681\n",
      "Epoch 110: val_accuracy did not improve from 0.60959\n",
      "10/10 [==============================] - 1s 50ms/step - loss: 0.1865 - accuracy: 0.5681 - val_loss: 0.2677 - val_accuracy: 0.4247\n",
      "Epoch 111/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1852 - accuracy: 0.5668\n",
      "Epoch 111: val_accuracy did not improve from 0.60959\n",
      "10/10 [==============================] - 1s 52ms/step - loss: 0.1851 - accuracy: 0.5672 - val_loss: 0.2610 - val_accuracy: 0.3767\n",
      "Epoch 112/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1835 - accuracy: 0.5825\n",
      "Epoch 112: val_accuracy did not improve from 0.60959\n",
      "10/10 [==============================] - 1s 50ms/step - loss: 0.1835 - accuracy: 0.5828 - val_loss: 0.2699 - val_accuracy: 0.4041\n",
      "Epoch 113/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1834 - accuracy: 0.5768\n",
      "Epoch 113: val_accuracy did not improve from 0.60959\n",
      "10/10 [==============================] - 1s 50ms/step - loss: 0.1834 - accuracy: 0.5768 - val_loss: 0.2643 - val_accuracy: 0.4521\n",
      "Epoch 114/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1847 - accuracy: 0.5612\n",
      "Epoch 114: val_accuracy did not improve from 0.60959\n",
      "10/10 [==============================] - 1s 52ms/step - loss: 0.1847 - accuracy: 0.5611 - val_loss: 0.2489 - val_accuracy: 0.4863\n",
      "Epoch 115/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1905 - accuracy: 0.5269\n",
      "Epoch 115: val_accuracy did not improve from 0.60959\n",
      "10/10 [==============================] - 1s 51ms/step - loss: 0.1904 - accuracy: 0.5273 - val_loss: 0.2557 - val_accuracy: 0.4110\n",
      "Epoch 116/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1866 - accuracy: 0.5677\n",
      "Epoch 116: val_accuracy did not improve from 0.60959\n",
      "10/10 [==============================] - 1s 52ms/step - loss: 0.1865 - accuracy: 0.5681 - val_loss: 0.2582 - val_accuracy: 0.3836\n",
      "Epoch 117/500\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1843 - accuracy: 0.5893\n",
      "Epoch 117: val_accuracy did not improve from 0.60959\n",
      "10/10 [==============================] - 1s 51ms/step - loss: 0.1843 - accuracy: 0.5893 - val_loss: 0.2691 - val_accuracy: 0.3973\n",
      "Epoch 118/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1871 - accuracy: 0.5686\n",
      "Epoch 118: val_accuracy did not improve from 0.60959\n",
      "10/10 [==============================] - 1s 51ms/step - loss: 0.1870 - accuracy: 0.5685 - val_loss: 0.2819 - val_accuracy: 0.4041\n",
      "Epoch 119/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1855 - accuracy: 0.5673\n",
      "Epoch 119: val_accuracy did not improve from 0.60959\n",
      "10/10 [==============================] - 0s 49ms/step - loss: 0.1855 - accuracy: 0.5672 - val_loss: 0.2593 - val_accuracy: 0.4178\n",
      "Epoch 120/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1836 - accuracy: 0.5781\n",
      "Epoch 120: val_accuracy did not improve from 0.60959\n",
      "10/10 [==============================] - 1s 51ms/step - loss: 0.1837 - accuracy: 0.5776 - val_loss: 0.2689 - val_accuracy: 0.4315\n",
      "Epoch 121/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1840 - accuracy: 0.5577\n",
      "Epoch 121: val_accuracy did not improve from 0.60959\n",
      "10/10 [==============================] - 1s 51ms/step - loss: 0.1840 - accuracy: 0.5577 - val_loss: 0.2459 - val_accuracy: 0.4247\n",
      "Epoch 122/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1835 - accuracy: 0.5747\n",
      "Epoch 122: val_accuracy did not improve from 0.60959\n",
      "10/10 [==============================] - 1s 53ms/step - loss: 0.1835 - accuracy: 0.5746 - val_loss: 0.2472 - val_accuracy: 0.3836\n",
      "Epoch 1/500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-08 23:31:06.917200: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape insequential_2/dropout_4/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.2249 - accuracy: 0.3672\n",
      "Epoch 1: val_accuracy improved from -inf to 0.33103, saving model to best_model_CNNLSTM.h5\n",
      "10/10 [==============================] - 2s 67ms/step - loss: 0.2249 - accuracy: 0.3667 - val_loss: 0.2223 - val_accuracy: 0.3310\n",
      "Epoch 2/500\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2129 - accuracy: 0.4465\n",
      "Epoch 2: val_accuracy improved from 0.33103 to 0.34483, saving model to best_model_CNNLSTM.h5\n",
      "10/10 [==============================] - 1s 52ms/step - loss: 0.2129 - accuracy: 0.4465 - val_loss: 0.2222 - val_accuracy: 0.3448\n",
      "Epoch 3/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.2124 - accuracy: 0.4501\n",
      "Epoch 3: val_accuracy improved from 0.34483 to 0.35862, saving model to best_model_CNNLSTM.h5\n",
      "10/10 [==============================] - 1s 53ms/step - loss: 0.2124 - accuracy: 0.4499 - val_loss: 0.2222 - val_accuracy: 0.3586\n",
      "Epoch 4/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.2105 - accuracy: 0.4674\n",
      "Epoch 4: val_accuracy improved from 0.35862 to 0.38621, saving model to best_model_CNNLSTM.h5\n",
      "10/10 [==============================] - 1s 52ms/step - loss: 0.2105 - accuracy: 0.4677 - val_loss: 0.2221 - val_accuracy: 0.3862\n",
      "Epoch 5/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.2100 - accuracy: 0.4670\n",
      "Epoch 5: val_accuracy did not improve from 0.38621\n",
      "10/10 [==============================] - 1s 51ms/step - loss: 0.2100 - accuracy: 0.4668 - val_loss: 0.2221 - val_accuracy: 0.3586\n",
      "Epoch 6/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.2117 - accuracy: 0.4536\n",
      "Epoch 6: val_accuracy did not improve from 0.38621\n",
      "10/10 [==============================] - 1s 51ms/step - loss: 0.2118 - accuracy: 0.4530 - val_loss: 0.2223 - val_accuracy: 0.2897\n",
      "Epoch 7/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.2112 - accuracy: 0.4470\n",
      "Epoch 7: val_accuracy did not improve from 0.38621\n",
      "10/10 [==============================] - 1s 50ms/step - loss: 0.2112 - accuracy: 0.4469 - val_loss: 0.2224 - val_accuracy: 0.3034\n",
      "Epoch 8/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.2108 - accuracy: 0.4540\n",
      "Epoch 8: val_accuracy did not improve from 0.38621\n",
      "10/10 [==============================] - 1s 52ms/step - loss: 0.2108 - accuracy: 0.4534 - val_loss: 0.2224 - val_accuracy: 0.2759\n",
      "Epoch 9/500\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2069 - accuracy: 0.4668\n",
      "Epoch 9: val_accuracy did not improve from 0.38621\n",
      "10/10 [==============================] - 1s 53ms/step - loss: 0.2069 - accuracy: 0.4668 - val_loss: 0.2225 - val_accuracy: 0.3103\n",
      "Epoch 10/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.2082 - accuracy: 0.4609\n",
      "Epoch 10: val_accuracy did not improve from 0.38621\n",
      "10/10 [==============================] - 1s 53ms/step - loss: 0.2082 - accuracy: 0.4603 - val_loss: 0.2225 - val_accuracy: 0.2621\n",
      "Epoch 11/500\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2068 - accuracy: 0.4629\n",
      "Epoch 11: val_accuracy did not improve from 0.38621\n",
      "10/10 [==============================] - 1s 52ms/step - loss: 0.2068 - accuracy: 0.4629 - val_loss: 0.2224 - val_accuracy: 0.2828\n",
      "Epoch 12/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.2070 - accuracy: 0.4653\n",
      "Epoch 12: val_accuracy did not improve from 0.38621\n",
      "10/10 [==============================] - 0s 50ms/step - loss: 0.2070 - accuracy: 0.4651 - val_loss: 0.2235 - val_accuracy: 0.2897\n",
      "Epoch 13/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.2076 - accuracy: 0.4644\n",
      "Epoch 13: val_accuracy did not improve from 0.38621\n",
      "10/10 [==============================] - 1s 51ms/step - loss: 0.2077 - accuracy: 0.4642 - val_loss: 0.2238 - val_accuracy: 0.2828\n",
      "Epoch 14/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.2062 - accuracy: 0.4731\n",
      "Epoch 14: val_accuracy did not improve from 0.38621\n",
      "10/10 [==============================] - 0s 49ms/step - loss: 0.2063 - accuracy: 0.4725 - val_loss: 0.2243 - val_accuracy: 0.3241\n",
      "Epoch 15/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.2053 - accuracy: 0.4648\n",
      "Epoch 15: val_accuracy did not improve from 0.38621\n",
      "10/10 [==============================] - 1s 51ms/step - loss: 0.2053 - accuracy: 0.4647 - val_loss: 0.2228 - val_accuracy: 0.3172\n",
      "Epoch 16/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.2030 - accuracy: 0.4787\n",
      "Epoch 16: val_accuracy improved from 0.38621 to 0.39310, saving model to best_model_CNNLSTM.h5\n",
      "10/10 [==============================] - 1s 55ms/step - loss: 0.2032 - accuracy: 0.4781 - val_loss: 0.2201 - val_accuracy: 0.3931\n",
      "Epoch 17/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1999 - accuracy: 0.5039\n",
      "Epoch 17: val_accuracy did not improve from 0.39310\n",
      "10/10 [==============================] - 1s 52ms/step - loss: 0.1999 - accuracy: 0.5037 - val_loss: 0.2224 - val_accuracy: 0.2897\n",
      "Epoch 18/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.2001 - accuracy: 0.4948\n",
      "Epoch 18: val_accuracy did not improve from 0.39310\n",
      "10/10 [==============================] - 1s 52ms/step - loss: 0.2002 - accuracy: 0.4941 - val_loss: 0.2270 - val_accuracy: 0.2690\n",
      "Epoch 19/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.2037 - accuracy: 0.4839\n",
      "Epoch 19: val_accuracy did not improve from 0.39310\n",
      "10/10 [==============================] - 1s 52ms/step - loss: 0.2037 - accuracy: 0.4846 - val_loss: 0.2280 - val_accuracy: 0.3172\n",
      "Epoch 20/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1982 - accuracy: 0.5122\n",
      "Epoch 20: val_accuracy did not improve from 0.39310\n",
      "10/10 [==============================] - 0s 49ms/step - loss: 0.1982 - accuracy: 0.5124 - val_loss: 0.2237 - val_accuracy: 0.3103\n",
      "Epoch 21/500\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1970 - accuracy: 0.5093\n",
      "Epoch 21: val_accuracy did not improve from 0.39310\n",
      "10/10 [==============================] - 1s 52ms/step - loss: 0.1970 - accuracy: 0.5093 - val_loss: 0.2241 - val_accuracy: 0.2690\n",
      "Epoch 22/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1982 - accuracy: 0.5104\n",
      "Epoch 22: val_accuracy did not improve from 0.39310\n",
      "10/10 [==============================] - 1s 53ms/step - loss: 0.1982 - accuracy: 0.5106 - val_loss: 0.2216 - val_accuracy: 0.3517\n",
      "Epoch 23/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1962 - accuracy: 0.5087\n",
      "Epoch 23: val_accuracy improved from 0.39310 to 0.43448, saving model to best_model_CNNLSTM.h5\n",
      "10/10 [==============================] - 1s 55ms/step - loss: 0.1963 - accuracy: 0.5085 - val_loss: 0.2163 - val_accuracy: 0.4345\n",
      "Epoch 24/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1937 - accuracy: 0.5286\n",
      "Epoch 24: val_accuracy did not improve from 0.43448\n",
      "10/10 [==============================] - 1s 52ms/step - loss: 0.1938 - accuracy: 0.5284 - val_loss: 0.2251 - val_accuracy: 0.2621\n",
      "Epoch 25/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1943 - accuracy: 0.5282\n",
      "Epoch 25: val_accuracy did not improve from 0.43448\n",
      "10/10 [==============================] - 1s 52ms/step - loss: 0.1943 - accuracy: 0.5284 - val_loss: 0.2202 - val_accuracy: 0.3793\n",
      "Epoch 26/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1944 - accuracy: 0.5273\n",
      "Epoch 26: val_accuracy did not improve from 0.43448\n",
      "10/10 [==============================] - 1s 52ms/step - loss: 0.1943 - accuracy: 0.5280 - val_loss: 0.2190 - val_accuracy: 0.4138\n",
      "Epoch 27/500\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1934 - accuracy: 0.5293\n",
      "Epoch 27: val_accuracy improved from 0.43448 to 0.46207, saving model to best_model_CNNLSTM.h5\n",
      "10/10 [==============================] - 1s 52ms/step - loss: 0.1934 - accuracy: 0.5293 - val_loss: 0.2167 - val_accuracy: 0.4621\n",
      "Epoch 28/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1960 - accuracy: 0.5087\n",
      "Epoch 28: val_accuracy did not improve from 0.46207\n",
      "10/10 [==============================] - 1s 51ms/step - loss: 0.1960 - accuracy: 0.5085 - val_loss: 0.2230 - val_accuracy: 0.4069\n",
      "Epoch 29/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1937 - accuracy: 0.5352\n",
      "Epoch 29: val_accuracy did not improve from 0.46207\n",
      "10/10 [==============================] - 1s 51ms/step - loss: 0.1937 - accuracy: 0.5349 - val_loss: 0.2238 - val_accuracy: 0.4000\n",
      "Epoch 30/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1974 - accuracy: 0.5013\n",
      "Epoch 30: val_accuracy did not improve from 0.46207\n",
      "10/10 [==============================] - 1s 50ms/step - loss: 0.1974 - accuracy: 0.5011 - val_loss: 0.2171 - val_accuracy: 0.4414\n",
      "Epoch 31/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1945 - accuracy: 0.5278\n",
      "Epoch 31: val_accuracy did not improve from 0.46207\n",
      "10/10 [==============================] - 1s 51ms/step - loss: 0.1945 - accuracy: 0.5280 - val_loss: 0.2183 - val_accuracy: 0.4345\n",
      "Epoch 32/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1933 - accuracy: 0.5295\n",
      "Epoch 32: val_accuracy did not improve from 0.46207\n",
      "10/10 [==============================] - 1s 52ms/step - loss: 0.1934 - accuracy: 0.5293 - val_loss: 0.2216 - val_accuracy: 0.4207\n",
      "Epoch 33/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1944 - accuracy: 0.5278\n",
      "Epoch 33: val_accuracy did not improve from 0.46207\n",
      "10/10 [==============================] - 1s 52ms/step - loss: 0.1944 - accuracy: 0.5275 - val_loss: 0.2410 - val_accuracy: 0.2897\n",
      "Epoch 34/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1959 - accuracy: 0.5156\n",
      "Epoch 34: val_accuracy did not improve from 0.46207\n",
      "10/10 [==============================] - 1s 52ms/step - loss: 0.1960 - accuracy: 0.5150 - val_loss: 0.2298 - val_accuracy: 0.3793\n",
      "Epoch 35/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1946 - accuracy: 0.5256\n",
      "Epoch 35: val_accuracy did not improve from 0.46207\n",
      "10/10 [==============================] - 1s 52ms/step - loss: 0.1948 - accuracy: 0.5249 - val_loss: 0.2264 - val_accuracy: 0.3724\n",
      "Epoch 36/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1948 - accuracy: 0.5308\n",
      "Epoch 36: val_accuracy did not improve from 0.46207\n",
      "10/10 [==============================] - 1s 52ms/step - loss: 0.1947 - accuracy: 0.5310 - val_loss: 0.2432 - val_accuracy: 0.3517\n",
      "Epoch 37/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1921 - accuracy: 0.5334\n",
      "Epoch 37: val_accuracy did not improve from 0.46207\n",
      "10/10 [==============================] - 1s 51ms/step - loss: 0.1921 - accuracy: 0.5336 - val_loss: 0.2298 - val_accuracy: 0.3862\n",
      "Epoch 38/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1931 - accuracy: 0.5148\n",
      "Epoch 38: val_accuracy did not improve from 0.46207\n",
      "10/10 [==============================] - 1s 52ms/step - loss: 0.1930 - accuracy: 0.5150 - val_loss: 0.2312 - val_accuracy: 0.3586\n",
      "Epoch 39/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1908 - accuracy: 0.5295\n",
      "Epoch 39: val_accuracy did not improve from 0.46207\n",
      "10/10 [==============================] - 1s 51ms/step - loss: 0.1908 - accuracy: 0.5297 - val_loss: 0.2440 - val_accuracy: 0.2897\n",
      "Epoch 40/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1892 - accuracy: 0.5443\n",
      "Epoch 40: val_accuracy did not improve from 0.46207\n",
      "10/10 [==============================] - 1s 51ms/step - loss: 0.1893 - accuracy: 0.5436 - val_loss: 0.2300 - val_accuracy: 0.3724\n",
      "Epoch 41/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1932 - accuracy: 0.5269\n",
      "Epoch 41: val_accuracy did not improve from 0.46207\n",
      "10/10 [==============================] - 1s 50ms/step - loss: 0.1932 - accuracy: 0.5271 - val_loss: 0.2228 - val_accuracy: 0.3931\n",
      "Epoch 42/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1951 - accuracy: 0.5165\n",
      "Epoch 42: val_accuracy did not improve from 0.46207\n",
      "10/10 [==============================] - 1s 52ms/step - loss: 0.1951 - accuracy: 0.5163 - val_loss: 0.2260 - val_accuracy: 0.4138\n",
      "Epoch 43/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1946 - accuracy: 0.5122\n",
      "Epoch 43: val_accuracy did not improve from 0.46207\n",
      "10/10 [==============================] - 1s 52ms/step - loss: 0.1946 - accuracy: 0.5124 - val_loss: 0.2211 - val_accuracy: 0.4000\n",
      "Epoch 44/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1920 - accuracy: 0.5317\n",
      "Epoch 44: val_accuracy did not improve from 0.46207\n",
      "10/10 [==============================] - 1s 51ms/step - loss: 0.1920 - accuracy: 0.5314 - val_loss: 0.2076 - val_accuracy: 0.4552\n",
      "Epoch 45/500\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1920 - accuracy: 0.5288\n",
      "Epoch 45: val_accuracy did not improve from 0.46207\n",
      "10/10 [==============================] - 1s 51ms/step - loss: 0.1920 - accuracy: 0.5288 - val_loss: 0.2127 - val_accuracy: 0.4345\n",
      "Epoch 46/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1945 - accuracy: 0.5061\n",
      "Epoch 46: val_accuracy did not improve from 0.46207\n",
      "10/10 [==============================] - 1s 50ms/step - loss: 0.1945 - accuracy: 0.5063 - val_loss: 0.2194 - val_accuracy: 0.3724\n",
      "Epoch 47/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1936 - accuracy: 0.5312\n",
      "Epoch 47: val_accuracy did not improve from 0.46207\n",
      "10/10 [==============================] - 1s 53ms/step - loss: 0.1935 - accuracy: 0.5314 - val_loss: 0.2173 - val_accuracy: 0.4000\n",
      "Epoch 48/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1929 - accuracy: 0.5278\n",
      "Epoch 48: val_accuracy did not improve from 0.46207\n",
      "10/10 [==============================] - 1s 52ms/step - loss: 0.1929 - accuracy: 0.5275 - val_loss: 0.2204 - val_accuracy: 0.3862\n",
      "Epoch 49/500\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1930 - accuracy: 0.5241\n",
      "Epoch 49: val_accuracy did not improve from 0.46207\n",
      "10/10 [==============================] - 1s 51ms/step - loss: 0.1930 - accuracy: 0.5241 - val_loss: 0.2103 - val_accuracy: 0.4069\n",
      "Epoch 50/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1919 - accuracy: 0.5339\n",
      "Epoch 50: val_accuracy did not improve from 0.46207\n",
      "10/10 [==============================] - 1s 53ms/step - loss: 0.1919 - accuracy: 0.5340 - val_loss: 0.2160 - val_accuracy: 0.4483\n",
      "Epoch 51/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1936 - accuracy: 0.5286\n",
      "Epoch 51: val_accuracy did not improve from 0.46207\n",
      "10/10 [==============================] - 1s 52ms/step - loss: 0.1936 - accuracy: 0.5284 - val_loss: 0.2253 - val_accuracy: 0.4138\n",
      "Epoch 52/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1871 - accuracy: 0.5556\n",
      "Epoch 52: val_accuracy improved from 0.46207 to 0.46897, saving model to best_model_CNNLSTM.h5\n",
      "10/10 [==============================] - 1s 52ms/step - loss: 0.1871 - accuracy: 0.5557 - val_loss: 0.2056 - val_accuracy: 0.4690\n",
      "Epoch 53/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1941 - accuracy: 0.5317\n",
      "Epoch 53: val_accuracy did not improve from 0.46897\n",
      "10/10 [==============================] - 1s 52ms/step - loss: 0.1940 - accuracy: 0.5323 - val_loss: 0.2048 - val_accuracy: 0.4345\n",
      "Epoch 54/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1900 - accuracy: 0.5521\n",
      "Epoch 54: val_accuracy did not improve from 0.46897\n",
      "10/10 [==============================] - 1s 50ms/step - loss: 0.1902 - accuracy: 0.5514 - val_loss: 0.2423 - val_accuracy: 0.3103\n",
      "Epoch 55/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1898 - accuracy: 0.5490\n",
      "Epoch 55: val_accuracy did not improve from 0.46897\n",
      "10/10 [==============================] - 1s 53ms/step - loss: 0.1898 - accuracy: 0.5492 - val_loss: 0.2239 - val_accuracy: 0.4345\n",
      "Epoch 56/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1883 - accuracy: 0.5551\n",
      "Epoch 56: val_accuracy did not improve from 0.46897\n",
      "10/10 [==============================] - 0s 49ms/step - loss: 0.1882 - accuracy: 0.5553 - val_loss: 0.2112 - val_accuracy: 0.4483\n",
      "Epoch 57/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1876 - accuracy: 0.5521\n",
      "Epoch 57: val_accuracy did not improve from 0.46897\n",
      "10/10 [==============================] - 1s 52ms/step - loss: 0.1875 - accuracy: 0.5527 - val_loss: 0.2190 - val_accuracy: 0.4690\n",
      "Epoch 58/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1849 - accuracy: 0.5569\n",
      "Epoch 58: val_accuracy improved from 0.46897 to 0.49655, saving model to best_model_CNNLSTM.h5\n",
      "10/10 [==============================] - 1s 53ms/step - loss: 0.1850 - accuracy: 0.5570 - val_loss: 0.2005 - val_accuracy: 0.4966\n",
      "Epoch 59/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1899 - accuracy: 0.5438\n",
      "Epoch 59: val_accuracy did not improve from 0.49655\n",
      "10/10 [==============================] - 1s 52ms/step - loss: 0.1899 - accuracy: 0.5440 - val_loss: 0.2112 - val_accuracy: 0.4414\n",
      "Epoch 60/500\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1895 - accuracy: 0.5431\n",
      "Epoch 60: val_accuracy did not improve from 0.49655\n",
      "10/10 [==============================] - 1s 51ms/step - loss: 0.1895 - accuracy: 0.5431 - val_loss: 0.2097 - val_accuracy: 0.4897\n",
      "Epoch 61/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1907 - accuracy: 0.5382\n",
      "Epoch 61: val_accuracy did not improve from 0.49655\n",
      "10/10 [==============================] - 1s 52ms/step - loss: 0.1907 - accuracy: 0.5384 - val_loss: 0.2151 - val_accuracy: 0.4621\n",
      "Epoch 62/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1853 - accuracy: 0.5616\n",
      "Epoch 62: val_accuracy did not improve from 0.49655\n",
      "10/10 [==============================] - 1s 53ms/step - loss: 0.1853 - accuracy: 0.5613 - val_loss: 0.2099 - val_accuracy: 0.4690\n",
      "Epoch 63/500\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1905 - accuracy: 0.5397\n",
      "Epoch 63: val_accuracy did not improve from 0.49655\n",
      "10/10 [==============================] - 1s 51ms/step - loss: 0.1905 - accuracy: 0.5397 - val_loss: 0.1985 - val_accuracy: 0.4000\n",
      "Epoch 64/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1894 - accuracy: 0.5577\n",
      "Epoch 64: val_accuracy did not improve from 0.49655\n",
      "10/10 [==============================] - 1s 52ms/step - loss: 0.1893 - accuracy: 0.5583 - val_loss: 0.2176 - val_accuracy: 0.4069\n",
      "Epoch 65/500\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1871 - accuracy: 0.5566\n",
      "Epoch 65: val_accuracy did not improve from 0.49655\n",
      "10/10 [==============================] - 1s 50ms/step - loss: 0.1871 - accuracy: 0.5566 - val_loss: 0.2223 - val_accuracy: 0.4414\n",
      "Epoch 66/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1890 - accuracy: 0.5269\n",
      "Epoch 66: val_accuracy did not improve from 0.49655\n",
      "10/10 [==============================] - 0s 48ms/step - loss: 0.1891 - accuracy: 0.5262 - val_loss: 0.2242 - val_accuracy: 0.4069\n",
      "Epoch 67/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1925 - accuracy: 0.5304\n",
      "Epoch 67: val_accuracy did not improve from 0.49655\n",
      "10/10 [==============================] - 1s 52ms/step - loss: 0.1925 - accuracy: 0.5306 - val_loss: 0.2114 - val_accuracy: 0.4345\n",
      "Epoch 68/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1894 - accuracy: 0.5512\n",
      "Epoch 68: val_accuracy did not improve from 0.49655\n",
      "10/10 [==============================] - 1s 50ms/step - loss: 0.1894 - accuracy: 0.5505 - val_loss: 0.2348 - val_accuracy: 0.4621\n",
      "Epoch 69/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1917 - accuracy: 0.5356\n",
      "Epoch 69: val_accuracy did not improve from 0.49655\n",
      "10/10 [==============================] - 1s 52ms/step - loss: 0.1916 - accuracy: 0.5358 - val_loss: 0.2288 - val_accuracy: 0.4069\n",
      "Epoch 70/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1917 - accuracy: 0.5191\n",
      "Epoch 70: val_accuracy did not improve from 0.49655\n",
      "10/10 [==============================] - 1s 53ms/step - loss: 0.1917 - accuracy: 0.5189 - val_loss: 0.2193 - val_accuracy: 0.4759\n",
      "Epoch 71/500\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1864 - accuracy: 0.5596\n",
      "Epoch 71: val_accuracy did not improve from 0.49655\n",
      "10/10 [==============================] - 1s 52ms/step - loss: 0.1864 - accuracy: 0.5596 - val_loss: 0.2526 - val_accuracy: 0.3586\n",
      "Epoch 72/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1859 - accuracy: 0.5512\n",
      "Epoch 72: val_accuracy did not improve from 0.49655\n",
      "10/10 [==============================] - 1s 52ms/step - loss: 0.1860 - accuracy: 0.5509 - val_loss: 0.2462 - val_accuracy: 0.3862\n",
      "Epoch 73/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1873 - accuracy: 0.5534\n",
      "Epoch 73: val_accuracy did not improve from 0.49655\n",
      "10/10 [==============================] - 1s 53ms/step - loss: 0.1872 - accuracy: 0.5540 - val_loss: 0.2303 - val_accuracy: 0.4414\n",
      "Epoch 74/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1860 - accuracy: 0.5464\n",
      "Epoch 74: val_accuracy did not improve from 0.49655\n",
      "10/10 [==============================] - 1s 51ms/step - loss: 0.1860 - accuracy: 0.5462 - val_loss: 0.2376 - val_accuracy: 0.3724\n",
      "Epoch 75/500\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1878 - accuracy: 0.5431\n",
      "Epoch 75: val_accuracy did not improve from 0.49655\n",
      "10/10 [==============================] - 1s 50ms/step - loss: 0.1878 - accuracy: 0.5431 - val_loss: 0.2332 - val_accuracy: 0.4138\n",
      "Epoch 76/500\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1876 - accuracy: 0.5509\n",
      "Epoch 76: val_accuracy did not improve from 0.49655\n",
      "10/10 [==============================] - 0s 49ms/step - loss: 0.1876 - accuracy: 0.5509 - val_loss: 0.2402 - val_accuracy: 0.4552\n",
      "Epoch 77/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1873 - accuracy: 0.5477\n",
      "Epoch 77: val_accuracy did not improve from 0.49655\n",
      "10/10 [==============================] - 1s 52ms/step - loss: 0.1873 - accuracy: 0.5479 - val_loss: 0.2319 - val_accuracy: 0.4000\n",
      "Epoch 78/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1869 - accuracy: 0.5373\n",
      "Epoch 78: val_accuracy did not improve from 0.49655\n",
      "10/10 [==============================] - 1s 52ms/step - loss: 0.1870 - accuracy: 0.5366 - val_loss: 0.2236 - val_accuracy: 0.4069\n",
      "Epoch 79/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1889 - accuracy: 0.5525\n",
      "Epoch 79: val_accuracy did not improve from 0.49655\n",
      "10/10 [==============================] - 1s 51ms/step - loss: 0.1889 - accuracy: 0.5527 - val_loss: 0.2336 - val_accuracy: 0.3931\n",
      "Epoch 80/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1894 - accuracy: 0.5395\n",
      "Epoch 80: val_accuracy did not improve from 0.49655\n",
      "10/10 [==============================] - 1s 52ms/step - loss: 0.1895 - accuracy: 0.5392 - val_loss: 0.2547 - val_accuracy: 0.4345\n",
      "Epoch 81/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1917 - accuracy: 0.5247\n",
      "Epoch 81: val_accuracy did not improve from 0.49655\n",
      "10/10 [==============================] - 1s 51ms/step - loss: 0.1918 - accuracy: 0.5241 - val_loss: 0.2801 - val_accuracy: 0.3103\n",
      "Epoch 82/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1930 - accuracy: 0.5265\n",
      "Epoch 82: val_accuracy did not improve from 0.49655\n",
      "10/10 [==============================] - 1s 53ms/step - loss: 0.1932 - accuracy: 0.5258 - val_loss: 0.2602 - val_accuracy: 0.3931\n",
      "Epoch 83/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1896 - accuracy: 0.5356\n",
      "Epoch 83: val_accuracy did not improve from 0.49655\n",
      "10/10 [==============================] - 1s 52ms/step - loss: 0.1896 - accuracy: 0.5358 - val_loss: 0.2226 - val_accuracy: 0.4483\n",
      "Epoch 84/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1860 - accuracy: 0.5543\n",
      "Epoch 84: val_accuracy did not improve from 0.49655\n",
      "10/10 [==============================] - 1s 51ms/step - loss: 0.1861 - accuracy: 0.5544 - val_loss: 0.2244 - val_accuracy: 0.4483\n",
      "Epoch 85/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1872 - accuracy: 0.5516\n",
      "Epoch 85: val_accuracy did not improve from 0.49655\n",
      "10/10 [==============================] - 1s 51ms/step - loss: 0.1872 - accuracy: 0.5522 - val_loss: 0.2268 - val_accuracy: 0.4414\n",
      "Epoch 86/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1844 - accuracy: 0.5686\n",
      "Epoch 86: val_accuracy did not improve from 0.49655\n",
      "10/10 [==============================] - 1s 52ms/step - loss: 0.1844 - accuracy: 0.5683 - val_loss: 0.2338 - val_accuracy: 0.3586\n",
      "Epoch 87/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1847 - accuracy: 0.5317\n",
      "Epoch 87: val_accuracy did not improve from 0.49655\n",
      "10/10 [==============================] - 1s 51ms/step - loss: 0.1847 - accuracy: 0.5319 - val_loss: 0.2112 - val_accuracy: 0.4483\n",
      "Epoch 88/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1857 - accuracy: 0.5556\n",
      "Epoch 88: val_accuracy did not improve from 0.49655\n",
      "10/10 [==============================] - 1s 52ms/step - loss: 0.1857 - accuracy: 0.5557 - val_loss: 0.2193 - val_accuracy: 0.4966\n",
      "Epoch 89/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1846 - accuracy: 0.5530\n",
      "Epoch 89: val_accuracy did not improve from 0.49655\n",
      "10/10 [==============================] - 1s 52ms/step - loss: 0.1845 - accuracy: 0.5535 - val_loss: 0.2115 - val_accuracy: 0.4483\n",
      "Epoch 90/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1852 - accuracy: 0.5538\n",
      "Epoch 90: val_accuracy did not improve from 0.49655\n",
      "10/10 [==============================] - 1s 52ms/step - loss: 0.1852 - accuracy: 0.5540 - val_loss: 0.2050 - val_accuracy: 0.4897\n",
      "Epoch 91/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1815 - accuracy: 0.5621\n",
      "Epoch 91: val_accuracy did not improve from 0.49655\n",
      "10/10 [==============================] - 1s 51ms/step - loss: 0.1815 - accuracy: 0.5622 - val_loss: 0.2275 - val_accuracy: 0.4276\n",
      "Epoch 92/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1920 - accuracy: 0.5247\n",
      "Epoch 92: val_accuracy did not improve from 0.49655\n",
      "10/10 [==============================] - 1s 53ms/step - loss: 0.1921 - accuracy: 0.5245 - val_loss: 0.2229 - val_accuracy: 0.4069\n",
      "Epoch 93/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1926 - accuracy: 0.5343\n",
      "Epoch 93: val_accuracy did not improve from 0.49655\n",
      "10/10 [==============================] - 1s 52ms/step - loss: 0.1925 - accuracy: 0.5345 - val_loss: 0.2212 - val_accuracy: 0.4552\n",
      "Epoch 94/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1836 - accuracy: 0.5477\n",
      "Epoch 94: val_accuracy improved from 0.49655 to 0.51724, saving model to best_model_CNNLSTM.h5\n",
      "10/10 [==============================] - 1s 56ms/step - loss: 0.1835 - accuracy: 0.5479 - val_loss: 0.1980 - val_accuracy: 0.5172\n",
      "Epoch 95/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1814 - accuracy: 0.5712\n",
      "Epoch 95: val_accuracy improved from 0.51724 to 0.52414, saving model to best_model_CNNLSTM.h5\n",
      "10/10 [==============================] - 1s 55ms/step - loss: 0.1813 - accuracy: 0.5717 - val_loss: 0.1954 - val_accuracy: 0.5241\n",
      "Epoch 96/500\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1826 - accuracy: 0.5704\n",
      "Epoch 96: val_accuracy did not improve from 0.52414\n",
      "10/10 [==============================] - 0s 49ms/step - loss: 0.1826 - accuracy: 0.5704 - val_loss: 0.2124 - val_accuracy: 0.4966\n",
      "Epoch 97/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1835 - accuracy: 0.5590\n",
      "Epoch 97: val_accuracy did not improve from 0.52414\n",
      "10/10 [==============================] - 1s 50ms/step - loss: 0.1835 - accuracy: 0.5587 - val_loss: 0.1995 - val_accuracy: 0.4759\n",
      "Epoch 98/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1850 - accuracy: 0.5399\n",
      "Epoch 98: val_accuracy did not improve from 0.52414\n",
      "10/10 [==============================] - 1s 51ms/step - loss: 0.1851 - accuracy: 0.5397 - val_loss: 0.2262 - val_accuracy: 0.4207\n",
      "Epoch 99/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1856 - accuracy: 0.5608\n",
      "Epoch 99: val_accuracy did not improve from 0.52414\n",
      "10/10 [==============================] - 1s 52ms/step - loss: 0.1857 - accuracy: 0.5609 - val_loss: 0.2211 - val_accuracy: 0.4621\n",
      "Epoch 100/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1843 - accuracy: 0.5694\n",
      "Epoch 100: val_accuracy did not improve from 0.52414\n",
      "10/10 [==============================] - 1s 52ms/step - loss: 0.1842 - accuracy: 0.5696 - val_loss: 0.2215 - val_accuracy: 0.4897\n",
      "Epoch 101/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1843 - accuracy: 0.5725\n",
      "Epoch 101: val_accuracy did not improve from 0.52414\n",
      "10/10 [==============================] - 1s 52ms/step - loss: 0.1844 - accuracy: 0.5722 - val_loss: 0.2316 - val_accuracy: 0.4483\n",
      "Epoch 102/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1864 - accuracy: 0.5538\n",
      "Epoch 102: val_accuracy did not improve from 0.52414\n",
      "10/10 [==============================] - 1s 50ms/step - loss: 0.1864 - accuracy: 0.5540 - val_loss: 0.2030 - val_accuracy: 0.4759\n",
      "Epoch 103/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1839 - accuracy: 0.5664\n",
      "Epoch 103: val_accuracy did not improve from 0.52414\n",
      "10/10 [==============================] - 1s 52ms/step - loss: 0.1840 - accuracy: 0.5661 - val_loss: 0.2065 - val_accuracy: 0.5103\n",
      "Epoch 104/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1858 - accuracy: 0.5673\n",
      "Epoch 104: val_accuracy did not improve from 0.52414\n",
      "10/10 [==============================] - 1s 52ms/step - loss: 0.1860 - accuracy: 0.5665 - val_loss: 0.2172 - val_accuracy: 0.4759\n",
      "Epoch 105/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1872 - accuracy: 0.5508\n",
      "Epoch 105: val_accuracy did not improve from 0.52414\n",
      "10/10 [==============================] - 1s 51ms/step - loss: 0.1872 - accuracy: 0.5509 - val_loss: 0.2092 - val_accuracy: 0.4276\n",
      "Epoch 106/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1864 - accuracy: 0.5495\n",
      "Epoch 106: val_accuracy did not improve from 0.52414\n",
      "10/10 [==============================] - 1s 52ms/step - loss: 0.1863 - accuracy: 0.5501 - val_loss: 0.2229 - val_accuracy: 0.4276\n",
      "Epoch 107/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1861 - accuracy: 0.5660\n",
      "Epoch 107: val_accuracy did not improve from 0.52414\n",
      "10/10 [==============================] - 1s 52ms/step - loss: 0.1862 - accuracy: 0.5657 - val_loss: 0.2229 - val_accuracy: 0.4345\n",
      "Epoch 108/500\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1847 - accuracy: 0.5496\n",
      "Epoch 108: val_accuracy did not improve from 0.52414\n",
      "10/10 [==============================] - 1s 51ms/step - loss: 0.1847 - accuracy: 0.5496 - val_loss: 0.2111 - val_accuracy: 0.4690\n",
      "Epoch 109/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1838 - accuracy: 0.5434\n",
      "Epoch 109: val_accuracy did not improve from 0.52414\n",
      "10/10 [==============================] - 1s 50ms/step - loss: 0.1839 - accuracy: 0.5431 - val_loss: 0.2104 - val_accuracy: 0.4276\n",
      "Epoch 110/500\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1790 - accuracy: 0.5730\n",
      "Epoch 110: val_accuracy did not improve from 0.52414\n",
      "10/10 [==============================] - 1s 50ms/step - loss: 0.1790 - accuracy: 0.5730 - val_loss: 0.2050 - val_accuracy: 0.4759\n",
      "Epoch 111/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1844 - accuracy: 0.5651\n",
      "Epoch 111: val_accuracy did not improve from 0.52414\n",
      "10/10 [==============================] - 1s 53ms/step - loss: 0.1843 - accuracy: 0.5657 - val_loss: 0.2003 - val_accuracy: 0.4621\n",
      "Epoch 112/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1850 - accuracy: 0.5595\n",
      "Epoch 112: val_accuracy did not improve from 0.52414\n",
      "10/10 [==============================] - 1s 50ms/step - loss: 0.1850 - accuracy: 0.5596 - val_loss: 0.2253 - val_accuracy: 0.4276\n",
      "Epoch 113/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1831 - accuracy: 0.5668\n",
      "Epoch 113: val_accuracy did not improve from 0.52414\n",
      "10/10 [==============================] - 0s 50ms/step - loss: 0.1830 - accuracy: 0.5670 - val_loss: 0.2181 - val_accuracy: 0.4345\n",
      "Epoch 114/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1827 - accuracy: 0.5586\n",
      "Epoch 114: val_accuracy did not improve from 0.52414\n",
      "10/10 [==============================] - 1s 52ms/step - loss: 0.1826 - accuracy: 0.5592 - val_loss: 0.2131 - val_accuracy: 0.4345\n",
      "Epoch 115/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1813 - accuracy: 0.5655\n",
      "Epoch 115: val_accuracy did not improve from 0.52414\n",
      "10/10 [==============================] - 1s 51ms/step - loss: 0.1812 - accuracy: 0.5657 - val_loss: 0.2102 - val_accuracy: 0.5103\n",
      "Epoch 116/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1820 - accuracy: 0.5751\n",
      "Epoch 116: val_accuracy did not improve from 0.52414\n",
      "10/10 [==============================] - 1s 52ms/step - loss: 0.1820 - accuracy: 0.5752 - val_loss: 0.2174 - val_accuracy: 0.4759\n",
      "Epoch 117/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1825 - accuracy: 0.5703\n",
      "Epoch 117: val_accuracy did not improve from 0.52414\n",
      "10/10 [==============================] - 1s 51ms/step - loss: 0.1825 - accuracy: 0.5700 - val_loss: 0.2108 - val_accuracy: 0.5103\n",
      "Epoch 118/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1837 - accuracy: 0.5530\n",
      "Epoch 118: val_accuracy did not improve from 0.52414\n",
      "10/10 [==============================] - 1s 51ms/step - loss: 0.1837 - accuracy: 0.5527 - val_loss: 0.2201 - val_accuracy: 0.4897\n",
      "Epoch 119/500\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1839 - accuracy: 0.5613\n",
      "Epoch 119: val_accuracy did not improve from 0.52414\n",
      "10/10 [==============================] - 1s 52ms/step - loss: 0.1839 - accuracy: 0.5613 - val_loss: 0.2427 - val_accuracy: 0.3931\n",
      "Epoch 120/500\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1819 - accuracy: 0.5657\n",
      "Epoch 120: val_accuracy did not improve from 0.52414\n",
      "10/10 [==============================] - 1s 50ms/step - loss: 0.1819 - accuracy: 0.5657 - val_loss: 0.2269 - val_accuracy: 0.3655\n",
      "Epoch 121/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1837 - accuracy: 0.5634\n",
      "Epoch 121: val_accuracy did not improve from 0.52414\n",
      "10/10 [==============================] - 1s 52ms/step - loss: 0.1836 - accuracy: 0.5635 - val_loss: 0.2312 - val_accuracy: 0.4000\n",
      "Epoch 122/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1849 - accuracy: 0.5486\n",
      "Epoch 122: val_accuracy did not improve from 0.52414\n",
      "10/10 [==============================] - 1s 51ms/step - loss: 0.1850 - accuracy: 0.5483 - val_loss: 0.2275 - val_accuracy: 0.3724\n",
      "Epoch 123/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1844 - accuracy: 0.5503\n",
      "Epoch 123: val_accuracy did not improve from 0.52414\n",
      "10/10 [==============================] - 1s 52ms/step - loss: 0.1845 - accuracy: 0.5501 - val_loss: 0.2122 - val_accuracy: 0.4828\n",
      "Epoch 124/500\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1863 - accuracy: 0.5496\n",
      "Epoch 124: val_accuracy did not improve from 0.52414\n",
      "10/10 [==============================] - 1s 51ms/step - loss: 0.1863 - accuracy: 0.5496 - val_loss: 0.2386 - val_accuracy: 0.4276\n",
      "Epoch 125/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1878 - accuracy: 0.5469\n",
      "Epoch 125: val_accuracy did not improve from 0.52414\n",
      "10/10 [==============================] - 1s 53ms/step - loss: 0.1878 - accuracy: 0.5470 - val_loss: 0.2111 - val_accuracy: 0.4552\n",
      "Epoch 126/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1878 - accuracy: 0.5569\n",
      "Epoch 126: val_accuracy did not improve from 0.52414\n",
      "10/10 [==============================] - 1s 52ms/step - loss: 0.1877 - accuracy: 0.5570 - val_loss: 0.2183 - val_accuracy: 0.5103\n",
      "Epoch 127/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1830 - accuracy: 0.5612\n",
      "Epoch 127: val_accuracy did not improve from 0.52414\n",
      "10/10 [==============================] - 1s 52ms/step - loss: 0.1831 - accuracy: 0.5609 - val_loss: 0.2182 - val_accuracy: 0.4966\n",
      "Epoch 128/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1854 - accuracy: 0.5564\n",
      "Epoch 128: val_accuracy did not improve from 0.52414\n",
      "10/10 [==============================] - 1s 53ms/step - loss: 0.1854 - accuracy: 0.5557 - val_loss: 0.2103 - val_accuracy: 0.4966\n",
      "Epoch 129/500\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1899 - accuracy: 0.5275\n",
      "Epoch 129: val_accuracy did not improve from 0.52414\n",
      "10/10 [==============================] - 1s 51ms/step - loss: 0.1899 - accuracy: 0.5275 - val_loss: 0.2249 - val_accuracy: 0.4621\n",
      "Epoch 130/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1859 - accuracy: 0.5395\n",
      "Epoch 130: val_accuracy did not improve from 0.52414\n",
      "10/10 [==============================] - 1s 52ms/step - loss: 0.1859 - accuracy: 0.5397 - val_loss: 0.2204 - val_accuracy: 0.4414\n",
      "Epoch 131/500\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1840 - accuracy: 0.5600\n",
      "Epoch 131: val_accuracy did not improve from 0.52414\n",
      "10/10 [==============================] - 0s 49ms/step - loss: 0.1840 - accuracy: 0.5600 - val_loss: 0.2290 - val_accuracy: 0.4621\n",
      "Epoch 132/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1812 - accuracy: 0.5625\n",
      "Epoch 132: val_accuracy did not improve from 0.52414\n",
      "10/10 [==============================] - 1s 52ms/step - loss: 0.1813 - accuracy: 0.5618 - val_loss: 0.2212 - val_accuracy: 0.4552\n",
      "Epoch 133/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1872 - accuracy: 0.5382\n",
      "Epoch 133: val_accuracy did not improve from 0.52414\n",
      "10/10 [==============================] - 1s 52ms/step - loss: 0.1873 - accuracy: 0.5379 - val_loss: 0.2236 - val_accuracy: 0.4897\n",
      "Epoch 134/500\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1872 - accuracy: 0.5535\n",
      "Epoch 134: val_accuracy did not improve from 0.52414\n",
      "10/10 [==============================] - 1s 52ms/step - loss: 0.1872 - accuracy: 0.5535 - val_loss: 0.2247 - val_accuracy: 0.4897\n",
      "Epoch 135/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1867 - accuracy: 0.5417\n",
      "Epoch 135: val_accuracy did not improve from 0.52414\n",
      "10/10 [==============================] - 1s 52ms/step - loss: 0.1867 - accuracy: 0.5414 - val_loss: 0.2154 - val_accuracy: 0.4828\n",
      "Epoch 136/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1869 - accuracy: 0.5404\n",
      "Epoch 136: val_accuracy did not improve from 0.52414\n",
      "10/10 [==============================] - 1s 52ms/step - loss: 0.1870 - accuracy: 0.5401 - val_loss: 0.2067 - val_accuracy: 0.5103\n",
      "Epoch 137/500\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1833 - accuracy: 0.5561\n",
      "Epoch 137: val_accuracy did not improve from 0.52414\n",
      "10/10 [==============================] - 1s 51ms/step - loss: 0.1833 - accuracy: 0.5561 - val_loss: 0.2245 - val_accuracy: 0.5172\n",
      "Epoch 138/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1840 - accuracy: 0.5516\n",
      "Epoch 138: val_accuracy did not improve from 0.52414\n",
      "10/10 [==============================] - 1s 51ms/step - loss: 0.1839 - accuracy: 0.5518 - val_loss: 0.2273 - val_accuracy: 0.4966\n",
      "Epoch 139/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1821 - accuracy: 0.5747\n",
      "Epoch 139: val_accuracy did not improve from 0.52414\n",
      "10/10 [==============================] - 1s 52ms/step - loss: 0.1823 - accuracy: 0.5743 - val_loss: 0.2300 - val_accuracy: 0.4552\n",
      "Epoch 140/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1839 - accuracy: 0.5621\n",
      "Epoch 140: val_accuracy did not improve from 0.52414\n",
      "10/10 [==============================] - 1s 53ms/step - loss: 0.1838 - accuracy: 0.5622 - val_loss: 0.2224 - val_accuracy: 0.4069\n",
      "Epoch 141/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1825 - accuracy: 0.5512\n",
      "Epoch 141: val_accuracy did not improve from 0.52414\n",
      "10/10 [==============================] - 1s 51ms/step - loss: 0.1826 - accuracy: 0.5505 - val_loss: 0.2148 - val_accuracy: 0.4207\n",
      "Epoch 142/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1873 - accuracy: 0.5269\n",
      "Epoch 142: val_accuracy did not improve from 0.52414\n",
      "10/10 [==============================] - 1s 52ms/step - loss: 0.1874 - accuracy: 0.5262 - val_loss: 0.2023 - val_accuracy: 0.4414\n",
      "Epoch 143/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1851 - accuracy: 0.5612\n",
      "Epoch 143: val_accuracy did not improve from 0.52414\n",
      "10/10 [==============================] - 1s 52ms/step - loss: 0.1852 - accuracy: 0.5613 - val_loss: 0.2130 - val_accuracy: 0.4552\n",
      "Epoch 144/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1819 - accuracy: 0.5638\n",
      "Epoch 144: val_accuracy did not improve from 0.52414\n",
      "10/10 [==============================] - 1s 53ms/step - loss: 0.1820 - accuracy: 0.5635 - val_loss: 0.1998 - val_accuracy: 0.4966\n",
      "Epoch 145/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1798 - accuracy: 0.5720\n",
      "Epoch 145: val_accuracy did not improve from 0.52414\n",
      "10/10 [==============================] - 1s 53ms/step - loss: 0.1800 - accuracy: 0.5713 - val_loss: 0.1998 - val_accuracy: 0.5103\n",
      "Epoch 1/500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-08 23:32:24.351356: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape insequential_3/dropout_6/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.2289 - accuracy: 0.3338\n",
      "Epoch 1: val_accuracy improved from -inf to 0.34815, saving model to best_model_CNNLSTM.h5\n",
      "10/10 [==============================] - 2s 70ms/step - loss: 0.2288 - accuracy: 0.3341 - val_loss: 0.2224 - val_accuracy: 0.3481\n",
      "Epoch 2/500\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2206 - accuracy: 0.3858\n",
      "Epoch 2: val_accuracy did not improve from 0.34815\n",
      "10/10 [==============================] - 1s 51ms/step - loss: 0.2206 - accuracy: 0.3858 - val_loss: 0.2220 - val_accuracy: 0.3481\n",
      "Epoch 3/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.2156 - accuracy: 0.4201\n",
      "Epoch 3: val_accuracy did not improve from 0.34815\n",
      "10/10 [==============================] - 1s 53ms/step - loss: 0.2158 - accuracy: 0.4195 - val_loss: 0.2220 - val_accuracy: 0.3185\n",
      "Epoch 4/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.2122 - accuracy: 0.4497\n",
      "Epoch 4: val_accuracy did not improve from 0.34815\n",
      "10/10 [==============================] - 1s 52ms/step - loss: 0.2120 - accuracy: 0.4510 - val_loss: 0.2225 - val_accuracy: 0.3259\n",
      "Epoch 5/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.2089 - accuracy: 0.4688\n",
      "Epoch 5: val_accuracy did not improve from 0.34815\n",
      "10/10 [==============================] - 1s 51ms/step - loss: 0.2089 - accuracy: 0.4691 - val_loss: 0.2224 - val_accuracy: 0.3185\n",
      "Epoch 6/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.2080 - accuracy: 0.4766\n",
      "Epoch 6: val_accuracy did not improve from 0.34815\n",
      "10/10 [==============================] - 0s 49ms/step - loss: 0.2079 - accuracy: 0.4769 - val_loss: 0.2223 - val_accuracy: 0.3259\n",
      "Epoch 7/500\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2062 - accuracy: 0.4735\n",
      "Epoch 7: val_accuracy did not improve from 0.34815\n",
      "10/10 [==============================] - 1s 50ms/step - loss: 0.2062 - accuracy: 0.4735 - val_loss: 0.2220 - val_accuracy: 0.3111\n",
      "Epoch 8/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.2070 - accuracy: 0.4566\n",
      "Epoch 8: val_accuracy improved from 0.34815 to 0.36296, saving model to best_model_CNNLSTM.h5\n",
      "10/10 [==============================] - 1s 53ms/step - loss: 0.2071 - accuracy: 0.4562 - val_loss: 0.2231 - val_accuracy: 0.3630\n",
      "Epoch 9/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.2051 - accuracy: 0.4887\n",
      "Epoch 9: val_accuracy did not improve from 0.36296\n",
      "10/10 [==============================] - 1s 52ms/step - loss: 0.2052 - accuracy: 0.4873 - val_loss: 0.2236 - val_accuracy: 0.3259\n",
      "Epoch 10/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.2034 - accuracy: 0.4944\n",
      "Epoch 10: val_accuracy did not improve from 0.36296\n",
      "10/10 [==============================] - 1s 50ms/step - loss: 0.2034 - accuracy: 0.4942 - val_loss: 0.2246 - val_accuracy: 0.3259\n",
      "Epoch 11/500\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2021 - accuracy: 0.5019\n",
      "Epoch 11: val_accuracy did not improve from 0.36296\n",
      "10/10 [==============================] - 1s 52ms/step - loss: 0.2021 - accuracy: 0.5019 - val_loss: 0.2240 - val_accuracy: 0.3333\n",
      "Epoch 12/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1991 - accuracy: 0.5117\n",
      "Epoch 12: val_accuracy did not improve from 0.36296\n",
      "10/10 [==============================] - 1s 52ms/step - loss: 0.1991 - accuracy: 0.5119 - val_loss: 0.2224 - val_accuracy: 0.3407\n",
      "Epoch 13/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.2005 - accuracy: 0.5178\n",
      "Epoch 13: val_accuracy did not improve from 0.36296\n",
      "10/10 [==============================] - 1s 51ms/step - loss: 0.2006 - accuracy: 0.5175 - val_loss: 0.2222 - val_accuracy: 0.3556\n",
      "Epoch 14/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1979 - accuracy: 0.5326\n",
      "Epoch 14: val_accuracy improved from 0.36296 to 0.37037, saving model to best_model_CNNLSTM.h5\n",
      "10/10 [==============================] - 1s 55ms/step - loss: 0.1979 - accuracy: 0.5322 - val_loss: 0.2223 - val_accuracy: 0.3704\n",
      "Epoch 15/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1923 - accuracy: 0.5512\n",
      "Epoch 15: val_accuracy did not improve from 0.37037\n",
      "10/10 [==============================] - 1s 51ms/step - loss: 0.1926 - accuracy: 0.5494 - val_loss: 0.2224 - val_accuracy: 0.3333\n",
      "Epoch 16/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1924 - accuracy: 0.5486\n",
      "Epoch 16: val_accuracy did not improve from 0.37037\n",
      "10/10 [==============================] - 1s 51ms/step - loss: 0.1925 - accuracy: 0.5481 - val_loss: 0.2223 - val_accuracy: 0.2963\n",
      "Epoch 17/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1909 - accuracy: 0.5469\n",
      "Epoch 17: val_accuracy improved from 0.37037 to 0.37778, saving model to best_model_CNNLSTM.h5\n",
      "10/10 [==============================] - 1s 55ms/step - loss: 0.1907 - accuracy: 0.5477 - val_loss: 0.2213 - val_accuracy: 0.3778\n",
      "Epoch 18/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1888 - accuracy: 0.5477\n",
      "Epoch 18: val_accuracy did not improve from 0.37778\n",
      "10/10 [==============================] - 1s 52ms/step - loss: 0.1890 - accuracy: 0.5477 - val_loss: 0.2231 - val_accuracy: 0.2963\n",
      "Epoch 19/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1892 - accuracy: 0.5551\n",
      "Epoch 19: val_accuracy did not improve from 0.37778\n",
      "10/10 [==============================] - 1s 51ms/step - loss: 0.1891 - accuracy: 0.5550 - val_loss: 0.2234 - val_accuracy: 0.2889\n",
      "Epoch 20/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1911 - accuracy: 0.5395\n",
      "Epoch 20: val_accuracy did not improve from 0.37778\n",
      "10/10 [==============================] - 1s 50ms/step - loss: 0.1914 - accuracy: 0.5386 - val_loss: 0.2225 - val_accuracy: 0.3111\n",
      "Epoch 21/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1881 - accuracy: 0.5569\n",
      "Epoch 21: val_accuracy did not improve from 0.37778\n",
      "10/10 [==============================] - 1s 52ms/step - loss: 0.1882 - accuracy: 0.5550 - val_loss: 0.2276 - val_accuracy: 0.3111\n",
      "Epoch 22/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1920 - accuracy: 0.5404\n",
      "Epoch 22: val_accuracy did not improve from 0.37778\n",
      "10/10 [==============================] - 1s 51ms/step - loss: 0.1919 - accuracy: 0.5412 - val_loss: 0.2257 - val_accuracy: 0.3111\n",
      "Epoch 23/500\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1911 - accuracy: 0.5468\n",
      "Epoch 23: val_accuracy did not improve from 0.37778\n",
      "10/10 [==============================] - 1s 51ms/step - loss: 0.1911 - accuracy: 0.5468 - val_loss: 0.2231 - val_accuracy: 0.3556\n",
      "Epoch 24/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1871 - accuracy: 0.5560\n",
      "Epoch 24: val_accuracy did not improve from 0.37778\n",
      "10/10 [==============================] - 1s 51ms/step - loss: 0.1874 - accuracy: 0.5550 - val_loss: 0.2216 - val_accuracy: 0.3630\n",
      "Epoch 25/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1851 - accuracy: 0.5655\n",
      "Epoch 25: val_accuracy did not improve from 0.37778\n",
      "10/10 [==============================] - 1s 51ms/step - loss: 0.1852 - accuracy: 0.5645 - val_loss: 0.2231 - val_accuracy: 0.3037\n",
      "Epoch 26/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1817 - accuracy: 0.5833\n",
      "Epoch 26: val_accuracy did not improve from 0.37778\n",
      "10/10 [==============================] - 1s 51ms/step - loss: 0.1819 - accuracy: 0.5827 - val_loss: 0.2306 - val_accuracy: 0.3407\n",
      "Epoch 27/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1854 - accuracy: 0.5577\n",
      "Epoch 27: val_accuracy did not improve from 0.37778\n",
      "10/10 [==============================] - 1s 51ms/step - loss: 0.1852 - accuracy: 0.5589 - val_loss: 0.2236 - val_accuracy: 0.3481\n",
      "Epoch 28/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1848 - accuracy: 0.5577\n",
      "Epoch 28: val_accuracy did not improve from 0.37778\n",
      "10/10 [==============================] - 1s 52ms/step - loss: 0.1850 - accuracy: 0.5568 - val_loss: 0.2305 - val_accuracy: 0.3481\n",
      "Epoch 29/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1847 - accuracy: 0.5577\n",
      "Epoch 29: val_accuracy did not improve from 0.37778\n",
      "10/10 [==============================] - 1s 52ms/step - loss: 0.1847 - accuracy: 0.5576 - val_loss: 0.2323 - val_accuracy: 0.2963\n",
      "Epoch 30/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1849 - accuracy: 0.5647\n",
      "Epoch 30: val_accuracy did not improve from 0.37778\n",
      "10/10 [==============================] - 1s 52ms/step - loss: 0.1851 - accuracy: 0.5641 - val_loss: 0.2236 - val_accuracy: 0.3259\n",
      "Epoch 31/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1852 - accuracy: 0.5551\n",
      "Epoch 31: val_accuracy did not improve from 0.37778\n",
      "10/10 [==============================] - 1s 52ms/step - loss: 0.1851 - accuracy: 0.5555 - val_loss: 0.2220 - val_accuracy: 0.3259\n",
      "Epoch 32/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1834 - accuracy: 0.5642\n",
      "Epoch 32: val_accuracy improved from 0.37778 to 0.40741, saving model to best_model_CNNLSTM.h5\n",
      "10/10 [==============================] - 1s 54ms/step - loss: 0.1832 - accuracy: 0.5650 - val_loss: 0.2199 - val_accuracy: 0.4074\n",
      "Epoch 33/500\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1830 - accuracy: 0.5615\n",
      "Epoch 33: val_accuracy improved from 0.40741 to 0.43704, saving model to best_model_CNNLSTM.h5\n",
      "10/10 [==============================] - 1s 54ms/step - loss: 0.1830 - accuracy: 0.5615 - val_loss: 0.2176 - val_accuracy: 0.4370\n",
      "Epoch 34/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1876 - accuracy: 0.5460\n",
      "Epoch 34: val_accuracy did not improve from 0.43704\n",
      "10/10 [==============================] - 1s 51ms/step - loss: 0.1875 - accuracy: 0.5468 - val_loss: 0.2221 - val_accuracy: 0.3778\n",
      "Epoch 35/500\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1846 - accuracy: 0.5710\n",
      "Epoch 35: val_accuracy did not improve from 0.43704\n",
      "10/10 [==============================] - 0s 49ms/step - loss: 0.1846 - accuracy: 0.5710 - val_loss: 0.2165 - val_accuracy: 0.4148\n",
      "Epoch 36/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1824 - accuracy: 0.5764\n",
      "Epoch 36: val_accuracy did not improve from 0.43704\n",
      "10/10 [==============================] - 1s 52ms/step - loss: 0.1826 - accuracy: 0.5757 - val_loss: 0.2166 - val_accuracy: 0.4222\n",
      "Epoch 37/500\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1836 - accuracy: 0.5693\n",
      "Epoch 37: val_accuracy did not improve from 0.43704\n",
      "10/10 [==============================] - 1s 50ms/step - loss: 0.1836 - accuracy: 0.5693 - val_loss: 0.2160 - val_accuracy: 0.4074\n",
      "Epoch 38/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1832 - accuracy: 0.5764\n",
      "Epoch 38: val_accuracy did not improve from 0.43704\n",
      "10/10 [==============================] - 0s 49ms/step - loss: 0.1833 - accuracy: 0.5762 - val_loss: 0.2200 - val_accuracy: 0.3630\n",
      "Epoch 39/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1826 - accuracy: 0.5716\n",
      "Epoch 39: val_accuracy did not improve from 0.43704\n",
      "10/10 [==============================] - 0s 49ms/step - loss: 0.1825 - accuracy: 0.5714 - val_loss: 0.2188 - val_accuracy: 0.3630\n",
      "Epoch 40/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1798 - accuracy: 0.5907\n",
      "Epoch 40: val_accuracy did not improve from 0.43704\n",
      "10/10 [==============================] - 1s 51ms/step - loss: 0.1800 - accuracy: 0.5896 - val_loss: 0.2171 - val_accuracy: 0.3778\n",
      "Epoch 41/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1827 - accuracy: 0.5590\n",
      "Epoch 41: val_accuracy did not improve from 0.43704\n",
      "10/10 [==============================] - 1s 52ms/step - loss: 0.1825 - accuracy: 0.5598 - val_loss: 0.2153 - val_accuracy: 0.4370\n",
      "Epoch 42/500\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1815 - accuracy: 0.5757\n",
      "Epoch 42: val_accuracy improved from 0.43704 to 0.48148, saving model to best_model_CNNLSTM.h5\n",
      "10/10 [==============================] - 1s 52ms/step - loss: 0.1815 - accuracy: 0.5757 - val_loss: 0.2115 - val_accuracy: 0.4815\n",
      "Epoch 43/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1810 - accuracy: 0.5729\n",
      "Epoch 43: val_accuracy did not improve from 0.48148\n",
      "10/10 [==============================] - 0s 49ms/step - loss: 0.1812 - accuracy: 0.5727 - val_loss: 0.2199 - val_accuracy: 0.4000\n",
      "Epoch 44/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1826 - accuracy: 0.5812\n",
      "Epoch 44: val_accuracy did not improve from 0.48148\n",
      "10/10 [==============================] - 1s 51ms/step - loss: 0.1823 - accuracy: 0.5822 - val_loss: 0.2180 - val_accuracy: 0.3926\n",
      "Epoch 45/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1806 - accuracy: 0.5781\n",
      "Epoch 45: val_accuracy did not improve from 0.48148\n",
      "10/10 [==============================] - 1s 52ms/step - loss: 0.1808 - accuracy: 0.5775 - val_loss: 0.2163 - val_accuracy: 0.3852\n",
      "Epoch 46/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1792 - accuracy: 0.5968\n",
      "Epoch 46: val_accuracy did not improve from 0.48148\n",
      "10/10 [==============================] - 1s 52ms/step - loss: 0.1792 - accuracy: 0.5973 - val_loss: 0.2111 - val_accuracy: 0.4741\n",
      "Epoch 47/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1784 - accuracy: 0.5877\n",
      "Epoch 47: val_accuracy did not improve from 0.48148\n",
      "10/10 [==============================] - 1s 51ms/step - loss: 0.1786 - accuracy: 0.5865 - val_loss: 0.2180 - val_accuracy: 0.4370\n",
      "Epoch 48/500\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1796 - accuracy: 0.5809\n",
      "Epoch 48: val_accuracy improved from 0.48148 to 0.49630, saving model to best_model_CNNLSTM.h5\n",
      "10/10 [==============================] - 1s 54ms/step - loss: 0.1796 - accuracy: 0.5809 - val_loss: 0.2127 - val_accuracy: 0.4963\n",
      "Epoch 49/500\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1798 - accuracy: 0.5956\n",
      "Epoch 49: val_accuracy did not improve from 0.49630\n",
      "10/10 [==============================] - 0s 50ms/step - loss: 0.1798 - accuracy: 0.5956 - val_loss: 0.2106 - val_accuracy: 0.4741\n",
      "Epoch 50/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1811 - accuracy: 0.5773\n",
      "Epoch 50: val_accuracy did not improve from 0.49630\n",
      "10/10 [==============================] - 1s 52ms/step - loss: 0.1814 - accuracy: 0.5766 - val_loss: 0.2208 - val_accuracy: 0.4074\n",
      "Epoch 51/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1819 - accuracy: 0.5703\n",
      "Epoch 51: val_accuracy did not improve from 0.49630\n",
      "10/10 [==============================] - 0s 49ms/step - loss: 0.1821 - accuracy: 0.5697 - val_loss: 0.2120 - val_accuracy: 0.4148\n",
      "Epoch 52/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1827 - accuracy: 0.5694\n",
      "Epoch 52: val_accuracy did not improve from 0.49630\n",
      "10/10 [==============================] - 1s 50ms/step - loss: 0.1827 - accuracy: 0.5693 - val_loss: 0.2166 - val_accuracy: 0.4000\n",
      "Epoch 53/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1813 - accuracy: 0.5729\n",
      "Epoch 53: val_accuracy did not improve from 0.49630\n",
      "10/10 [==============================] - 0s 50ms/step - loss: 0.1812 - accuracy: 0.5727 - val_loss: 0.2119 - val_accuracy: 0.4444\n",
      "Epoch 54/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1796 - accuracy: 0.5764\n",
      "Epoch 54: val_accuracy did not improve from 0.49630\n",
      "10/10 [==============================] - 0s 49ms/step - loss: 0.1798 - accuracy: 0.5757 - val_loss: 0.2182 - val_accuracy: 0.4519\n",
      "Epoch 55/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1820 - accuracy: 0.5634\n",
      "Epoch 55: val_accuracy did not improve from 0.49630\n",
      "10/10 [==============================] - 1s 53ms/step - loss: 0.1817 - accuracy: 0.5654 - val_loss: 0.2231 - val_accuracy: 0.4296\n",
      "Epoch 56/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1839 - accuracy: 0.5738\n",
      "Epoch 56: val_accuracy did not improve from 0.49630\n",
      "10/10 [==============================] - 1s 51ms/step - loss: 0.1836 - accuracy: 0.5749 - val_loss: 0.2077 - val_accuracy: 0.4889\n",
      "Epoch 57/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1803 - accuracy: 0.5755\n",
      "Epoch 57: val_accuracy did not improve from 0.49630\n",
      "10/10 [==============================] - 1s 51ms/step - loss: 0.1801 - accuracy: 0.5762 - val_loss: 0.2138 - val_accuracy: 0.3926\n",
      "Epoch 58/500\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1805 - accuracy: 0.5805\n",
      "Epoch 58: val_accuracy did not improve from 0.49630\n",
      "10/10 [==============================] - 1s 50ms/step - loss: 0.1805 - accuracy: 0.5805 - val_loss: 0.2084 - val_accuracy: 0.4815\n",
      "Epoch 59/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1784 - accuracy: 0.5877\n",
      "Epoch 59: val_accuracy did not improve from 0.49630\n",
      "10/10 [==============================] - 0s 49ms/step - loss: 0.1784 - accuracy: 0.5874 - val_loss: 0.2201 - val_accuracy: 0.4593\n",
      "Epoch 60/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1796 - accuracy: 0.5734\n",
      "Epoch 60: val_accuracy did not improve from 0.49630\n",
      "10/10 [==============================] - 1s 51ms/step - loss: 0.1798 - accuracy: 0.5732 - val_loss: 0.2175 - val_accuracy: 0.4296\n",
      "Epoch 61/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1796 - accuracy: 0.5924\n",
      "Epoch 61: val_accuracy did not improve from 0.49630\n",
      "10/10 [==============================] - 1s 51ms/step - loss: 0.1796 - accuracy: 0.5921 - val_loss: 0.2154 - val_accuracy: 0.4667\n",
      "Epoch 62/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1790 - accuracy: 0.5885\n",
      "Epoch 62: val_accuracy did not improve from 0.49630\n",
      "10/10 [==============================] - 1s 51ms/step - loss: 0.1792 - accuracy: 0.5874 - val_loss: 0.2160 - val_accuracy: 0.4370\n",
      "Epoch 63/500\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1802 - accuracy: 0.5792\n",
      "Epoch 63: val_accuracy did not improve from 0.49630\n",
      "10/10 [==============================] - 1s 51ms/step - loss: 0.1802 - accuracy: 0.5792 - val_loss: 0.2276 - val_accuracy: 0.4296\n",
      "Epoch 64/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1798 - accuracy: 0.5816\n",
      "Epoch 64: val_accuracy did not improve from 0.49630\n",
      "10/10 [==============================] - 1s 52ms/step - loss: 0.1800 - accuracy: 0.5818 - val_loss: 0.2169 - val_accuracy: 0.3852\n",
      "Epoch 65/500\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1797 - accuracy: 0.5740\n",
      "Epoch 65: val_accuracy did not improve from 0.49630\n",
      "10/10 [==============================] - 0s 50ms/step - loss: 0.1797 - accuracy: 0.5740 - val_loss: 0.2276 - val_accuracy: 0.4815\n",
      "Epoch 66/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1818 - accuracy: 0.5881\n",
      "Epoch 66: val_accuracy did not improve from 0.49630\n",
      "10/10 [==============================] - 1s 50ms/step - loss: 0.1823 - accuracy: 0.5865 - val_loss: 0.2113 - val_accuracy: 0.4444\n",
      "Epoch 67/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1837 - accuracy: 0.5560\n",
      "Epoch 67: val_accuracy did not improve from 0.49630\n",
      "10/10 [==============================] - 0s 50ms/step - loss: 0.1837 - accuracy: 0.5559 - val_loss: 0.2195 - val_accuracy: 0.4074\n",
      "Epoch 68/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1808 - accuracy: 0.5803\n",
      "Epoch 68: val_accuracy did not improve from 0.49630\n",
      "10/10 [==============================] - 1s 51ms/step - loss: 0.1806 - accuracy: 0.5809 - val_loss: 0.2186 - val_accuracy: 0.4370\n",
      "Epoch 69/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1790 - accuracy: 0.5820\n",
      "Epoch 69: val_accuracy did not improve from 0.49630\n",
      "10/10 [==============================] - 1s 51ms/step - loss: 0.1793 - accuracy: 0.5822 - val_loss: 0.2209 - val_accuracy: 0.3630\n",
      "Epoch 70/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1791 - accuracy: 0.5838\n",
      "Epoch 70: val_accuracy did not improve from 0.49630\n",
      "10/10 [==============================] - 1s 53ms/step - loss: 0.1792 - accuracy: 0.5831 - val_loss: 0.2156 - val_accuracy: 0.4741\n",
      "Epoch 71/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1807 - accuracy: 0.5651\n",
      "Epoch 71: val_accuracy did not improve from 0.49630\n",
      "10/10 [==============================] - 0s 49ms/step - loss: 0.1809 - accuracy: 0.5641 - val_loss: 0.2103 - val_accuracy: 0.4296\n",
      "Epoch 72/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1798 - accuracy: 0.5712\n",
      "Epoch 72: val_accuracy did not improve from 0.49630\n",
      "10/10 [==============================] - 1s 50ms/step - loss: 0.1800 - accuracy: 0.5701 - val_loss: 0.2174 - val_accuracy: 0.4222\n",
      "Epoch 73/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1763 - accuracy: 0.5968\n",
      "Epoch 73: val_accuracy did not improve from 0.49630\n",
      "10/10 [==============================] - 1s 52ms/step - loss: 0.1764 - accuracy: 0.5960 - val_loss: 0.2096 - val_accuracy: 0.4889\n",
      "Epoch 74/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1763 - accuracy: 0.5959\n",
      "Epoch 74: val_accuracy did not improve from 0.49630\n",
      "10/10 [==============================] - 1s 51ms/step - loss: 0.1766 - accuracy: 0.5943 - val_loss: 0.2205 - val_accuracy: 0.4296\n",
      "Epoch 75/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1769 - accuracy: 0.5933\n",
      "Epoch 75: val_accuracy did not improve from 0.49630\n",
      "10/10 [==============================] - 1s 53ms/step - loss: 0.1768 - accuracy: 0.5930 - val_loss: 0.2271 - val_accuracy: 0.4296\n",
      "Epoch 76/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1766 - accuracy: 0.5920\n",
      "Epoch 76: val_accuracy did not improve from 0.49630\n",
      "10/10 [==============================] - 1s 52ms/step - loss: 0.1766 - accuracy: 0.5921 - val_loss: 0.2197 - val_accuracy: 0.4074\n",
      "Epoch 77/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1758 - accuracy: 0.5764\n",
      "Epoch 77: val_accuracy did not improve from 0.49630\n",
      "10/10 [==============================] - 1s 50ms/step - loss: 0.1760 - accuracy: 0.5749 - val_loss: 0.2140 - val_accuracy: 0.4370\n",
      "Epoch 78/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1768 - accuracy: 0.5760\n",
      "Epoch 78: val_accuracy did not improve from 0.49630\n",
      "10/10 [==============================] - 0s 47ms/step - loss: 0.1769 - accuracy: 0.5766 - val_loss: 0.2270 - val_accuracy: 0.4148\n",
      "Epoch 79/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1775 - accuracy: 0.5890\n",
      "Epoch 79: val_accuracy did not improve from 0.49630\n",
      "10/10 [==============================] - 1s 51ms/step - loss: 0.1777 - accuracy: 0.5883 - val_loss: 0.2211 - val_accuracy: 0.4889\n",
      "Epoch 80/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1805 - accuracy: 0.5803\n",
      "Epoch 80: val_accuracy did not improve from 0.49630\n",
      "10/10 [==============================] - 1s 50ms/step - loss: 0.1807 - accuracy: 0.5801 - val_loss: 0.2200 - val_accuracy: 0.4815\n",
      "Epoch 81/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1791 - accuracy: 0.5777\n",
      "Epoch 81: val_accuracy did not improve from 0.49630\n",
      "10/10 [==============================] - 1s 51ms/step - loss: 0.1791 - accuracy: 0.5775 - val_loss: 0.2182 - val_accuracy: 0.4000\n",
      "Epoch 82/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1773 - accuracy: 0.5864\n",
      "Epoch 82: val_accuracy improved from 0.49630 to 0.51111, saving model to best_model_CNNLSTM.h5\n",
      "10/10 [==============================] - 1s 54ms/step - loss: 0.1772 - accuracy: 0.5874 - val_loss: 0.2159 - val_accuracy: 0.5111\n",
      "Epoch 83/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1756 - accuracy: 0.5911\n",
      "Epoch 83: val_accuracy did not improve from 0.51111\n",
      "10/10 [==============================] - 1s 51ms/step - loss: 0.1754 - accuracy: 0.5917 - val_loss: 0.2087 - val_accuracy: 0.4889\n",
      "Epoch 84/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1777 - accuracy: 0.5781\n",
      "Epoch 84: val_accuracy did not improve from 0.51111\n",
      "10/10 [==============================] - 1s 52ms/step - loss: 0.1780 - accuracy: 0.5770 - val_loss: 0.2150 - val_accuracy: 0.4370\n",
      "Epoch 85/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1767 - accuracy: 0.5951\n",
      "Epoch 85: val_accuracy did not improve from 0.51111\n",
      "10/10 [==============================] - 1s 52ms/step - loss: 0.1766 - accuracy: 0.5947 - val_loss: 0.2125 - val_accuracy: 0.4296\n",
      "Epoch 86/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1745 - accuracy: 0.5977\n",
      "Epoch 86: val_accuracy did not improve from 0.51111\n",
      "10/10 [==============================] - 1s 51ms/step - loss: 0.1746 - accuracy: 0.5965 - val_loss: 0.2139 - val_accuracy: 0.4815\n",
      "Epoch 87/500\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1764 - accuracy: 0.5995\n",
      "Epoch 87: val_accuracy did not improve from 0.51111\n",
      "10/10 [==============================] - 0s 49ms/step - loss: 0.1764 - accuracy: 0.5995 - val_loss: 0.2123 - val_accuracy: 0.4741\n",
      "Epoch 88/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1724 - accuracy: 0.6033\n",
      "Epoch 88: val_accuracy did not improve from 0.51111\n",
      "10/10 [==============================] - 0s 49ms/step - loss: 0.1727 - accuracy: 0.6021 - val_loss: 0.2102 - val_accuracy: 0.4667\n",
      "Epoch 89/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1748 - accuracy: 0.5977\n",
      "Epoch 89: val_accuracy did not improve from 0.51111\n",
      "10/10 [==============================] - 1s 51ms/step - loss: 0.1747 - accuracy: 0.5982 - val_loss: 0.2267 - val_accuracy: 0.3333\n",
      "Epoch 90/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1755 - accuracy: 0.5890\n",
      "Epoch 90: val_accuracy did not improve from 0.51111\n",
      "10/10 [==============================] - 1s 52ms/step - loss: 0.1755 - accuracy: 0.5887 - val_loss: 0.2180 - val_accuracy: 0.3778\n",
      "Epoch 91/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1756 - accuracy: 0.5959\n",
      "Epoch 91: val_accuracy did not improve from 0.51111\n",
      "10/10 [==============================] - 1s 53ms/step - loss: 0.1756 - accuracy: 0.5960 - val_loss: 0.2255 - val_accuracy: 0.3926\n",
      "Epoch 92/500\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1771 - accuracy: 0.5952\n",
      "Epoch 92: val_accuracy did not improve from 0.51111\n",
      "10/10 [==============================] - 1s 49ms/step - loss: 0.1771 - accuracy: 0.5952 - val_loss: 0.2135 - val_accuracy: 0.4519\n",
      "Epoch 93/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1721 - accuracy: 0.5920\n",
      "Epoch 93: val_accuracy did not improve from 0.51111\n",
      "10/10 [==============================] - 1s 50ms/step - loss: 0.1721 - accuracy: 0.5913 - val_loss: 0.2236 - val_accuracy: 0.4519\n",
      "Epoch 94/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1716 - accuracy: 0.5938\n",
      "Epoch 94: val_accuracy did not improve from 0.51111\n",
      "10/10 [==============================] - 1s 50ms/step - loss: 0.1715 - accuracy: 0.5952 - val_loss: 0.2224 - val_accuracy: 0.4444\n",
      "Epoch 95/500\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1730 - accuracy: 0.5939\n",
      "Epoch 95: val_accuracy did not improve from 0.51111\n",
      "10/10 [==============================] - 1s 50ms/step - loss: 0.1730 - accuracy: 0.5939 - val_loss: 0.2210 - val_accuracy: 0.4000\n",
      "Epoch 96/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1719 - accuracy: 0.6111\n",
      "Epoch 96: val_accuracy did not improve from 0.51111\n",
      "10/10 [==============================] - 1s 53ms/step - loss: 0.1720 - accuracy: 0.6111 - val_loss: 0.2256 - val_accuracy: 0.3704\n",
      "Epoch 97/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1748 - accuracy: 0.5864\n",
      "Epoch 97: val_accuracy did not improve from 0.51111\n",
      "10/10 [==============================] - 1s 50ms/step - loss: 0.1747 - accuracy: 0.5861 - val_loss: 0.2173 - val_accuracy: 0.4815\n",
      "Epoch 98/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1732 - accuracy: 0.5972\n",
      "Epoch 98: val_accuracy did not improve from 0.51111\n",
      "10/10 [==============================] - 1s 53ms/step - loss: 0.1729 - accuracy: 0.5991 - val_loss: 0.2161 - val_accuracy: 0.4519\n",
      "Epoch 99/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1712 - accuracy: 0.6046\n",
      "Epoch 99: val_accuracy did not improve from 0.51111\n",
      "10/10 [==============================] - 1s 51ms/step - loss: 0.1717 - accuracy: 0.6034 - val_loss: 0.2149 - val_accuracy: 0.4519\n",
      "Epoch 100/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1746 - accuracy: 0.5903\n",
      "Epoch 100: val_accuracy did not improve from 0.51111\n",
      "10/10 [==============================] - 1s 50ms/step - loss: 0.1745 - accuracy: 0.5904 - val_loss: 0.2154 - val_accuracy: 0.4444\n",
      "Epoch 101/500\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1735 - accuracy: 0.5995\n",
      "Epoch 101: val_accuracy did not improve from 0.51111\n",
      "10/10 [==============================] - 1s 50ms/step - loss: 0.1735 - accuracy: 0.5995 - val_loss: 0.2164 - val_accuracy: 0.4000\n",
      "Epoch 102/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1750 - accuracy: 0.5820\n",
      "Epoch 102: val_accuracy did not improve from 0.51111\n",
      "10/10 [==============================] - 1s 50ms/step - loss: 0.1749 - accuracy: 0.5822 - val_loss: 0.2263 - val_accuracy: 0.4444\n",
      "Epoch 103/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1737 - accuracy: 0.6072\n",
      "Epoch 103: val_accuracy did not improve from 0.51111\n",
      "10/10 [==============================] - 1s 52ms/step - loss: 0.1738 - accuracy: 0.6068 - val_loss: 0.2151 - val_accuracy: 0.4741\n",
      "Epoch 104/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1745 - accuracy: 0.5846\n",
      "Epoch 104: val_accuracy did not improve from 0.51111\n",
      "10/10 [==============================] - 1s 51ms/step - loss: 0.1745 - accuracy: 0.5848 - val_loss: 0.2244 - val_accuracy: 0.4519\n",
      "Epoch 105/500\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1730 - accuracy: 0.6034\n",
      "Epoch 105: val_accuracy did not improve from 0.51111\n",
      "10/10 [==============================] - 1s 52ms/step - loss: 0.1730 - accuracy: 0.6034 - val_loss: 0.2262 - val_accuracy: 0.4074\n",
      "Epoch 106/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1731 - accuracy: 0.6089\n",
      "Epoch 106: val_accuracy did not improve from 0.51111\n",
      "10/10 [==============================] - 1s 51ms/step - loss: 0.1731 - accuracy: 0.6077 - val_loss: 0.2282 - val_accuracy: 0.4222\n",
      "Epoch 107/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1758 - accuracy: 0.6050\n",
      "Epoch 107: val_accuracy did not improve from 0.51111\n",
      "10/10 [==============================] - 1s 54ms/step - loss: 0.1757 - accuracy: 0.6060 - val_loss: 0.2136 - val_accuracy: 0.4222\n",
      "Epoch 108/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1732 - accuracy: 0.6033\n",
      "Epoch 108: val_accuracy did not improve from 0.51111\n",
      "10/10 [==============================] - 1s 50ms/step - loss: 0.1736 - accuracy: 0.6016 - val_loss: 0.2227 - val_accuracy: 0.5037\n",
      "Epoch 109/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1752 - accuracy: 0.5894\n",
      "Epoch 109: val_accuracy did not improve from 0.51111\n",
      "10/10 [==============================] - 1s 51ms/step - loss: 0.1750 - accuracy: 0.5891 - val_loss: 0.2547 - val_accuracy: 0.3778\n",
      "Epoch 110/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1713 - accuracy: 0.6107\n",
      "Epoch 110: val_accuracy did not improve from 0.51111\n",
      "10/10 [==============================] - 1s 52ms/step - loss: 0.1714 - accuracy: 0.6098 - val_loss: 0.2133 - val_accuracy: 0.4074\n",
      "Epoch 111/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1730 - accuracy: 0.5985\n",
      "Epoch 111: val_accuracy did not improve from 0.51111\n",
      "10/10 [==============================] - 1s 52ms/step - loss: 0.1731 - accuracy: 0.5978 - val_loss: 0.2208 - val_accuracy: 0.4444\n",
      "Epoch 112/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1707 - accuracy: 0.5994\n",
      "Epoch 112: val_accuracy did not improve from 0.51111\n",
      "10/10 [==============================] - 0s 49ms/step - loss: 0.1709 - accuracy: 0.5982 - val_loss: 0.2177 - val_accuracy: 0.4519\n",
      "Epoch 113/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1710 - accuracy: 0.6059\n",
      "Epoch 113: val_accuracy did not improve from 0.51111\n",
      "10/10 [==============================] - 0s 50ms/step - loss: 0.1709 - accuracy: 0.6060 - val_loss: 0.2193 - val_accuracy: 0.4296\n",
      "Epoch 114/500\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1708 - accuracy: 0.6077\n",
      "Epoch 114: val_accuracy did not improve from 0.51111\n",
      "10/10 [==============================] - 1s 51ms/step - loss: 0.1708 - accuracy: 0.6077 - val_loss: 0.2264 - val_accuracy: 0.3630\n",
      "Epoch 115/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1718 - accuracy: 0.5907\n",
      "Epoch 115: val_accuracy did not improve from 0.51111\n",
      "10/10 [==============================] - 1s 50ms/step - loss: 0.1721 - accuracy: 0.5904 - val_loss: 0.2258 - val_accuracy: 0.4444\n",
      "Epoch 116/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1713 - accuracy: 0.6107\n",
      "Epoch 116: val_accuracy did not improve from 0.51111\n",
      "10/10 [==============================] - 1s 52ms/step - loss: 0.1709 - accuracy: 0.6116 - val_loss: 0.2199 - val_accuracy: 0.3333\n",
      "Epoch 117/500\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1718 - accuracy: 0.5978\n",
      "Epoch 117: val_accuracy did not improve from 0.51111\n",
      "10/10 [==============================] - 1s 51ms/step - loss: 0.1718 - accuracy: 0.5978 - val_loss: 0.2173 - val_accuracy: 0.3704\n",
      "Epoch 118/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1714 - accuracy: 0.5985\n",
      "Epoch 118: val_accuracy did not improve from 0.51111\n",
      "10/10 [==============================] - 1s 53ms/step - loss: 0.1717 - accuracy: 0.5978 - val_loss: 0.2317 - val_accuracy: 0.3556\n",
      "Epoch 119/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1758 - accuracy: 0.5977\n",
      "Epoch 119: val_accuracy did not improve from 0.51111\n",
      "10/10 [==============================] - 0s 49ms/step - loss: 0.1758 - accuracy: 0.5973 - val_loss: 0.2273 - val_accuracy: 0.4519\n",
      "Epoch 120/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1724 - accuracy: 0.6020\n",
      "Epoch 120: val_accuracy did not improve from 0.51111\n",
      "10/10 [==============================] - 0s 49ms/step - loss: 0.1723 - accuracy: 0.6025 - val_loss: 0.2434 - val_accuracy: 0.3407\n",
      "Epoch 121/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1724 - accuracy: 0.6003\n",
      "Epoch 121: val_accuracy did not improve from 0.51111\n",
      "10/10 [==============================] - 1s 51ms/step - loss: 0.1726 - accuracy: 0.5995 - val_loss: 0.2237 - val_accuracy: 0.4667\n",
      "Epoch 122/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1737 - accuracy: 0.5924\n",
      "Epoch 122: val_accuracy did not improve from 0.51111\n",
      "10/10 [==============================] - 1s 53ms/step - loss: 0.1736 - accuracy: 0.5934 - val_loss: 0.2124 - val_accuracy: 0.4815\n",
      "Epoch 123/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1726 - accuracy: 0.6020\n",
      "Epoch 123: val_accuracy did not improve from 0.51111\n",
      "10/10 [==============================] - 1s 52ms/step - loss: 0.1731 - accuracy: 0.6008 - val_loss: 0.2251 - val_accuracy: 0.4667\n",
      "Epoch 124/500\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1738 - accuracy: 0.5956\n",
      "Epoch 124: val_accuracy did not improve from 0.51111\n",
      "10/10 [==============================] - 0s 47ms/step - loss: 0.1738 - accuracy: 0.5956 - val_loss: 0.2374 - val_accuracy: 0.3407\n",
      "Epoch 125/500\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1733 - accuracy: 0.5913\n",
      "Epoch 125: val_accuracy did not improve from 0.51111\n",
      "10/10 [==============================] - 1s 51ms/step - loss: 0.1733 - accuracy: 0.5913 - val_loss: 0.2242 - val_accuracy: 0.4444\n",
      "Epoch 126/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1677 - accuracy: 0.6137\n",
      "Epoch 126: val_accuracy did not improve from 0.51111\n",
      "10/10 [==============================] - 1s 52ms/step - loss: 0.1681 - accuracy: 0.6111 - val_loss: 0.2111 - val_accuracy: 0.4519\n",
      "Epoch 127/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1721 - accuracy: 0.5885\n",
      "Epoch 127: val_accuracy did not improve from 0.51111\n",
      "10/10 [==============================] - 1s 53ms/step - loss: 0.1720 - accuracy: 0.5887 - val_loss: 0.2139 - val_accuracy: 0.4370\n",
      "Epoch 128/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1696 - accuracy: 0.6072\n",
      "Epoch 128: val_accuracy did not improve from 0.51111\n",
      "10/10 [==============================] - 1s 51ms/step - loss: 0.1695 - accuracy: 0.6077 - val_loss: 0.2153 - val_accuracy: 0.4667\n",
      "Epoch 129/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1688 - accuracy: 0.6063\n",
      "Epoch 129: val_accuracy did not improve from 0.51111\n",
      "10/10 [==============================] - 1s 52ms/step - loss: 0.1687 - accuracy: 0.6060 - val_loss: 0.2302 - val_accuracy: 0.4667\n",
      "Epoch 130/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1689 - accuracy: 0.6059\n",
      "Epoch 130: val_accuracy did not improve from 0.51111\n",
      "10/10 [==============================] - 1s 50ms/step - loss: 0.1690 - accuracy: 0.6055 - val_loss: 0.2204 - val_accuracy: 0.4444\n",
      "Epoch 131/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1680 - accuracy: 0.6089\n",
      "Epoch 131: val_accuracy did not improve from 0.51111\n",
      "10/10 [==============================] - 1s 51ms/step - loss: 0.1678 - accuracy: 0.6103 - val_loss: 0.2168 - val_accuracy: 0.4222\n",
      "Epoch 132/500\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1707 - accuracy: 0.6021\n",
      "Epoch 132: val_accuracy did not improve from 0.51111\n",
      "10/10 [==============================] - 1s 50ms/step - loss: 0.1707 - accuracy: 0.6021 - val_loss: 0.2230 - val_accuracy: 0.4741\n",
      "Epoch 1/500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-08 23:33:34.382903: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape insequential_4/dropout_8/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.2269 - accuracy: 0.3594\n",
      "Epoch 1: val_accuracy improved from -inf to 0.33333, saving model to best_model_CNNLSTM.h5\n",
      "10/10 [==============================] - 2s 70ms/step - loss: 0.2267 - accuracy: 0.3611 - val_loss: 0.2221 - val_accuracy: 0.3333\n",
      "Epoch 2/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.2119 - accuracy: 0.4579\n",
      "Epoch 2: val_accuracy did not improve from 0.33333\n",
      "10/10 [==============================] - 1s 50ms/step - loss: 0.2121 - accuracy: 0.4560 - val_loss: 0.2221 - val_accuracy: 0.3171\n",
      "Epoch 3/500\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2083 - accuracy: 0.4547\n",
      "Epoch 3: val_accuracy improved from 0.33333 to 0.39837, saving model to best_model_CNNLSTM.h5\n",
      "10/10 [==============================] - 1s 53ms/step - loss: 0.2083 - accuracy: 0.4547 - val_loss: 0.2219 - val_accuracy: 0.3984\n",
      "Epoch 4/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.2068 - accuracy: 0.4796\n",
      "Epoch 4: val_accuracy did not improve from 0.39837\n",
      "10/10 [==============================] - 1s 52ms/step - loss: 0.2068 - accuracy: 0.4779 - val_loss: 0.2222 - val_accuracy: 0.3171\n",
      "Epoch 5/500\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2073 - accuracy: 0.4672\n",
      "Epoch 5: val_accuracy did not improve from 0.39837\n",
      "10/10 [==============================] - 0s 50ms/step - loss: 0.2073 - accuracy: 0.4672 - val_loss: 0.2223 - val_accuracy: 0.3740\n",
      "Epoch 6/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.2033 - accuracy: 0.4909\n",
      "Epoch 6: val_accuracy did not improve from 0.39837\n",
      "10/10 [==============================] - 1s 51ms/step - loss: 0.2034 - accuracy: 0.4899 - val_loss: 0.2218 - val_accuracy: 0.3821\n",
      "Epoch 7/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.2012 - accuracy: 0.4991\n",
      "Epoch 7: val_accuracy did not improve from 0.39837\n",
      "10/10 [==============================] - 0s 47ms/step - loss: 0.2010 - accuracy: 0.5002 - val_loss: 0.2215 - val_accuracy: 0.3577\n",
      "Epoch 8/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1979 - accuracy: 0.5234\n",
      "Epoch 8: val_accuracy did not improve from 0.39837\n",
      "10/10 [==============================] - 0s 49ms/step - loss: 0.1977 - accuracy: 0.5243 - val_loss: 0.2225 - val_accuracy: 0.3659\n",
      "Epoch 9/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1950 - accuracy: 0.5352\n",
      "Epoch 9: val_accuracy improved from 0.39837 to 0.50407, saving model to best_model_CNNLSTM.h5\n",
      "10/10 [==============================] - 1s 54ms/step - loss: 0.1949 - accuracy: 0.5346 - val_loss: 0.2217 - val_accuracy: 0.5041\n",
      "Epoch 10/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1912 - accuracy: 0.5547\n",
      "Epoch 10: val_accuracy did not improve from 0.50407\n",
      "10/10 [==============================] - 0s 47ms/step - loss: 0.1910 - accuracy: 0.5547 - val_loss: 0.2228 - val_accuracy: 0.3577\n",
      "Epoch 11/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1877 - accuracy: 0.5512\n",
      "Epoch 11: val_accuracy did not improve from 0.50407\n",
      "10/10 [==============================] - 0s 48ms/step - loss: 0.1877 - accuracy: 0.5509 - val_loss: 0.2225 - val_accuracy: 0.3577\n",
      "Epoch 12/500\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1887 - accuracy: 0.5569\n",
      "Epoch 12: val_accuracy did not improve from 0.50407\n",
      "10/10 [==============================] - 0s 47ms/step - loss: 0.1887 - accuracy: 0.5569 - val_loss: 0.2192 - val_accuracy: 0.4959\n",
      "Epoch 13/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1899 - accuracy: 0.5486\n",
      "Epoch 13: val_accuracy did not improve from 0.50407\n",
      "10/10 [==============================] - 0s 49ms/step - loss: 0.1900 - accuracy: 0.5474 - val_loss: 0.2219 - val_accuracy: 0.5041\n",
      "Epoch 14/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1862 - accuracy: 0.5569\n",
      "Epoch 14: val_accuracy improved from 0.50407 to 0.53659, saving model to best_model_CNNLSTM.h5\n",
      "10/10 [==============================] - 1s 52ms/step - loss: 0.1866 - accuracy: 0.5560 - val_loss: 0.2194 - val_accuracy: 0.5366\n",
      "Epoch 15/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1863 - accuracy: 0.5473\n",
      "Epoch 15: val_accuracy improved from 0.53659 to 0.57724, saving model to best_model_CNNLSTM.h5\n",
      "10/10 [==============================] - 1s 54ms/step - loss: 0.1863 - accuracy: 0.5470 - val_loss: 0.2177 - val_accuracy: 0.5772\n",
      "Epoch 16/500\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1860 - accuracy: 0.5590\n",
      "Epoch 16: val_accuracy did not improve from 0.57724\n",
      "10/10 [==============================] - 0s 48ms/step - loss: 0.1860 - accuracy: 0.5590 - val_loss: 0.2159 - val_accuracy: 0.4959\n",
      "Epoch 17/500\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1841 - accuracy: 0.5655\n",
      "Epoch 17: val_accuracy did not improve from 0.57724\n",
      "10/10 [==============================] - 0s 49ms/step - loss: 0.1841 - accuracy: 0.5655 - val_loss: 0.2225 - val_accuracy: 0.3333\n",
      "Epoch 18/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1850 - accuracy: 0.5564\n",
      "Epoch 18: val_accuracy did not improve from 0.57724\n",
      "10/10 [==============================] - 1s 52ms/step - loss: 0.1852 - accuracy: 0.5560 - val_loss: 0.2155 - val_accuracy: 0.5610\n",
      "Epoch 19/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1838 - accuracy: 0.5781\n",
      "Epoch 19: val_accuracy did not improve from 0.57724\n",
      "10/10 [==============================] - 1s 51ms/step - loss: 0.1841 - accuracy: 0.5762 - val_loss: 0.2151 - val_accuracy: 0.4472\n",
      "Epoch 20/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1840 - accuracy: 0.5707\n",
      "Epoch 20: val_accuracy did not improve from 0.57724\n",
      "10/10 [==============================] - 1s 51ms/step - loss: 0.1836 - accuracy: 0.5723 - val_loss: 0.2143 - val_accuracy: 0.3902\n",
      "Epoch 21/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1837 - accuracy: 0.5651\n",
      "Epoch 21: val_accuracy did not improve from 0.57724\n",
      "10/10 [==============================] - 0s 46ms/step - loss: 0.1835 - accuracy: 0.5659 - val_loss: 0.2101 - val_accuracy: 0.5122\n",
      "Epoch 22/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1813 - accuracy: 0.5703\n",
      "Epoch 22: val_accuracy did not improve from 0.57724\n",
      "10/10 [==============================] - 1s 52ms/step - loss: 0.1812 - accuracy: 0.5706 - val_loss: 0.2113 - val_accuracy: 0.4472\n",
      "Epoch 23/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1805 - accuracy: 0.5786\n",
      "Epoch 23: val_accuracy did not improve from 0.57724\n",
      "10/10 [==============================] - 1s 53ms/step - loss: 0.1804 - accuracy: 0.5788 - val_loss: 0.2142 - val_accuracy: 0.3740\n",
      "Epoch 24/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1790 - accuracy: 0.5807\n",
      "Epoch 24: val_accuracy did not improve from 0.57724\n",
      "10/10 [==============================] - 1s 50ms/step - loss: 0.1788 - accuracy: 0.5818 - val_loss: 0.2137 - val_accuracy: 0.3171\n",
      "Epoch 25/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1797 - accuracy: 0.5747\n",
      "Epoch 25: val_accuracy did not improve from 0.57724\n",
      "10/10 [==============================] - 1s 53ms/step - loss: 0.1796 - accuracy: 0.5754 - val_loss: 0.2091 - val_accuracy: 0.3821\n",
      "Epoch 26/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1796 - accuracy: 0.5699\n",
      "Epoch 26: val_accuracy did not improve from 0.57724\n",
      "10/10 [==============================] - 0s 47ms/step - loss: 0.1798 - accuracy: 0.5689 - val_loss: 0.2179 - val_accuracy: 0.3740\n",
      "Epoch 27/500\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1815 - accuracy: 0.5796\n",
      "Epoch 27: val_accuracy did not improve from 0.57724\n",
      "10/10 [==============================] - 0s 49ms/step - loss: 0.1815 - accuracy: 0.5796 - val_loss: 0.2114 - val_accuracy: 0.4065\n",
      "Epoch 28/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1797 - accuracy: 0.5734\n",
      "Epoch 28: val_accuracy did not improve from 0.57724\n",
      "10/10 [==============================] - 1s 52ms/step - loss: 0.1798 - accuracy: 0.5728 - val_loss: 0.2157 - val_accuracy: 0.4472\n",
      "Epoch 29/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1818 - accuracy: 0.5742\n",
      "Epoch 29: val_accuracy did not improve from 0.57724\n",
      "10/10 [==============================] - 1s 53ms/step - loss: 0.1818 - accuracy: 0.5741 - val_loss: 0.2071 - val_accuracy: 0.4309\n",
      "Epoch 30/500\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1773 - accuracy: 0.5895\n",
      "Epoch 30: val_accuracy did not improve from 0.57724\n",
      "10/10 [==============================] - 1s 53ms/step - loss: 0.1773 - accuracy: 0.5895 - val_loss: 0.2292 - val_accuracy: 0.3333\n",
      "Epoch 31/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1778 - accuracy: 0.5833\n",
      "Epoch 31: val_accuracy did not improve from 0.57724\n",
      "10/10 [==============================] - 0s 46ms/step - loss: 0.1778 - accuracy: 0.5831 - val_loss: 0.2231 - val_accuracy: 0.3740\n",
      "Epoch 32/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1785 - accuracy: 0.5781\n",
      "Epoch 32: val_accuracy did not improve from 0.57724\n",
      "10/10 [==============================] - 0s 49ms/step - loss: 0.1783 - accuracy: 0.5788 - val_loss: 0.2289 - val_accuracy: 0.3821\n",
      "Epoch 33/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1781 - accuracy: 0.5868\n",
      "Epoch 33: val_accuracy did not improve from 0.57724\n",
      "10/10 [==============================] - 0s 49ms/step - loss: 0.1786 - accuracy: 0.5861 - val_loss: 0.2044 - val_accuracy: 0.4472\n",
      "Epoch 34/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1797 - accuracy: 0.5742\n",
      "Epoch 34: val_accuracy did not improve from 0.57724\n",
      "10/10 [==============================] - 0s 47ms/step - loss: 0.1794 - accuracy: 0.5749 - val_loss: 0.2189 - val_accuracy: 0.4228\n",
      "Epoch 35/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1757 - accuracy: 0.5864\n",
      "Epoch 35: val_accuracy did not improve from 0.57724\n",
      "10/10 [==============================] - 1s 53ms/step - loss: 0.1756 - accuracy: 0.5878 - val_loss: 0.2099 - val_accuracy: 0.3984\n",
      "Epoch 36/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1778 - accuracy: 0.5816\n",
      "Epoch 36: val_accuracy did not improve from 0.57724\n",
      "10/10 [==============================] - 0s 49ms/step - loss: 0.1780 - accuracy: 0.5814 - val_loss: 0.2103 - val_accuracy: 0.3984\n",
      "Epoch 37/500\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1780 - accuracy: 0.5809\n",
      "Epoch 37: val_accuracy did not improve from 0.57724\n",
      "10/10 [==============================] - 1s 51ms/step - loss: 0.1780 - accuracy: 0.5809 - val_loss: 0.2204 - val_accuracy: 0.3740\n",
      "Epoch 38/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1784 - accuracy: 0.5846\n",
      "Epoch 38: val_accuracy did not improve from 0.57724\n",
      "10/10 [==============================] - 0s 50ms/step - loss: 0.1782 - accuracy: 0.5848 - val_loss: 0.2137 - val_accuracy: 0.3821\n",
      "Epoch 39/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1783 - accuracy: 0.5755\n",
      "Epoch 39: val_accuracy did not improve from 0.57724\n",
      "10/10 [==============================] - 1s 50ms/step - loss: 0.1779 - accuracy: 0.5775 - val_loss: 0.2153 - val_accuracy: 0.4228\n",
      "Epoch 40/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1725 - accuracy: 0.6033\n",
      "Epoch 40: val_accuracy did not improve from 0.57724\n",
      "10/10 [==============================] - 1s 51ms/step - loss: 0.1727 - accuracy: 0.6028 - val_loss: 0.2229 - val_accuracy: 0.4065\n",
      "Epoch 41/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1742 - accuracy: 0.5964\n",
      "Epoch 41: val_accuracy did not improve from 0.57724\n",
      "10/10 [==============================] - 1s 51ms/step - loss: 0.1744 - accuracy: 0.5951 - val_loss: 0.2002 - val_accuracy: 0.5122\n",
      "Epoch 42/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1750 - accuracy: 0.5938\n",
      "Epoch 42: val_accuracy did not improve from 0.57724\n",
      "10/10 [==============================] - 1s 53ms/step - loss: 0.1751 - accuracy: 0.5934 - val_loss: 0.2066 - val_accuracy: 0.4146\n",
      "Epoch 43/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1758 - accuracy: 0.5933\n",
      "Epoch 43: val_accuracy did not improve from 0.57724\n",
      "10/10 [==============================] - 0s 49ms/step - loss: 0.1756 - accuracy: 0.5930 - val_loss: 0.1989 - val_accuracy: 0.4715\n",
      "Epoch 44/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1772 - accuracy: 0.5864\n",
      "Epoch 44: val_accuracy did not improve from 0.57724\n",
      "10/10 [==============================] - 0s 48ms/step - loss: 0.1771 - accuracy: 0.5865 - val_loss: 0.1943 - val_accuracy: 0.5447\n",
      "Epoch 45/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1740 - accuracy: 0.5938\n",
      "Epoch 45: val_accuracy did not improve from 0.57724\n",
      "10/10 [==============================] - 0s 47ms/step - loss: 0.1742 - accuracy: 0.5921 - val_loss: 0.1998 - val_accuracy: 0.4797\n",
      "Epoch 46/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1729 - accuracy: 0.5920\n",
      "Epoch 46: val_accuracy did not improve from 0.57724\n",
      "10/10 [==============================] - 0s 49ms/step - loss: 0.1725 - accuracy: 0.5921 - val_loss: 0.1916 - val_accuracy: 0.5528\n",
      "Epoch 47/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1742 - accuracy: 0.5881\n",
      "Epoch 47: val_accuracy did not improve from 0.57724\n",
      "10/10 [==============================] - 1s 51ms/step - loss: 0.1740 - accuracy: 0.5895 - val_loss: 0.2052 - val_accuracy: 0.4309\n",
      "Epoch 48/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1736 - accuracy: 0.5890\n",
      "Epoch 48: val_accuracy did not improve from 0.57724\n",
      "10/10 [==============================] - 0s 49ms/step - loss: 0.1734 - accuracy: 0.5908 - val_loss: 0.2104 - val_accuracy: 0.4146\n",
      "Epoch 49/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1727 - accuracy: 0.5946\n",
      "Epoch 49: val_accuracy did not improve from 0.57724\n",
      "10/10 [==============================] - 0s 48ms/step - loss: 0.1729 - accuracy: 0.5947 - val_loss: 0.1940 - val_accuracy: 0.5691\n",
      "Epoch 50/500\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1736 - accuracy: 0.5934\n",
      "Epoch 50: val_accuracy did not improve from 0.57724\n",
      "10/10 [==============================] - 0s 50ms/step - loss: 0.1736 - accuracy: 0.5934 - val_loss: 0.2147 - val_accuracy: 0.3821\n",
      "Epoch 51/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1736 - accuracy: 0.5998\n",
      "Epoch 51: val_accuracy did not improve from 0.57724\n",
      "10/10 [==============================] - 1s 51ms/step - loss: 0.1736 - accuracy: 0.5994 - val_loss: 0.2022 - val_accuracy: 0.4553\n",
      "Epoch 52/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1723 - accuracy: 0.6063\n",
      "Epoch 52: val_accuracy did not improve from 0.57724\n",
      "10/10 [==============================] - 0s 49ms/step - loss: 0.1725 - accuracy: 0.6058 - val_loss: 0.1966 - val_accuracy: 0.5122\n",
      "Epoch 53/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1721 - accuracy: 0.6033\n",
      "Epoch 53: val_accuracy did not improve from 0.57724\n",
      "10/10 [==============================] - 1s 53ms/step - loss: 0.1723 - accuracy: 0.6033 - val_loss: 0.1991 - val_accuracy: 0.4797\n",
      "Epoch 54/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1735 - accuracy: 0.5990\n",
      "Epoch 54: val_accuracy did not improve from 0.57724\n",
      "10/10 [==============================] - 1s 51ms/step - loss: 0.1736 - accuracy: 0.5985 - val_loss: 0.1934 - val_accuracy: 0.5772\n",
      "Epoch 55/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1718 - accuracy: 0.6076\n",
      "Epoch 55: val_accuracy did not improve from 0.57724\n",
      "10/10 [==============================] - 0s 50ms/step - loss: 0.1716 - accuracy: 0.6076 - val_loss: 0.1903 - val_accuracy: 0.4715\n",
      "Epoch 56/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1736 - accuracy: 0.6033\n",
      "Epoch 56: val_accuracy did not improve from 0.57724\n",
      "10/10 [==============================] - 1s 51ms/step - loss: 0.1734 - accuracy: 0.6037 - val_loss: 0.1984 - val_accuracy: 0.4878\n",
      "Epoch 57/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1724 - accuracy: 0.5946\n",
      "Epoch 57: val_accuracy did not improve from 0.57724\n",
      "10/10 [==============================] - 1s 50ms/step - loss: 0.1725 - accuracy: 0.5938 - val_loss: 0.1917 - val_accuracy: 0.4878\n",
      "Epoch 58/500\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1723 - accuracy: 0.6071\n",
      "Epoch 58: val_accuracy did not improve from 0.57724\n",
      "10/10 [==============================] - 1s 52ms/step - loss: 0.1723 - accuracy: 0.6071 - val_loss: 0.2071 - val_accuracy: 0.4309\n",
      "Epoch 59/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1736 - accuracy: 0.5946\n",
      "Epoch 59: val_accuracy did not improve from 0.57724\n",
      "10/10 [==============================] - 1s 52ms/step - loss: 0.1732 - accuracy: 0.5955 - val_loss: 0.2140 - val_accuracy: 0.4309\n",
      "Epoch 60/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1725 - accuracy: 0.5890\n",
      "Epoch 60: val_accuracy did not improve from 0.57724\n",
      "10/10 [==============================] - 1s 52ms/step - loss: 0.1726 - accuracy: 0.5891 - val_loss: 0.1859 - val_accuracy: 0.5610\n",
      "Epoch 61/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1698 - accuracy: 0.6059\n",
      "Epoch 61: val_accuracy did not improve from 0.57724\n",
      "10/10 [==============================] - 1s 52ms/step - loss: 0.1698 - accuracy: 0.6054 - val_loss: 0.2075 - val_accuracy: 0.4715\n",
      "Epoch 62/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1705 - accuracy: 0.6020\n",
      "Epoch 62: val_accuracy did not improve from 0.57724\n",
      "10/10 [==============================] - 1s 52ms/step - loss: 0.1703 - accuracy: 0.6024 - val_loss: 0.2131 - val_accuracy: 0.4553\n",
      "Epoch 63/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1705 - accuracy: 0.5938\n",
      "Epoch 63: val_accuracy did not improve from 0.57724\n",
      "10/10 [==============================] - 0s 50ms/step - loss: 0.1705 - accuracy: 0.5938 - val_loss: 0.2116 - val_accuracy: 0.4634\n",
      "Epoch 64/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1692 - accuracy: 0.6124\n",
      "Epoch 64: val_accuracy did not improve from 0.57724\n",
      "10/10 [==============================] - 0s 48ms/step - loss: 0.1693 - accuracy: 0.6119 - val_loss: 0.2030 - val_accuracy: 0.4797\n",
      "Epoch 65/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1720 - accuracy: 0.6037\n",
      "Epoch 65: val_accuracy did not improve from 0.57724\n",
      "10/10 [==============================] - 1s 52ms/step - loss: 0.1719 - accuracy: 0.6041 - val_loss: 0.2167 - val_accuracy: 0.4390\n",
      "Epoch 1/500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-08 23:34:09.330591: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape insequential_5/dropout_10/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.2289 - accuracy: 0.3377\n",
      "Epoch 1: val_accuracy improved from -inf to 0.35461, saving model to best_model_CNNLSTM.h5\n",
      "10/10 [==============================] - 2s 68ms/step - loss: 0.2289 - accuracy: 0.3384 - val_loss: 0.2221 - val_accuracy: 0.3546\n",
      "Epoch 2/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.2168 - accuracy: 0.4154\n",
      "Epoch 2: val_accuracy did not improve from 0.35461\n",
      "10/10 [==============================] - 0s 48ms/step - loss: 0.2167 - accuracy: 0.4154 - val_loss: 0.2224 - val_accuracy: 0.3121\n",
      "Epoch 3/500\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2130 - accuracy: 0.4483\n",
      "Epoch 3: val_accuracy did not improve from 0.35461\n",
      "10/10 [==============================] - 0s 49ms/step - loss: 0.2130 - accuracy: 0.4483 - val_loss: 0.2224 - val_accuracy: 0.3262\n",
      "Epoch 4/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.2134 - accuracy: 0.4462\n",
      "Epoch 4: val_accuracy improved from 0.35461 to 0.37589, saving model to best_model_CNNLSTM.h5\n",
      "10/10 [==============================] - 1s 55ms/step - loss: 0.2133 - accuracy: 0.4461 - val_loss: 0.2224 - val_accuracy: 0.3759\n",
      "Epoch 5/500\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2099 - accuracy: 0.4626\n",
      "Epoch 5: val_accuracy did not improve from 0.37589\n",
      "10/10 [==============================] - 1s 51ms/step - loss: 0.2099 - accuracy: 0.4626 - val_loss: 0.2223 - val_accuracy: 0.3688\n",
      "Epoch 6/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.2084 - accuracy: 0.4653\n",
      "Epoch 6: val_accuracy did not improve from 0.37589\n",
      "10/10 [==============================] - 0s 49ms/step - loss: 0.2084 - accuracy: 0.4656 - val_loss: 0.2230 - val_accuracy: 0.3121\n",
      "Epoch 7/500\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2085 - accuracy: 0.4751\n",
      "Epoch 7: val_accuracy did not improve from 0.37589\n",
      "10/10 [==============================] - 0s 48ms/step - loss: 0.2085 - accuracy: 0.4751 - val_loss: 0.2230 - val_accuracy: 0.3191\n",
      "Epoch 8/500\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2043 - accuracy: 0.4907\n",
      "Epoch 8: val_accuracy did not improve from 0.37589\n",
      "10/10 [==============================] - 1s 51ms/step - loss: 0.2043 - accuracy: 0.4907 - val_loss: 0.2216 - val_accuracy: 0.3688\n",
      "Epoch 9/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.2052 - accuracy: 0.4857\n",
      "Epoch 9: val_accuracy did not improve from 0.37589\n",
      "10/10 [==============================] - 1s 51ms/step - loss: 0.2051 - accuracy: 0.4868 - val_loss: 0.2227 - val_accuracy: 0.3546\n",
      "Epoch 10/500\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2024 - accuracy: 0.4985\n",
      "Epoch 10: val_accuracy did not improve from 0.37589\n",
      "10/10 [==============================] - 1s 51ms/step - loss: 0.2024 - accuracy: 0.4985 - val_loss: 0.2213 - val_accuracy: 0.3546\n",
      "Epoch 11/500\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2004 - accuracy: 0.4963\n",
      "Epoch 11: val_accuracy did not improve from 0.37589\n",
      "10/10 [==============================] - 1s 50ms/step - loss: 0.2004 - accuracy: 0.4963 - val_loss: 0.2208 - val_accuracy: 0.3546\n",
      "Epoch 12/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1972 - accuracy: 0.5130\n",
      "Epoch 12: val_accuracy did not improve from 0.37589\n",
      "10/10 [==============================] - 1s 52ms/step - loss: 0.1971 - accuracy: 0.5136 - val_loss: 0.2238 - val_accuracy: 0.3191\n",
      "Epoch 13/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1993 - accuracy: 0.5117\n",
      "Epoch 13: val_accuracy did not improve from 0.37589\n",
      "10/10 [==============================] - 1s 51ms/step - loss: 0.1995 - accuracy: 0.5115 - val_loss: 0.2216 - val_accuracy: 0.3262\n",
      "Epoch 14/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1940 - accuracy: 0.5122\n",
      "Epoch 14: val_accuracy did not improve from 0.37589\n",
      "10/10 [==============================] - 1s 52ms/step - loss: 0.1940 - accuracy: 0.5119 - val_loss: 0.2186 - val_accuracy: 0.3688\n",
      "Epoch 15/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1965 - accuracy: 0.5391\n",
      "Epoch 15: val_accuracy did not improve from 0.37589\n",
      "10/10 [==============================] - 1s 51ms/step - loss: 0.1965 - accuracy: 0.5387 - val_loss: 0.2205 - val_accuracy: 0.3617\n",
      "Epoch 16/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1959 - accuracy: 0.5278\n",
      "Epoch 16: val_accuracy did not improve from 0.37589\n",
      "10/10 [==============================] - 1s 52ms/step - loss: 0.1960 - accuracy: 0.5270 - val_loss: 0.2213 - val_accuracy: 0.3546\n",
      "Epoch 17/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1968 - accuracy: 0.5052\n",
      "Epoch 17: val_accuracy did not improve from 0.37589\n",
      "10/10 [==============================] - 1s 53ms/step - loss: 0.1968 - accuracy: 0.5050 - val_loss: 0.2192 - val_accuracy: 0.3688\n",
      "Epoch 18/500\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1935 - accuracy: 0.5210\n",
      "Epoch 18: val_accuracy did not improve from 0.37589\n",
      "10/10 [==============================] - 1s 50ms/step - loss: 0.1935 - accuracy: 0.5210 - val_loss: 0.2240 - val_accuracy: 0.2979\n",
      "Epoch 19/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1940 - accuracy: 0.5425\n",
      "Epoch 19: val_accuracy improved from 0.37589 to 0.50355, saving model to best_model_CNNLSTM.h5\n",
      "10/10 [==============================] - 1s 52ms/step - loss: 0.1941 - accuracy: 0.5422 - val_loss: 0.2171 - val_accuracy: 0.5035\n",
      "Epoch 20/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1960 - accuracy: 0.5126\n",
      "Epoch 20: val_accuracy did not improve from 0.50355\n",
      "10/10 [==============================] - 1s 51ms/step - loss: 0.1961 - accuracy: 0.5119 - val_loss: 0.2189 - val_accuracy: 0.3333\n",
      "Epoch 21/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1973 - accuracy: 0.5213\n",
      "Epoch 21: val_accuracy did not improve from 0.50355\n",
      "10/10 [==============================] - 1s 53ms/step - loss: 0.1971 - accuracy: 0.5219 - val_loss: 0.2184 - val_accuracy: 0.3901\n",
      "Epoch 22/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1932 - accuracy: 0.5191\n",
      "Epoch 22: val_accuracy did not improve from 0.50355\n",
      "10/10 [==============================] - 1s 51ms/step - loss: 0.1933 - accuracy: 0.5184 - val_loss: 0.2165 - val_accuracy: 0.3830\n",
      "Epoch 23/500\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1903 - accuracy: 0.5387\n",
      "Epoch 23: val_accuracy improved from 0.50355 to 0.52482, saving model to best_model_CNNLSTM.h5\n",
      "10/10 [==============================] - 1s 53ms/step - loss: 0.1903 - accuracy: 0.5387 - val_loss: 0.2152 - val_accuracy: 0.5248\n",
      "Epoch 24/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1899 - accuracy: 0.5399\n",
      "Epoch 24: val_accuracy did not improve from 0.52482\n",
      "10/10 [==============================] - 1s 52ms/step - loss: 0.1900 - accuracy: 0.5396 - val_loss: 0.2135 - val_accuracy: 0.4397\n",
      "Epoch 25/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1946 - accuracy: 0.5278\n",
      "Epoch 25: val_accuracy did not improve from 0.52482\n",
      "10/10 [==============================] - 1s 53ms/step - loss: 0.1947 - accuracy: 0.5279 - val_loss: 0.2145 - val_accuracy: 0.3972\n",
      "Epoch 26/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1948 - accuracy: 0.5161\n",
      "Epoch 26: val_accuracy improved from 0.52482 to 0.57447, saving model to best_model_CNNLSTM.h5\n",
      "10/10 [==============================] - 1s 55ms/step - loss: 0.1949 - accuracy: 0.5158 - val_loss: 0.2109 - val_accuracy: 0.5745\n",
      "Epoch 27/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1900 - accuracy: 0.5295\n",
      "Epoch 27: val_accuracy did not improve from 0.57447\n",
      "10/10 [==============================] - 1s 53ms/step - loss: 0.1901 - accuracy: 0.5288 - val_loss: 0.2109 - val_accuracy: 0.4539\n",
      "Epoch 28/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1891 - accuracy: 0.5352\n",
      "Epoch 28: val_accuracy did not improve from 0.57447\n",
      "10/10 [==============================] - 1s 52ms/step - loss: 0.1891 - accuracy: 0.5353 - val_loss: 0.2105 - val_accuracy: 0.3688\n",
      "Epoch 29/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1886 - accuracy: 0.5464\n",
      "Epoch 29: val_accuracy did not improve from 0.57447\n",
      "10/10 [==============================] - 1s 53ms/step - loss: 0.1887 - accuracy: 0.5452 - val_loss: 0.2082 - val_accuracy: 0.4255\n",
      "Epoch 30/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1884 - accuracy: 0.5482\n",
      "Epoch 30: val_accuracy improved from 0.57447 to 0.58156, saving model to best_model_CNNLSTM.h5\n",
      "10/10 [==============================] - 1s 55ms/step - loss: 0.1885 - accuracy: 0.5474 - val_loss: 0.2006 - val_accuracy: 0.5816\n",
      "Epoch 31/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1871 - accuracy: 0.5399\n",
      "Epoch 31: val_accuracy did not improve from 0.58156\n",
      "10/10 [==============================] - 1s 51ms/step - loss: 0.1871 - accuracy: 0.5396 - val_loss: 0.2106 - val_accuracy: 0.5674\n",
      "Epoch 32/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1898 - accuracy: 0.5412\n",
      "Epoch 32: val_accuracy did not improve from 0.58156\n",
      "10/10 [==============================] - 1s 51ms/step - loss: 0.1897 - accuracy: 0.5418 - val_loss: 0.2008 - val_accuracy: 0.4823\n",
      "Epoch 33/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1885 - accuracy: 0.5347\n",
      "Epoch 33: val_accuracy did not improve from 0.58156\n",
      "10/10 [==============================] - 1s 52ms/step - loss: 0.1885 - accuracy: 0.5340 - val_loss: 0.2024 - val_accuracy: 0.5674\n",
      "Epoch 34/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1866 - accuracy: 0.5408\n",
      "Epoch 34: val_accuracy did not improve from 0.58156\n",
      "10/10 [==============================] - 1s 50ms/step - loss: 0.1866 - accuracy: 0.5400 - val_loss: 0.2055 - val_accuracy: 0.5319\n",
      "Epoch 35/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1872 - accuracy: 0.5530\n",
      "Epoch 35: val_accuracy did not improve from 0.58156\n",
      "10/10 [==============================] - 0s 49ms/step - loss: 0.1874 - accuracy: 0.5517 - val_loss: 0.2061 - val_accuracy: 0.4894\n",
      "Epoch 36/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1921 - accuracy: 0.5356\n",
      "Epoch 36: val_accuracy did not improve from 0.58156\n",
      "10/10 [==============================] - 0s 47ms/step - loss: 0.1922 - accuracy: 0.5344 - val_loss: 0.2072 - val_accuracy: 0.5390\n",
      "Epoch 37/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1881 - accuracy: 0.5543\n",
      "Epoch 37: val_accuracy did not improve from 0.58156\n",
      "10/10 [==============================] - 1s 50ms/step - loss: 0.1883 - accuracy: 0.5543 - val_loss: 0.2036 - val_accuracy: 0.4894\n",
      "Epoch 38/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1894 - accuracy: 0.5378\n",
      "Epoch 38: val_accuracy did not improve from 0.58156\n",
      "10/10 [==============================] - 1s 52ms/step - loss: 0.1893 - accuracy: 0.5374 - val_loss: 0.1967 - val_accuracy: 0.5816\n",
      "Epoch 39/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1851 - accuracy: 0.5612\n",
      "Epoch 39: val_accuracy did not improve from 0.58156\n",
      "10/10 [==============================] - 1s 50ms/step - loss: 0.1851 - accuracy: 0.5612 - val_loss: 0.1959 - val_accuracy: 0.5816\n",
      "Epoch 40/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1831 - accuracy: 0.5508\n",
      "Epoch 40: val_accuracy did not improve from 0.58156\n",
      "10/10 [==============================] - 1s 51ms/step - loss: 0.1831 - accuracy: 0.5508 - val_loss: 0.2001 - val_accuracy: 0.5603\n",
      "Epoch 41/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1828 - accuracy: 0.5629\n",
      "Epoch 41: val_accuracy did not improve from 0.58156\n",
      "10/10 [==============================] - 1s 53ms/step - loss: 0.1831 - accuracy: 0.5621 - val_loss: 0.2142 - val_accuracy: 0.4894\n",
      "Epoch 42/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1864 - accuracy: 0.5495\n",
      "Epoch 42: val_accuracy improved from 0.58156 to 0.59574, saving model to best_model_CNNLSTM.h5\n",
      "10/10 [==============================] - 1s 54ms/step - loss: 0.1864 - accuracy: 0.5495 - val_loss: 0.1999 - val_accuracy: 0.5957\n",
      "Epoch 43/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1840 - accuracy: 0.5716\n",
      "Epoch 43: val_accuracy improved from 0.59574 to 0.60993, saving model to best_model_CNNLSTM.h5\n",
      "10/10 [==============================] - 1s 56ms/step - loss: 0.1840 - accuracy: 0.5716 - val_loss: 0.1989 - val_accuracy: 0.6099\n",
      "Epoch 44/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1845 - accuracy: 0.5586\n",
      "Epoch 44: val_accuracy improved from 0.60993 to 0.61702, saving model to best_model_CNNLSTM.h5\n",
      "10/10 [==============================] - 1s 55ms/step - loss: 0.1844 - accuracy: 0.5591 - val_loss: 0.2080 - val_accuracy: 0.6170\n",
      "Epoch 45/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1825 - accuracy: 0.5560\n",
      "Epoch 45: val_accuracy did not improve from 0.61702\n",
      "10/10 [==============================] - 1s 52ms/step - loss: 0.1824 - accuracy: 0.5565 - val_loss: 0.2069 - val_accuracy: 0.5674\n",
      "Epoch 46/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1823 - accuracy: 0.5642\n",
      "Epoch 46: val_accuracy did not improve from 0.61702\n",
      "10/10 [==============================] - 1s 53ms/step - loss: 0.1823 - accuracy: 0.5638 - val_loss: 0.2173 - val_accuracy: 0.5532\n",
      "Epoch 47/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1828 - accuracy: 0.5530\n",
      "Epoch 47: val_accuracy did not improve from 0.61702\n",
      "10/10 [==============================] - 1s 53ms/step - loss: 0.1831 - accuracy: 0.5517 - val_loss: 0.2233 - val_accuracy: 0.5390\n",
      "Epoch 48/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1862 - accuracy: 0.5421\n",
      "Epoch 48: val_accuracy did not improve from 0.61702\n",
      "10/10 [==============================] - 1s 53ms/step - loss: 0.1864 - accuracy: 0.5413 - val_loss: 0.2158 - val_accuracy: 0.5674\n",
      "Epoch 49/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1869 - accuracy: 0.5321\n",
      "Epoch 49: val_accuracy did not improve from 0.61702\n",
      "10/10 [==============================] - 1s 52ms/step - loss: 0.1869 - accuracy: 0.5322 - val_loss: 0.2314 - val_accuracy: 0.4965\n",
      "Epoch 50/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1816 - accuracy: 0.5577\n",
      "Epoch 50: val_accuracy improved from 0.61702 to 0.63121, saving model to best_model_CNNLSTM.h5\n",
      "10/10 [==============================] - 1s 54ms/step - loss: 0.1816 - accuracy: 0.5578 - val_loss: 0.2011 - val_accuracy: 0.6312\n",
      "Epoch 51/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1815 - accuracy: 0.5625\n",
      "Epoch 51: val_accuracy did not improve from 0.63121\n",
      "10/10 [==============================] - 1s 51ms/step - loss: 0.1815 - accuracy: 0.5625 - val_loss: 0.2288 - val_accuracy: 0.4965\n",
      "Epoch 52/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1858 - accuracy: 0.5312\n",
      "Epoch 52: val_accuracy did not improve from 0.63121\n",
      "10/10 [==============================] - 1s 52ms/step - loss: 0.1860 - accuracy: 0.5301 - val_loss: 0.2355 - val_accuracy: 0.4610\n",
      "Epoch 53/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1872 - accuracy: 0.5278\n",
      "Epoch 53: val_accuracy did not improve from 0.63121\n",
      "10/10 [==============================] - 1s 53ms/step - loss: 0.1873 - accuracy: 0.5275 - val_loss: 0.2260 - val_accuracy: 0.5248\n",
      "Epoch 54/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1819 - accuracy: 0.5586\n",
      "Epoch 54: val_accuracy did not improve from 0.63121\n",
      "10/10 [==============================] - 1s 53ms/step - loss: 0.1818 - accuracy: 0.5586 - val_loss: 0.2319 - val_accuracy: 0.5106\n",
      "Epoch 55/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1832 - accuracy: 0.5586\n",
      "Epoch 55: val_accuracy did not improve from 0.63121\n",
      "10/10 [==============================] - 1s 53ms/step - loss: 0.1831 - accuracy: 0.5591 - val_loss: 0.2200 - val_accuracy: 0.5106\n",
      "Epoch 56/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1816 - accuracy: 0.5625\n",
      "Epoch 56: val_accuracy did not improve from 0.63121\n",
      "10/10 [==============================] - 1s 52ms/step - loss: 0.1815 - accuracy: 0.5630 - val_loss: 0.2082 - val_accuracy: 0.5319\n",
      "Epoch 57/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1790 - accuracy: 0.5755\n",
      "Epoch 57: val_accuracy did not improve from 0.63121\n",
      "10/10 [==============================] - 1s 53ms/step - loss: 0.1791 - accuracy: 0.5751 - val_loss: 0.2056 - val_accuracy: 0.5745\n",
      "Epoch 58/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1815 - accuracy: 0.5543\n",
      "Epoch 58: val_accuracy did not improve from 0.63121\n",
      "10/10 [==============================] - 1s 52ms/step - loss: 0.1813 - accuracy: 0.5552 - val_loss: 0.2064 - val_accuracy: 0.5177\n",
      "Epoch 59/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1788 - accuracy: 0.5773\n",
      "Epoch 59: val_accuracy did not improve from 0.63121\n",
      "10/10 [==============================] - 1s 52ms/step - loss: 0.1789 - accuracy: 0.5768 - val_loss: 0.2184 - val_accuracy: 0.5177\n",
      "Epoch 60/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1798 - accuracy: 0.5582\n",
      "Epoch 60: val_accuracy did not improve from 0.63121\n",
      "10/10 [==============================] - 1s 51ms/step - loss: 0.1799 - accuracy: 0.5578 - val_loss: 0.2014 - val_accuracy: 0.5816\n",
      "Epoch 61/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1831 - accuracy: 0.5599\n",
      "Epoch 61: val_accuracy did not improve from 0.63121\n",
      "10/10 [==============================] - 1s 52ms/step - loss: 0.1831 - accuracy: 0.5595 - val_loss: 0.2011 - val_accuracy: 0.5887\n",
      "Epoch 62/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1792 - accuracy: 0.5664\n",
      "Epoch 62: val_accuracy did not improve from 0.63121\n",
      "10/10 [==============================] - 1s 52ms/step - loss: 0.1791 - accuracy: 0.5669 - val_loss: 0.2119 - val_accuracy: 0.5532\n",
      "Epoch 63/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1788 - accuracy: 0.5751\n",
      "Epoch 63: val_accuracy did not improve from 0.63121\n",
      "10/10 [==============================] - 1s 51ms/step - loss: 0.1788 - accuracy: 0.5755 - val_loss: 0.2088 - val_accuracy: 0.5745\n",
      "Epoch 64/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1802 - accuracy: 0.5729\n",
      "Epoch 64: val_accuracy did not improve from 0.63121\n",
      "10/10 [==============================] - 1s 52ms/step - loss: 0.1802 - accuracy: 0.5725 - val_loss: 0.2053 - val_accuracy: 0.5957\n",
      "Epoch 65/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1781 - accuracy: 0.5729\n",
      "Epoch 65: val_accuracy did not improve from 0.63121\n",
      "10/10 [==============================] - 1s 53ms/step - loss: 0.1781 - accuracy: 0.5733 - val_loss: 0.2123 - val_accuracy: 0.5745\n",
      "Epoch 66/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1819 - accuracy: 0.5634\n",
      "Epoch 66: val_accuracy did not improve from 0.63121\n",
      "10/10 [==============================] - 1s 52ms/step - loss: 0.1818 - accuracy: 0.5634 - val_loss: 0.2231 - val_accuracy: 0.4539\n",
      "Epoch 67/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1838 - accuracy: 0.5530\n",
      "Epoch 67: val_accuracy did not improve from 0.63121\n",
      "10/10 [==============================] - 1s 53ms/step - loss: 0.1839 - accuracy: 0.5526 - val_loss: 0.2096 - val_accuracy: 0.5319\n",
      "Epoch 68/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1796 - accuracy: 0.5664\n",
      "Epoch 68: val_accuracy did not improve from 0.63121\n",
      "10/10 [==============================] - 1s 52ms/step - loss: 0.1794 - accuracy: 0.5669 - val_loss: 0.2131 - val_accuracy: 0.5532\n",
      "Epoch 69/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1780 - accuracy: 0.5673\n",
      "Epoch 69: val_accuracy did not improve from 0.63121\n",
      "10/10 [==============================] - 1s 52ms/step - loss: 0.1779 - accuracy: 0.5677 - val_loss: 0.2368 - val_accuracy: 0.4823\n",
      "Epoch 70/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1776 - accuracy: 0.5781\n",
      "Epoch 70: val_accuracy did not improve from 0.63121\n",
      "10/10 [==============================] - 1s 51ms/step - loss: 0.1776 - accuracy: 0.5781 - val_loss: 0.2210 - val_accuracy: 0.5957\n",
      "Epoch 71/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1786 - accuracy: 0.5681\n",
      "Epoch 71: val_accuracy did not improve from 0.63121\n",
      "10/10 [==============================] - 1s 51ms/step - loss: 0.1788 - accuracy: 0.5682 - val_loss: 0.2498 - val_accuracy: 0.3475\n",
      "Epoch 72/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1798 - accuracy: 0.5681\n",
      "Epoch 72: val_accuracy did not improve from 0.63121\n",
      "10/10 [==============================] - 1s 51ms/step - loss: 0.1798 - accuracy: 0.5686 - val_loss: 0.2209 - val_accuracy: 0.5745\n",
      "Epoch 73/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1774 - accuracy: 0.5720\n",
      "Epoch 73: val_accuracy did not improve from 0.63121\n",
      "10/10 [==============================] - 1s 51ms/step - loss: 0.1775 - accuracy: 0.5716 - val_loss: 0.2414 - val_accuracy: 0.4752\n",
      "Epoch 74/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1790 - accuracy: 0.5621\n",
      "Epoch 74: val_accuracy did not improve from 0.63121\n",
      "10/10 [==============================] - 1s 53ms/step - loss: 0.1791 - accuracy: 0.5617 - val_loss: 0.2375 - val_accuracy: 0.4894\n",
      "Epoch 75/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1768 - accuracy: 0.5760\n",
      "Epoch 75: val_accuracy did not improve from 0.63121\n",
      "10/10 [==============================] - 1s 52ms/step - loss: 0.1768 - accuracy: 0.5764 - val_loss: 0.2315 - val_accuracy: 0.4752\n",
      "Epoch 76/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1753 - accuracy: 0.5777\n",
      "Epoch 76: val_accuracy did not improve from 0.63121\n",
      "10/10 [==============================] - 1s 51ms/step - loss: 0.1753 - accuracy: 0.5777 - val_loss: 0.2105 - val_accuracy: 0.6028\n",
      "Epoch 77/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1767 - accuracy: 0.5712\n",
      "Epoch 77: val_accuracy did not improve from 0.63121\n",
      "10/10 [==============================] - 1s 51ms/step - loss: 0.1767 - accuracy: 0.5712 - val_loss: 0.2305 - val_accuracy: 0.4681\n",
      "Epoch 78/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1779 - accuracy: 0.5647\n",
      "Epoch 78: val_accuracy did not improve from 0.63121\n",
      "10/10 [==============================] - 1s 53ms/step - loss: 0.1780 - accuracy: 0.5638 - val_loss: 0.2343 - val_accuracy: 0.4752\n",
      "Epoch 79/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1826 - accuracy: 0.5547\n",
      "Epoch 79: val_accuracy did not improve from 0.63121\n",
      "10/10 [==============================] - 1s 53ms/step - loss: 0.1823 - accuracy: 0.5560 - val_loss: 0.2225 - val_accuracy: 0.4894\n",
      "Epoch 80/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1772 - accuracy: 0.5773\n",
      "Epoch 80: val_accuracy did not improve from 0.63121\n",
      "10/10 [==============================] - 1s 54ms/step - loss: 0.1773 - accuracy: 0.5772 - val_loss: 0.2359 - val_accuracy: 0.5106\n",
      "Epoch 81/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1767 - accuracy: 0.5738\n",
      "Epoch 81: val_accuracy did not improve from 0.63121\n",
      "10/10 [==============================] - 1s 53ms/step - loss: 0.1767 - accuracy: 0.5733 - val_loss: 0.2439 - val_accuracy: 0.4468\n",
      "Epoch 82/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1820 - accuracy: 0.5686\n",
      "Epoch 82: val_accuracy did not improve from 0.63121\n",
      "10/10 [==============================] - 1s 52ms/step - loss: 0.1819 - accuracy: 0.5686 - val_loss: 0.2516 - val_accuracy: 0.4043\n",
      "Epoch 83/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1784 - accuracy: 0.5725\n",
      "Epoch 83: val_accuracy did not improve from 0.63121\n",
      "10/10 [==============================] - 1s 53ms/step - loss: 0.1783 - accuracy: 0.5729 - val_loss: 0.2434 - val_accuracy: 0.4397\n",
      "Epoch 84/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1742 - accuracy: 0.5972\n",
      "Epoch 84: val_accuracy did not improve from 0.63121\n",
      "10/10 [==============================] - 1s 53ms/step - loss: 0.1743 - accuracy: 0.5967 - val_loss: 0.2248 - val_accuracy: 0.5532\n",
      "Epoch 85/500\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1751 - accuracy: 0.5785\n",
      "Epoch 85: val_accuracy did not improve from 0.63121\n",
      "10/10 [==============================] - 1s 50ms/step - loss: 0.1751 - accuracy: 0.5785 - val_loss: 0.2301 - val_accuracy: 0.4965\n",
      "Epoch 86/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1781 - accuracy: 0.5729\n",
      "Epoch 86: val_accuracy did not improve from 0.63121\n",
      "10/10 [==============================] - 1s 52ms/step - loss: 0.1780 - accuracy: 0.5733 - val_loss: 0.2374 - val_accuracy: 0.4468\n",
      "Epoch 87/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1747 - accuracy: 0.5825\n",
      "Epoch 87: val_accuracy did not improve from 0.63121\n",
      "10/10 [==============================] - 1s 53ms/step - loss: 0.1746 - accuracy: 0.5833 - val_loss: 0.2266 - val_accuracy: 0.4965\n",
      "Epoch 88/500\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1747 - accuracy: 0.5811\n",
      "Epoch 88: val_accuracy did not improve from 0.63121\n",
      "10/10 [==============================] - 1s 52ms/step - loss: 0.1747 - accuracy: 0.5811 - val_loss: 0.2119 - val_accuracy: 0.5603\n",
      "Epoch 89/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1795 - accuracy: 0.5686\n",
      "Epoch 89: val_accuracy did not improve from 0.63121\n",
      "10/10 [==============================] - 1s 53ms/step - loss: 0.1797 - accuracy: 0.5677 - val_loss: 0.2258 - val_accuracy: 0.4823\n",
      "Epoch 90/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1809 - accuracy: 0.5677\n",
      "Epoch 90: val_accuracy did not improve from 0.63121\n",
      "10/10 [==============================] - 1s 52ms/step - loss: 0.1810 - accuracy: 0.5669 - val_loss: 0.2261 - val_accuracy: 0.4752\n",
      "Epoch 91/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1764 - accuracy: 0.5681\n",
      "Epoch 91: val_accuracy did not improve from 0.63121\n",
      "10/10 [==============================] - 1s 53ms/step - loss: 0.1764 - accuracy: 0.5677 - val_loss: 0.2217 - val_accuracy: 0.4823\n",
      "Epoch 92/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1761 - accuracy: 0.5720\n",
      "Epoch 92: val_accuracy did not improve from 0.63121\n",
      "10/10 [==============================] - 1s 53ms/step - loss: 0.1759 - accuracy: 0.5733 - val_loss: 0.2155 - val_accuracy: 0.5035\n",
      "Epoch 93/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1746 - accuracy: 0.5872\n",
      "Epoch 93: val_accuracy did not improve from 0.63121\n",
      "10/10 [==============================] - 1s 52ms/step - loss: 0.1745 - accuracy: 0.5876 - val_loss: 0.2321 - val_accuracy: 0.3404\n",
      "Epoch 94/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1734 - accuracy: 0.5959\n",
      "Epoch 94: val_accuracy did not improve from 0.63121\n",
      "10/10 [==============================] - 1s 53ms/step - loss: 0.1733 - accuracy: 0.5967 - val_loss: 0.2189 - val_accuracy: 0.4326\n",
      "Epoch 95/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1732 - accuracy: 0.5964\n",
      "Epoch 95: val_accuracy did not improve from 0.63121\n",
      "10/10 [==============================] - 0s 48ms/step - loss: 0.1731 - accuracy: 0.5963 - val_loss: 0.2294 - val_accuracy: 0.3972\n",
      "Epoch 96/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1750 - accuracy: 0.5890\n",
      "Epoch 96: val_accuracy did not improve from 0.63121\n",
      "10/10 [==============================] - 1s 53ms/step - loss: 0.1752 - accuracy: 0.5885 - val_loss: 0.2628 - val_accuracy: 0.1915\n",
      "Epoch 97/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1811 - accuracy: 0.5729\n",
      "Epoch 97: val_accuracy did not improve from 0.63121\n",
      "10/10 [==============================] - 1s 53ms/step - loss: 0.1811 - accuracy: 0.5733 - val_loss: 0.2388 - val_accuracy: 0.4043\n",
      "Epoch 98/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1828 - accuracy: 0.5599\n",
      "Epoch 98: val_accuracy did not improve from 0.63121\n",
      "10/10 [==============================] - 1s 51ms/step - loss: 0.1826 - accuracy: 0.5604 - val_loss: 0.2213 - val_accuracy: 0.5319\n",
      "Epoch 99/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1733 - accuracy: 0.5938\n",
      "Epoch 99: val_accuracy did not improve from 0.63121\n",
      "10/10 [==============================] - 1s 53ms/step - loss: 0.1733 - accuracy: 0.5932 - val_loss: 0.2538 - val_accuracy: 0.2482\n",
      "Epoch 100/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1757 - accuracy: 0.5712\n",
      "Epoch 100: val_accuracy did not improve from 0.63121\n",
      "10/10 [==============================] - 1s 51ms/step - loss: 0.1756 - accuracy: 0.5716 - val_loss: 0.2190 - val_accuracy: 0.4823\n",
      "Epoch 1/500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-08 23:35:03.890136: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape insequential_6/dropout_12/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.2261 - accuracy: 0.3568\n",
      "Epoch 1: val_accuracy improved from -inf to 0.35036, saving model to best_model_CNNLSTM.h5\n",
      "10/10 [==============================] - 2s 67ms/step - loss: 0.2260 - accuracy: 0.3572 - val_loss: 0.2223 - val_accuracy: 0.3504\n",
      "Epoch 2/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.2146 - accuracy: 0.4323\n",
      "Epoch 2: val_accuracy did not improve from 0.35036\n",
      "10/10 [==============================] - 1s 50ms/step - loss: 0.2146 - accuracy: 0.4320 - val_loss: 0.2225 - val_accuracy: 0.3285\n",
      "Epoch 3/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.2091 - accuracy: 0.4727\n",
      "Epoch 3: val_accuracy did not improve from 0.35036\n",
      "10/10 [==============================] - 1s 53ms/step - loss: 0.2091 - accuracy: 0.4730 - val_loss: 0.2224 - val_accuracy: 0.3285\n",
      "Epoch 4/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.2051 - accuracy: 0.4883\n",
      "Epoch 4: val_accuracy did not improve from 0.35036\n",
      "10/10 [==============================] - 1s 52ms/step - loss: 0.2050 - accuracy: 0.4894 - val_loss: 0.2231 - val_accuracy: 0.3358\n",
      "Epoch 5/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1982 - accuracy: 0.5239\n",
      "Epoch 5: val_accuracy did not improve from 0.35036\n",
      "10/10 [==============================] - 1s 53ms/step - loss: 0.1982 - accuracy: 0.5227 - val_loss: 0.2229 - val_accuracy: 0.3285\n",
      "Epoch 6/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1975 - accuracy: 0.5065\n",
      "Epoch 6: val_accuracy did not improve from 0.35036\n",
      "10/10 [==============================] - 1s 50ms/step - loss: 0.1976 - accuracy: 0.5067 - val_loss: 0.2227 - val_accuracy: 0.3358\n",
      "Epoch 7/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1946 - accuracy: 0.5386\n",
      "Epoch 7: val_accuracy did not improve from 0.35036\n",
      "10/10 [==============================] - 1s 50ms/step - loss: 0.1945 - accuracy: 0.5395 - val_loss: 0.2221 - val_accuracy: 0.3431\n",
      "Epoch 8/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1943 - accuracy: 0.5382\n",
      "Epoch 8: val_accuracy did not improve from 0.35036\n",
      "10/10 [==============================] - 1s 53ms/step - loss: 0.1945 - accuracy: 0.5369 - val_loss: 0.2233 - val_accuracy: 0.3285\n",
      "Epoch 9/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1940 - accuracy: 0.5295\n",
      "Epoch 9: val_accuracy did not improve from 0.35036\n",
      "10/10 [==============================] - 1s 52ms/step - loss: 0.1940 - accuracy: 0.5296 - val_loss: 0.2225 - val_accuracy: 0.3358\n",
      "Epoch 10/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1913 - accuracy: 0.5516\n",
      "Epoch 10: val_accuracy did not improve from 0.35036\n",
      "10/10 [==============================] - 1s 52ms/step - loss: 0.1914 - accuracy: 0.5512 - val_loss: 0.2218 - val_accuracy: 0.3139\n",
      "Epoch 11/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1912 - accuracy: 0.5569\n",
      "Epoch 11: val_accuracy did not improve from 0.35036\n",
      "10/10 [==============================] - 1s 52ms/step - loss: 0.1913 - accuracy: 0.5568 - val_loss: 0.2252 - val_accuracy: 0.3358\n",
      "Epoch 12/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1909 - accuracy: 0.5525\n",
      "Epoch 12: val_accuracy did not improve from 0.35036\n",
      "10/10 [==============================] - 1s 52ms/step - loss: 0.1908 - accuracy: 0.5529 - val_loss: 0.2222 - val_accuracy: 0.3358\n",
      "Epoch 13/500\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1921 - accuracy: 0.5516\n",
      "Epoch 13: val_accuracy did not improve from 0.35036\n",
      "10/10 [==============================] - 1s 51ms/step - loss: 0.1921 - accuracy: 0.5516 - val_loss: 0.2217 - val_accuracy: 0.3431\n",
      "Epoch 14/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1915 - accuracy: 0.5438\n",
      "Epoch 14: val_accuracy did not improve from 0.35036\n",
      "10/10 [==============================] - 1s 53ms/step - loss: 0.1916 - accuracy: 0.5430 - val_loss: 0.2233 - val_accuracy: 0.3431\n",
      "Epoch 15/500\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1904 - accuracy: 0.5335\n",
      "Epoch 15: val_accuracy improved from 0.35036 to 0.35766, saving model to best_model_CNNLSTM.h5\n",
      "10/10 [==============================] - 1s 53ms/step - loss: 0.1904 - accuracy: 0.5335 - val_loss: 0.2225 - val_accuracy: 0.3577\n",
      "Epoch 16/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1904 - accuracy: 0.5530\n",
      "Epoch 16: val_accuracy did not improve from 0.35766\n",
      "10/10 [==============================] - 1s 53ms/step - loss: 0.1903 - accuracy: 0.5533 - val_loss: 0.2222 - val_accuracy: 0.3504\n",
      "Epoch 17/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1891 - accuracy: 0.5430\n",
      "Epoch 17: val_accuracy improved from 0.35766 to 0.37226, saving model to best_model_CNNLSTM.h5\n",
      "10/10 [==============================] - 1s 56ms/step - loss: 0.1891 - accuracy: 0.5425 - val_loss: 0.2262 - val_accuracy: 0.3723\n",
      "Epoch 18/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1907 - accuracy: 0.5521\n",
      "Epoch 18: val_accuracy did not improve from 0.37226\n",
      "10/10 [==============================] - 1s 53ms/step - loss: 0.1908 - accuracy: 0.5521 - val_loss: 0.2281 - val_accuracy: 0.3577\n",
      "Epoch 19/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1913 - accuracy: 0.5495\n",
      "Epoch 19: val_accuracy improved from 0.37226 to 0.38686, saving model to best_model_CNNLSTM.h5\n",
      "10/10 [==============================] - 1s 53ms/step - loss: 0.1912 - accuracy: 0.5503 - val_loss: 0.2182 - val_accuracy: 0.3869\n",
      "Epoch 20/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1894 - accuracy: 0.5447\n",
      "Epoch 20: val_accuracy did not improve from 0.38686\n",
      "10/10 [==============================] - 1s 51ms/step - loss: 0.1894 - accuracy: 0.5443 - val_loss: 0.2200 - val_accuracy: 0.3796\n",
      "Epoch 21/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1867 - accuracy: 0.5599\n",
      "Epoch 21: val_accuracy improved from 0.38686 to 0.42336, saving model to best_model_CNNLSTM.h5\n",
      "10/10 [==============================] - 1s 53ms/step - loss: 0.1867 - accuracy: 0.5598 - val_loss: 0.2238 - val_accuracy: 0.4234\n",
      "Epoch 22/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1883 - accuracy: 0.5586\n",
      "Epoch 22: val_accuracy did not improve from 0.42336\n",
      "10/10 [==============================] - 1s 53ms/step - loss: 0.1881 - accuracy: 0.5585 - val_loss: 0.2307 - val_accuracy: 0.4015\n",
      "Epoch 23/500\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1872 - accuracy: 0.5512\n",
      "Epoch 23: val_accuracy improved from 0.42336 to 0.43066, saving model to best_model_CNNLSTM.h5\n",
      "10/10 [==============================] - 1s 55ms/step - loss: 0.1872 - accuracy: 0.5512 - val_loss: 0.2330 - val_accuracy: 0.4307\n",
      "Epoch 24/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1857 - accuracy: 0.5686\n",
      "Epoch 24: val_accuracy improved from 0.43066 to 0.45985, saving model to best_model_CNNLSTM.h5\n",
      "10/10 [==============================] - 1s 55ms/step - loss: 0.1854 - accuracy: 0.5702 - val_loss: 0.2305 - val_accuracy: 0.4599\n",
      "Epoch 25/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1848 - accuracy: 0.5621\n",
      "Epoch 25: val_accuracy improved from 0.45985 to 0.46715, saving model to best_model_CNNLSTM.h5\n",
      "10/10 [==============================] - 1s 54ms/step - loss: 0.1848 - accuracy: 0.5629 - val_loss: 0.2213 - val_accuracy: 0.4672\n",
      "Epoch 26/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1869 - accuracy: 0.5625\n",
      "Epoch 26: val_accuracy did not improve from 0.46715\n",
      "10/10 [==============================] - 1s 53ms/step - loss: 0.1869 - accuracy: 0.5624 - val_loss: 0.2237 - val_accuracy: 0.4672\n",
      "Epoch 27/500\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1837 - accuracy: 0.5667\n",
      "Epoch 27: val_accuracy did not improve from 0.46715\n",
      "10/10 [==============================] - 1s 50ms/step - loss: 0.1837 - accuracy: 0.5667 - val_loss: 0.2289 - val_accuracy: 0.4307\n",
      "Epoch 28/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1880 - accuracy: 0.5482\n",
      "Epoch 28: val_accuracy did not improve from 0.46715\n",
      "10/10 [==============================] - 1s 50ms/step - loss: 0.1876 - accuracy: 0.5499 - val_loss: 0.2315 - val_accuracy: 0.4380\n",
      "Epoch 29/500\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1854 - accuracy: 0.5611\n",
      "Epoch 29: val_accuracy improved from 0.46715 to 0.47445, saving model to best_model_CNNLSTM.h5\n",
      "10/10 [==============================] - 1s 52ms/step - loss: 0.1854 - accuracy: 0.5611 - val_loss: 0.2280 - val_accuracy: 0.4745\n",
      "Epoch 30/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1851 - accuracy: 0.5725\n",
      "Epoch 30: val_accuracy improved from 0.47445 to 0.51095, saving model to best_model_CNNLSTM.h5\n",
      "10/10 [==============================] - 1s 54ms/step - loss: 0.1851 - accuracy: 0.5728 - val_loss: 0.2237 - val_accuracy: 0.5109\n",
      "Epoch 31/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1873 - accuracy: 0.5525\n",
      "Epoch 31: val_accuracy did not improve from 0.51095\n",
      "10/10 [==============================] - 1s 51ms/step - loss: 0.1876 - accuracy: 0.5521 - val_loss: 0.2266 - val_accuracy: 0.4964\n",
      "Epoch 32/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1850 - accuracy: 0.5638\n",
      "Epoch 32: val_accuracy did not improve from 0.51095\n",
      "10/10 [==============================] - 1s 52ms/step - loss: 0.1850 - accuracy: 0.5637 - val_loss: 0.2240 - val_accuracy: 0.4161\n",
      "Epoch 33/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1867 - accuracy: 0.5521\n",
      "Epoch 33: val_accuracy did not improve from 0.51095\n",
      "10/10 [==============================] - 1s 50ms/step - loss: 0.1865 - accuracy: 0.5529 - val_loss: 0.2331 - val_accuracy: 0.4161\n",
      "Epoch 34/500\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1861 - accuracy: 0.5525\n",
      "Epoch 34: val_accuracy did not improve from 0.51095\n",
      "10/10 [==============================] - 1s 51ms/step - loss: 0.1861 - accuracy: 0.5525 - val_loss: 0.2143 - val_accuracy: 0.4380\n",
      "Epoch 35/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1852 - accuracy: 0.5677\n",
      "Epoch 35: val_accuracy did not improve from 0.51095\n",
      "10/10 [==============================] - 1s 52ms/step - loss: 0.1854 - accuracy: 0.5672 - val_loss: 0.2165 - val_accuracy: 0.4234\n",
      "Epoch 36/500\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1867 - accuracy: 0.5516\n",
      "Epoch 36: val_accuracy did not improve from 0.51095\n",
      "10/10 [==============================] - 1s 52ms/step - loss: 0.1867 - accuracy: 0.5516 - val_loss: 0.2214 - val_accuracy: 0.4015\n",
      "Epoch 37/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1859 - accuracy: 0.5530\n",
      "Epoch 37: val_accuracy did not improve from 0.51095\n",
      "10/10 [==============================] - 1s 51ms/step - loss: 0.1858 - accuracy: 0.5542 - val_loss: 0.2190 - val_accuracy: 0.4891\n",
      "Epoch 38/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1845 - accuracy: 0.5690\n",
      "Epoch 38: val_accuracy did not improve from 0.51095\n",
      "10/10 [==============================] - 1s 50ms/step - loss: 0.1846 - accuracy: 0.5685 - val_loss: 0.2238 - val_accuracy: 0.4380\n",
      "Epoch 39/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1858 - accuracy: 0.5738\n",
      "Epoch 39: val_accuracy did not improve from 0.51095\n",
      "10/10 [==============================] - 0s 49ms/step - loss: 0.1855 - accuracy: 0.5749 - val_loss: 0.2256 - val_accuracy: 0.4672\n",
      "Epoch 40/500\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1855 - accuracy: 0.5521\n",
      "Epoch 40: val_accuracy did not improve from 0.51095\n",
      "10/10 [==============================] - 1s 49ms/step - loss: 0.1855 - accuracy: 0.5521 - val_loss: 0.2161 - val_accuracy: 0.4891\n",
      "Epoch 41/500\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1850 - accuracy: 0.5762\n",
      "Epoch 41: val_accuracy did not improve from 0.51095\n",
      "10/10 [==============================] - 1s 50ms/step - loss: 0.1850 - accuracy: 0.5762 - val_loss: 0.2152 - val_accuracy: 0.5109\n",
      "Epoch 42/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1875 - accuracy: 0.5538\n",
      "Epoch 42: val_accuracy did not improve from 0.51095\n",
      "10/10 [==============================] - 1s 50ms/step - loss: 0.1875 - accuracy: 0.5529 - val_loss: 0.1971 - val_accuracy: 0.5109\n",
      "Epoch 43/500\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1831 - accuracy: 0.5819\n",
      "Epoch 43: val_accuracy improved from 0.51095 to 0.59124, saving model to best_model_CNNLSTM.h5\n",
      "10/10 [==============================] - 1s 54ms/step - loss: 0.1831 - accuracy: 0.5819 - val_loss: 0.2192 - val_accuracy: 0.5912\n",
      "Epoch 44/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1843 - accuracy: 0.5621\n",
      "Epoch 44: val_accuracy did not improve from 0.59124\n",
      "10/10 [==============================] - 1s 51ms/step - loss: 0.1842 - accuracy: 0.5620 - val_loss: 0.2013 - val_accuracy: 0.5693\n",
      "Epoch 45/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1840 - accuracy: 0.5764\n",
      "Epoch 45: val_accuracy did not improve from 0.59124\n",
      "10/10 [==============================] - 1s 53ms/step - loss: 0.1841 - accuracy: 0.5771 - val_loss: 0.2133 - val_accuracy: 0.5693\n",
      "Epoch 46/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1819 - accuracy: 0.5690\n",
      "Epoch 46: val_accuracy did not improve from 0.59124\n",
      "10/10 [==============================] - 1s 52ms/step - loss: 0.1818 - accuracy: 0.5702 - val_loss: 0.2144 - val_accuracy: 0.4307\n",
      "Epoch 47/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1824 - accuracy: 0.5790\n",
      "Epoch 47: val_accuracy did not improve from 0.59124\n",
      "10/10 [==============================] - 1s 50ms/step - loss: 0.1826 - accuracy: 0.5788 - val_loss: 0.2081 - val_accuracy: 0.4526\n",
      "Epoch 48/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1822 - accuracy: 0.5616\n",
      "Epoch 48: val_accuracy did not improve from 0.59124\n",
      "10/10 [==============================] - 1s 51ms/step - loss: 0.1823 - accuracy: 0.5611 - val_loss: 0.2239 - val_accuracy: 0.4234\n",
      "Epoch 49/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1881 - accuracy: 0.5651\n",
      "Epoch 49: val_accuracy did not improve from 0.59124\n",
      "10/10 [==============================] - 0s 49ms/step - loss: 0.1883 - accuracy: 0.5637 - val_loss: 0.1972 - val_accuracy: 0.5182\n",
      "Epoch 50/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1887 - accuracy: 0.5312\n",
      "Epoch 50: val_accuracy did not improve from 0.59124\n",
      "10/10 [==============================] - 1s 52ms/step - loss: 0.1886 - accuracy: 0.5313 - val_loss: 0.2023 - val_accuracy: 0.4526\n",
      "Epoch 51/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1858 - accuracy: 0.5612\n",
      "Epoch 51: val_accuracy did not improve from 0.59124\n",
      "10/10 [==============================] - 1s 52ms/step - loss: 0.1856 - accuracy: 0.5620 - val_loss: 0.2215 - val_accuracy: 0.4891\n",
      "Epoch 52/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1865 - accuracy: 0.5616\n",
      "Epoch 52: val_accuracy did not improve from 0.59124\n",
      "10/10 [==============================] - 1s 51ms/step - loss: 0.1862 - accuracy: 0.5624 - val_loss: 0.2134 - val_accuracy: 0.5547\n",
      "Epoch 53/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1838 - accuracy: 0.5677\n",
      "Epoch 53: val_accuracy did not improve from 0.59124\n",
      "10/10 [==============================] - 1s 52ms/step - loss: 0.1839 - accuracy: 0.5680 - val_loss: 0.2315 - val_accuracy: 0.3577\n",
      "Epoch 54/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1834 - accuracy: 0.5586\n",
      "Epoch 54: val_accuracy did not improve from 0.59124\n",
      "10/10 [==============================] - 1s 52ms/step - loss: 0.1837 - accuracy: 0.5577 - val_loss: 0.2090 - val_accuracy: 0.5474\n",
      "Epoch 55/500\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1873 - accuracy: 0.5473\n",
      "Epoch 55: val_accuracy did not improve from 0.59124\n",
      "10/10 [==============================] - 1s 52ms/step - loss: 0.1873 - accuracy: 0.5473 - val_loss: 0.2178 - val_accuracy: 0.5547\n",
      "Epoch 56/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1865 - accuracy: 0.5469\n",
      "Epoch 56: val_accuracy did not improve from 0.59124\n",
      "10/10 [==============================] - 1s 52ms/step - loss: 0.1865 - accuracy: 0.5464 - val_loss: 0.2227 - val_accuracy: 0.4745\n",
      "Epoch 57/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1860 - accuracy: 0.5425\n",
      "Epoch 57: val_accuracy did not improve from 0.59124\n",
      "10/10 [==============================] - 1s 52ms/step - loss: 0.1858 - accuracy: 0.5430 - val_loss: 0.2175 - val_accuracy: 0.4672\n",
      "Epoch 58/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1830 - accuracy: 0.5686\n",
      "Epoch 58: val_accuracy did not improve from 0.59124\n",
      "10/10 [==============================] - 1s 51ms/step - loss: 0.1828 - accuracy: 0.5693 - val_loss: 0.2251 - val_accuracy: 0.5182\n",
      "Epoch 59/500\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1795 - accuracy: 0.5879\n",
      "Epoch 59: val_accuracy did not improve from 0.59124\n",
      "10/10 [==============================] - 1s 52ms/step - loss: 0.1795 - accuracy: 0.5879 - val_loss: 0.2240 - val_accuracy: 0.4672\n",
      "Epoch 60/500\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1822 - accuracy: 0.5711\n",
      "Epoch 60: val_accuracy did not improve from 0.59124\n",
      "10/10 [==============================] - 1s 52ms/step - loss: 0.1822 - accuracy: 0.5711 - val_loss: 0.2119 - val_accuracy: 0.4599\n",
      "Epoch 61/500\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1833 - accuracy: 0.5663\n",
      "Epoch 61: val_accuracy did not improve from 0.59124\n",
      "10/10 [==============================] - 1s 51ms/step - loss: 0.1833 - accuracy: 0.5663 - val_loss: 0.2184 - val_accuracy: 0.5109\n",
      "Epoch 62/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1781 - accuracy: 0.5868\n",
      "Epoch 62: val_accuracy did not improve from 0.59124\n",
      "10/10 [==============================] - 1s 52ms/step - loss: 0.1785 - accuracy: 0.5853 - val_loss: 0.2208 - val_accuracy: 0.5255\n",
      "Epoch 63/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1828 - accuracy: 0.5790\n",
      "Epoch 63: val_accuracy did not improve from 0.59124\n",
      "10/10 [==============================] - 1s 53ms/step - loss: 0.1829 - accuracy: 0.5784 - val_loss: 0.2074 - val_accuracy: 0.5401\n",
      "Epoch 64/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1828 - accuracy: 0.5664\n",
      "Epoch 64: val_accuracy did not improve from 0.59124\n",
      "10/10 [==============================] - 1s 50ms/step - loss: 0.1829 - accuracy: 0.5667 - val_loss: 0.2044 - val_accuracy: 0.5474\n",
      "Epoch 65/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1837 - accuracy: 0.5720\n",
      "Epoch 65: val_accuracy did not improve from 0.59124\n",
      "10/10 [==============================] - 1s 52ms/step - loss: 0.1835 - accuracy: 0.5724 - val_loss: 0.2074 - val_accuracy: 0.4380\n",
      "Epoch 66/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1824 - accuracy: 0.5760\n",
      "Epoch 66: val_accuracy did not improve from 0.59124\n",
      "10/10 [==============================] - 1s 51ms/step - loss: 0.1824 - accuracy: 0.5758 - val_loss: 0.2215 - val_accuracy: 0.5182\n",
      "Epoch 67/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1801 - accuracy: 0.5842\n",
      "Epoch 67: val_accuracy did not improve from 0.59124\n",
      "10/10 [==============================] - 1s 51ms/step - loss: 0.1805 - accuracy: 0.5832 - val_loss: 0.2178 - val_accuracy: 0.4161\n",
      "Epoch 68/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1809 - accuracy: 0.5755\n",
      "Epoch 68: val_accuracy did not improve from 0.59124\n",
      "10/10 [==============================] - 1s 51ms/step - loss: 0.1810 - accuracy: 0.5754 - val_loss: 0.2153 - val_accuracy: 0.4234\n",
      "Epoch 69/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1806 - accuracy: 0.5764\n",
      "Epoch 69: val_accuracy did not improve from 0.59124\n",
      "10/10 [==============================] - 1s 52ms/step - loss: 0.1805 - accuracy: 0.5767 - val_loss: 0.2261 - val_accuracy: 0.4088\n",
      "Epoch 70/500\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1794 - accuracy: 0.5819\n",
      "Epoch 70: val_accuracy did not improve from 0.59124\n",
      "10/10 [==============================] - 1s 50ms/step - loss: 0.1794 - accuracy: 0.5819 - val_loss: 0.2205 - val_accuracy: 0.4526\n",
      "Epoch 71/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1782 - accuracy: 0.5859\n",
      "Epoch 71: val_accuracy did not improve from 0.59124\n",
      "10/10 [==============================] - 1s 53ms/step - loss: 0.1782 - accuracy: 0.5866 - val_loss: 0.2121 - val_accuracy: 0.5839\n",
      "Epoch 72/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1798 - accuracy: 0.5734\n",
      "Epoch 72: val_accuracy improved from 0.59124 to 0.61314, saving model to best_model_CNNLSTM.h5\n",
      "10/10 [==============================] - 1s 55ms/step - loss: 0.1799 - accuracy: 0.5728 - val_loss: 0.1900 - val_accuracy: 0.6131\n",
      "Epoch 73/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1804 - accuracy: 0.5781\n",
      "Epoch 73: val_accuracy did not improve from 0.61314\n",
      "10/10 [==============================] - 1s 52ms/step - loss: 0.1803 - accuracy: 0.5780 - val_loss: 0.1890 - val_accuracy: 0.5912\n",
      "Epoch 74/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1793 - accuracy: 0.5777\n",
      "Epoch 74: val_accuracy did not improve from 0.61314\n",
      "10/10 [==============================] - 1s 53ms/step - loss: 0.1792 - accuracy: 0.5784 - val_loss: 0.2331 - val_accuracy: 0.4745\n",
      "Epoch 75/500\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1819 - accuracy: 0.5512\n",
      "Epoch 75: val_accuracy did not improve from 0.61314\n",
      "10/10 [==============================] - 1s 52ms/step - loss: 0.1819 - accuracy: 0.5512 - val_loss: 0.2080 - val_accuracy: 0.5036\n",
      "Epoch 76/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1820 - accuracy: 0.5707\n",
      "Epoch 76: val_accuracy did not improve from 0.61314\n",
      "10/10 [==============================] - 1s 51ms/step - loss: 0.1820 - accuracy: 0.5702 - val_loss: 0.1969 - val_accuracy: 0.5401\n",
      "Epoch 77/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1825 - accuracy: 0.5694\n",
      "Epoch 77: val_accuracy did not improve from 0.61314\n",
      "10/10 [==============================] - 1s 50ms/step - loss: 0.1826 - accuracy: 0.5689 - val_loss: 0.1904 - val_accuracy: 0.5839\n",
      "Epoch 78/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1823 - accuracy: 0.5751\n",
      "Epoch 78: val_accuracy did not improve from 0.61314\n",
      "10/10 [==============================] - 1s 51ms/step - loss: 0.1825 - accuracy: 0.5741 - val_loss: 0.2023 - val_accuracy: 0.5693\n",
      "Epoch 79/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1823 - accuracy: 0.5551\n",
      "Epoch 79: val_accuracy did not improve from 0.61314\n",
      "10/10 [==============================] - 1s 53ms/step - loss: 0.1824 - accuracy: 0.5546 - val_loss: 0.1825 - val_accuracy: 0.5547\n",
      "Epoch 80/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1797 - accuracy: 0.5942\n",
      "Epoch 80: val_accuracy did not improve from 0.61314\n",
      "10/10 [==============================] - 1s 53ms/step - loss: 0.1798 - accuracy: 0.5935 - val_loss: 0.1895 - val_accuracy: 0.5912\n",
      "Epoch 81/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1816 - accuracy: 0.5681\n",
      "Epoch 81: val_accuracy did not improve from 0.61314\n",
      "10/10 [==============================] - 1s 51ms/step - loss: 0.1816 - accuracy: 0.5676 - val_loss: 0.1989 - val_accuracy: 0.5912\n",
      "Epoch 82/500\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1781 - accuracy: 0.5892\n",
      "Epoch 82: val_accuracy did not improve from 0.61314\n",
      "10/10 [==============================] - 1s 50ms/step - loss: 0.1781 - accuracy: 0.5892 - val_loss: 0.1872 - val_accuracy: 0.6131\n",
      "Epoch 83/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1808 - accuracy: 0.5521\n",
      "Epoch 83: val_accuracy improved from 0.61314 to 0.62774, saving model to best_model_CNNLSTM.h5\n",
      "10/10 [==============================] - 1s 53ms/step - loss: 0.1807 - accuracy: 0.5525 - val_loss: 0.1996 - val_accuracy: 0.6277\n",
      "Epoch 84/500\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1804 - accuracy: 0.5672\n",
      "Epoch 84: val_accuracy did not improve from 0.62774\n",
      "10/10 [==============================] - 1s 51ms/step - loss: 0.1804 - accuracy: 0.5672 - val_loss: 0.1795 - val_accuracy: 0.5474\n",
      "Epoch 85/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1796 - accuracy: 0.5742\n",
      "Epoch 85: val_accuracy did not improve from 0.62774\n",
      "10/10 [==============================] - 1s 50ms/step - loss: 0.1794 - accuracy: 0.5741 - val_loss: 0.1840 - val_accuracy: 0.5620\n",
      "Epoch 86/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1795 - accuracy: 0.5747\n",
      "Epoch 86: val_accuracy did not improve from 0.62774\n",
      "10/10 [==============================] - 1s 52ms/step - loss: 0.1793 - accuracy: 0.5749 - val_loss: 0.2153 - val_accuracy: 0.5839\n",
      "Epoch 87/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1795 - accuracy: 0.5777\n",
      "Epoch 87: val_accuracy did not improve from 0.62774\n",
      "10/10 [==============================] - 1s 53ms/step - loss: 0.1795 - accuracy: 0.5775 - val_loss: 0.2031 - val_accuracy: 0.5547\n",
      "Epoch 88/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1804 - accuracy: 0.5647\n",
      "Epoch 88: val_accuracy did not improve from 0.62774\n",
      "10/10 [==============================] - 1s 51ms/step - loss: 0.1805 - accuracy: 0.5641 - val_loss: 0.1865 - val_accuracy: 0.5401\n",
      "Epoch 89/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1774 - accuracy: 0.5773\n",
      "Epoch 89: val_accuracy did not improve from 0.62774\n",
      "10/10 [==============================] - 1s 51ms/step - loss: 0.1773 - accuracy: 0.5784 - val_loss: 0.2055 - val_accuracy: 0.5036\n",
      "Epoch 90/500\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1782 - accuracy: 0.5711\n",
      "Epoch 90: val_accuracy did not improve from 0.62774\n",
      "10/10 [==============================] - 1s 51ms/step - loss: 0.1782 - accuracy: 0.5711 - val_loss: 0.2043 - val_accuracy: 0.4380\n",
      "Epoch 91/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1814 - accuracy: 0.5638\n",
      "Epoch 91: val_accuracy did not improve from 0.62774\n",
      "10/10 [==============================] - 1s 50ms/step - loss: 0.1816 - accuracy: 0.5624 - val_loss: 0.1984 - val_accuracy: 0.5474\n",
      "Epoch 92/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1817 - accuracy: 0.5495\n",
      "Epoch 92: val_accuracy did not improve from 0.62774\n",
      "10/10 [==============================] - 1s 51ms/step - loss: 0.1817 - accuracy: 0.5495 - val_loss: 0.1939 - val_accuracy: 0.5036\n",
      "Epoch 93/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1795 - accuracy: 0.5677\n",
      "Epoch 93: val_accuracy did not improve from 0.62774\n",
      "10/10 [==============================] - 1s 53ms/step - loss: 0.1797 - accuracy: 0.5672 - val_loss: 0.1791 - val_accuracy: 0.5474\n",
      "Epoch 94/500\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1788 - accuracy: 0.5780\n",
      "Epoch 94: val_accuracy did not improve from 0.62774\n",
      "10/10 [==============================] - 0s 49ms/step - loss: 0.1788 - accuracy: 0.5780 - val_loss: 0.2316 - val_accuracy: 0.4234\n",
      "Epoch 95/500\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1779 - accuracy: 0.5745\n",
      "Epoch 95: val_accuracy did not improve from 0.62774\n",
      "10/10 [==============================] - 1s 51ms/step - loss: 0.1779 - accuracy: 0.5745 - val_loss: 0.2199 - val_accuracy: 0.3358\n",
      "Epoch 96/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1766 - accuracy: 0.5742\n",
      "Epoch 96: val_accuracy did not improve from 0.62774\n",
      "10/10 [==============================] - 1s 52ms/step - loss: 0.1766 - accuracy: 0.5745 - val_loss: 0.2046 - val_accuracy: 0.4380\n",
      "Epoch 97/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1797 - accuracy: 0.5699\n",
      "Epoch 97: val_accuracy did not improve from 0.62774\n",
      "10/10 [==============================] - 1s 49ms/step - loss: 0.1796 - accuracy: 0.5711 - val_loss: 0.2071 - val_accuracy: 0.3504\n",
      "Epoch 98/500\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1762 - accuracy: 0.6039\n",
      "Epoch 98: val_accuracy did not improve from 0.62774\n",
      "10/10 [==============================] - 1s 51ms/step - loss: 0.1762 - accuracy: 0.6039 - val_loss: 0.1911 - val_accuracy: 0.4380\n",
      "Epoch 99/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1792 - accuracy: 0.5673\n",
      "Epoch 99: val_accuracy did not improve from 0.62774\n",
      "10/10 [==============================] - 1s 52ms/step - loss: 0.1793 - accuracy: 0.5672 - val_loss: 0.2012 - val_accuracy: 0.4818\n",
      "Epoch 100/500\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1768 - accuracy: 0.5762\n",
      "Epoch 100: val_accuracy did not improve from 0.62774\n",
      "10/10 [==============================] - 1s 50ms/step - loss: 0.1768 - accuracy: 0.5762 - val_loss: 0.1976 - val_accuracy: 0.5255\n",
      "Epoch 101/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1743 - accuracy: 0.5885\n",
      "Epoch 101: val_accuracy did not improve from 0.62774\n",
      "10/10 [==============================] - 1s 52ms/step - loss: 0.1743 - accuracy: 0.5888 - val_loss: 0.1908 - val_accuracy: 0.5547\n",
      "Epoch 102/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1775 - accuracy: 0.5812\n",
      "Epoch 102: val_accuracy did not improve from 0.62774\n",
      "10/10 [==============================] - 1s 52ms/step - loss: 0.1773 - accuracy: 0.5819 - val_loss: 0.2082 - val_accuracy: 0.5109\n",
      "Epoch 103/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1799 - accuracy: 0.5829\n",
      "Epoch 103: val_accuracy did not improve from 0.62774\n",
      "10/10 [==============================] - 1s 52ms/step - loss: 0.1799 - accuracy: 0.5827 - val_loss: 0.1860 - val_accuracy: 0.5401\n",
      "Epoch 104/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1734 - accuracy: 0.5951\n",
      "Epoch 104: val_accuracy did not improve from 0.62774\n",
      "10/10 [==============================] - 1s 51ms/step - loss: 0.1734 - accuracy: 0.5948 - val_loss: 0.2070 - val_accuracy: 0.5182\n",
      "Epoch 105/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1764 - accuracy: 0.5872\n",
      "Epoch 105: val_accuracy did not improve from 0.62774\n",
      "10/10 [==============================] - 1s 52ms/step - loss: 0.1766 - accuracy: 0.5862 - val_loss: 0.2002 - val_accuracy: 0.4964\n",
      "Epoch 106/500\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1745 - accuracy: 0.5853\n",
      "Epoch 106: val_accuracy did not improve from 0.62774\n",
      "10/10 [==============================] - 1s 52ms/step - loss: 0.1745 - accuracy: 0.5853 - val_loss: 0.2086 - val_accuracy: 0.3869\n",
      "Epoch 107/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1764 - accuracy: 0.5985\n",
      "Epoch 107: val_accuracy did not improve from 0.62774\n",
      "10/10 [==============================] - 1s 52ms/step - loss: 0.1764 - accuracy: 0.5978 - val_loss: 0.2186 - val_accuracy: 0.3577\n",
      "Epoch 108/500\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1756 - accuracy: 0.5931\n",
      "Epoch 108: val_accuracy did not improve from 0.62774\n",
      "10/10 [==============================] - 1s 50ms/step - loss: 0.1756 - accuracy: 0.5931 - val_loss: 0.2096 - val_accuracy: 0.3650\n",
      "Epoch 109/500\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1745 - accuracy: 0.5909\n",
      "Epoch 109: val_accuracy did not improve from 0.62774\n",
      "10/10 [==============================] - 1s 51ms/step - loss: 0.1745 - accuracy: 0.5909 - val_loss: 0.2197 - val_accuracy: 0.3212\n",
      "Epoch 110/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1751 - accuracy: 0.5799\n",
      "Epoch 110: val_accuracy did not improve from 0.62774\n",
      "10/10 [==============================] - 1s 51ms/step - loss: 0.1750 - accuracy: 0.5801 - val_loss: 0.2068 - val_accuracy: 0.3869\n",
      "Epoch 111/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1735 - accuracy: 0.5964\n",
      "Epoch 111: val_accuracy did not improve from 0.62774\n",
      "10/10 [==============================] - 1s 49ms/step - loss: 0.1737 - accuracy: 0.5961 - val_loss: 0.2026 - val_accuracy: 0.5255\n",
      "Epoch 112/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1785 - accuracy: 0.5703\n",
      "Epoch 112: val_accuracy did not improve from 0.62774\n",
      "10/10 [==============================] - 1s 51ms/step - loss: 0.1787 - accuracy: 0.5693 - val_loss: 0.2275 - val_accuracy: 0.3650\n",
      "Epoch 113/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1777 - accuracy: 0.5660\n",
      "Epoch 113: val_accuracy did not improve from 0.62774\n",
      "10/10 [==============================] - 1s 51ms/step - loss: 0.1778 - accuracy: 0.5663 - val_loss: 0.1875 - val_accuracy: 0.5036\n",
      "Epoch 114/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1784 - accuracy: 0.5720\n",
      "Epoch 114: val_accuracy did not improve from 0.62774\n",
      "10/10 [==============================] - 1s 53ms/step - loss: 0.1783 - accuracy: 0.5715 - val_loss: 0.2039 - val_accuracy: 0.4599\n",
      "Epoch 115/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1793 - accuracy: 0.5655\n",
      "Epoch 115: val_accuracy did not improve from 0.62774\n",
      "10/10 [==============================] - 1s 51ms/step - loss: 0.1794 - accuracy: 0.5650 - val_loss: 0.1959 - val_accuracy: 0.4745\n",
      "Epoch 116/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1774 - accuracy: 0.5799\n",
      "Epoch 116: val_accuracy did not improve from 0.62774\n",
      "10/10 [==============================] - 1s 52ms/step - loss: 0.1774 - accuracy: 0.5806 - val_loss: 0.2265 - val_accuracy: 0.4891\n",
      "Epoch 117/500\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1786 - accuracy: 0.5870\n",
      "Epoch 117: val_accuracy did not improve from 0.62774\n",
      "10/10 [==============================] - 1s 51ms/step - loss: 0.1786 - accuracy: 0.5870 - val_loss: 0.1861 - val_accuracy: 0.5328\n",
      "Epoch 118/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1779 - accuracy: 0.5781\n",
      "Epoch 118: val_accuracy did not improve from 0.62774\n",
      "10/10 [==============================] - 1s 51ms/step - loss: 0.1780 - accuracy: 0.5771 - val_loss: 0.2091 - val_accuracy: 0.4526\n",
      "Epoch 119/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1769 - accuracy: 0.5807\n",
      "Epoch 119: val_accuracy did not improve from 0.62774\n",
      "10/10 [==============================] - 1s 51ms/step - loss: 0.1768 - accuracy: 0.5810 - val_loss: 0.1986 - val_accuracy: 0.5182\n",
      "Epoch 120/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1769 - accuracy: 0.5829\n",
      "Epoch 120: val_accuracy did not improve from 0.62774\n",
      "10/10 [==============================] - 1s 51ms/step - loss: 0.1768 - accuracy: 0.5832 - val_loss: 0.1914 - val_accuracy: 0.5620\n",
      "Epoch 121/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1775 - accuracy: 0.5920\n",
      "Epoch 121: val_accuracy improved from 0.62774 to 0.66423, saving model to best_model_CNNLSTM.h5\n",
      "10/10 [==============================] - 1s 55ms/step - loss: 0.1777 - accuracy: 0.5901 - val_loss: 0.1741 - val_accuracy: 0.6642\n",
      "Epoch 122/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1788 - accuracy: 0.5651\n",
      "Epoch 122: val_accuracy did not improve from 0.66423\n",
      "10/10 [==============================] - 1s 53ms/step - loss: 0.1786 - accuracy: 0.5663 - val_loss: 0.1768 - val_accuracy: 0.6423\n",
      "Epoch 123/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1743 - accuracy: 0.5981\n",
      "Epoch 123: val_accuracy did not improve from 0.66423\n",
      "10/10 [==============================] - 1s 52ms/step - loss: 0.1741 - accuracy: 0.5987 - val_loss: 0.1878 - val_accuracy: 0.4964\n",
      "Epoch 124/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1735 - accuracy: 0.5833\n",
      "Epoch 124: val_accuracy did not improve from 0.66423\n",
      "10/10 [==============================] - 1s 51ms/step - loss: 0.1737 - accuracy: 0.5827 - val_loss: 0.1846 - val_accuracy: 0.5401\n",
      "Epoch 125/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1743 - accuracy: 0.5786\n",
      "Epoch 125: val_accuracy did not improve from 0.66423\n",
      "10/10 [==============================] - 1s 53ms/step - loss: 0.1744 - accuracy: 0.5775 - val_loss: 0.2053 - val_accuracy: 0.4453\n",
      "Epoch 126/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1767 - accuracy: 0.5803\n",
      "Epoch 126: val_accuracy improved from 0.66423 to 0.67883, saving model to best_model_CNNLSTM.h5\n",
      "10/10 [==============================] - 1s 54ms/step - loss: 0.1767 - accuracy: 0.5801 - val_loss: 0.1755 - val_accuracy: 0.6788\n",
      "Epoch 127/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1766 - accuracy: 0.5872\n",
      "Epoch 127: val_accuracy did not improve from 0.67883\n",
      "10/10 [==============================] - 1s 50ms/step - loss: 0.1766 - accuracy: 0.5875 - val_loss: 0.2120 - val_accuracy: 0.4015\n",
      "Epoch 128/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1765 - accuracy: 0.5764\n",
      "Epoch 128: val_accuracy did not improve from 0.67883\n",
      "10/10 [==============================] - 0s 49ms/step - loss: 0.1764 - accuracy: 0.5762 - val_loss: 0.1976 - val_accuracy: 0.4818\n",
      "Epoch 129/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1754 - accuracy: 0.5898\n",
      "Epoch 129: val_accuracy did not improve from 0.67883\n",
      "10/10 [==============================] - 1s 52ms/step - loss: 0.1757 - accuracy: 0.5896 - val_loss: 0.1824 - val_accuracy: 0.6204\n",
      "Epoch 130/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1764 - accuracy: 0.5825\n",
      "Epoch 130: val_accuracy did not improve from 0.67883\n",
      "10/10 [==============================] - 1s 50ms/step - loss: 0.1765 - accuracy: 0.5827 - val_loss: 0.1768 - val_accuracy: 0.5912\n",
      "Epoch 131/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1716 - accuracy: 0.5907\n",
      "Epoch 131: val_accuracy did not improve from 0.67883\n",
      "10/10 [==============================] - 0s 48ms/step - loss: 0.1716 - accuracy: 0.5905 - val_loss: 0.1837 - val_accuracy: 0.5693\n",
      "Epoch 132/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1738 - accuracy: 0.5881\n",
      "Epoch 132: val_accuracy did not improve from 0.67883\n",
      "10/10 [==============================] - 1s 50ms/step - loss: 0.1740 - accuracy: 0.5862 - val_loss: 0.1869 - val_accuracy: 0.5693\n",
      "Epoch 133/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1739 - accuracy: 0.5881\n",
      "Epoch 133: val_accuracy did not improve from 0.67883\n",
      "10/10 [==============================] - 1s 50ms/step - loss: 0.1737 - accuracy: 0.5883 - val_loss: 0.2142 - val_accuracy: 0.3723\n",
      "Epoch 134/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1739 - accuracy: 0.5898\n",
      "Epoch 134: val_accuracy did not improve from 0.67883\n",
      "10/10 [==============================] - 1s 52ms/step - loss: 0.1739 - accuracy: 0.5892 - val_loss: 0.2017 - val_accuracy: 0.4234\n",
      "Epoch 135/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1732 - accuracy: 0.5942\n",
      "Epoch 135: val_accuracy did not improve from 0.67883\n",
      "10/10 [==============================] - 0s 49ms/step - loss: 0.1729 - accuracy: 0.5948 - val_loss: 0.2432 - val_accuracy: 0.2628\n",
      "Epoch 136/500\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1747 - accuracy: 0.5909\n",
      "Epoch 136: val_accuracy did not improve from 0.67883\n",
      "10/10 [==============================] - 0s 49ms/step - loss: 0.1747 - accuracy: 0.5909 - val_loss: 0.2126 - val_accuracy: 0.4234\n",
      "Epoch 137/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1746 - accuracy: 0.5885\n",
      "Epoch 137: val_accuracy did not improve from 0.67883\n",
      "10/10 [==============================] - 0s 49ms/step - loss: 0.1748 - accuracy: 0.5875 - val_loss: 0.2014 - val_accuracy: 0.3942\n",
      "Epoch 138/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1755 - accuracy: 0.5833\n",
      "Epoch 138: val_accuracy did not improve from 0.67883\n",
      "10/10 [==============================] - 1s 51ms/step - loss: 0.1756 - accuracy: 0.5827 - val_loss: 0.2111 - val_accuracy: 0.4161\n",
      "Epoch 139/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1743 - accuracy: 0.5872\n",
      "Epoch 139: val_accuracy did not improve from 0.67883\n",
      "10/10 [==============================] - 1s 52ms/step - loss: 0.1743 - accuracy: 0.5870 - val_loss: 0.2065 - val_accuracy: 0.4672\n",
      "Epoch 140/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1771 - accuracy: 0.5694\n",
      "Epoch 140: val_accuracy did not improve from 0.67883\n",
      "10/10 [==============================] - 1s 50ms/step - loss: 0.1773 - accuracy: 0.5693 - val_loss: 0.2076 - val_accuracy: 0.4453\n",
      "Epoch 141/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1730 - accuracy: 0.5907\n",
      "Epoch 141: val_accuracy did not improve from 0.67883\n",
      "10/10 [==============================] - 0s 50ms/step - loss: 0.1730 - accuracy: 0.5909 - val_loss: 0.1775 - val_accuracy: 0.6423\n",
      "Epoch 142/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1737 - accuracy: 0.5924\n",
      "Epoch 142: val_accuracy did not improve from 0.67883\n",
      "10/10 [==============================] - 0s 48ms/step - loss: 0.1741 - accuracy: 0.5909 - val_loss: 0.2078 - val_accuracy: 0.3869\n",
      "Epoch 143/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1750 - accuracy: 0.5842\n",
      "Epoch 143: val_accuracy did not improve from 0.67883\n",
      "10/10 [==============================] - 1s 52ms/step - loss: 0.1752 - accuracy: 0.5832 - val_loss: 0.2259 - val_accuracy: 0.2628\n",
      "Epoch 144/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1722 - accuracy: 0.6037\n",
      "Epoch 144: val_accuracy did not improve from 0.67883\n",
      "10/10 [==============================] - 0s 49ms/step - loss: 0.1722 - accuracy: 0.6030 - val_loss: 0.2024 - val_accuracy: 0.4088\n",
      "Epoch 145/500\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1752 - accuracy: 0.5827\n",
      "Epoch 145: val_accuracy did not improve from 0.67883\n",
      "10/10 [==============================] - 1s 50ms/step - loss: 0.1752 - accuracy: 0.5827 - val_loss: 0.2095 - val_accuracy: 0.3869\n",
      "Epoch 146/500\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1716 - accuracy: 0.5892\n",
      "Epoch 146: val_accuracy did not improve from 0.67883\n",
      "10/10 [==============================] - 0s 50ms/step - loss: 0.1716 - accuracy: 0.5892 - val_loss: 0.1922 - val_accuracy: 0.5182\n",
      "Epoch 147/500\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1756 - accuracy: 0.5741\n",
      "Epoch 147: val_accuracy did not improve from 0.67883\n",
      "10/10 [==============================] - 0s 49ms/step - loss: 0.1756 - accuracy: 0.5741 - val_loss: 0.1962 - val_accuracy: 0.4599\n",
      "Epoch 148/500\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1729 - accuracy: 0.5914\n",
      "Epoch 148: val_accuracy did not improve from 0.67883\n",
      "10/10 [==============================] - 0s 48ms/step - loss: 0.1729 - accuracy: 0.5914 - val_loss: 0.1994 - val_accuracy: 0.4307\n",
      "Epoch 149/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1746 - accuracy: 0.5985\n",
      "Epoch 149: val_accuracy did not improve from 0.67883\n",
      "10/10 [==============================] - 1s 51ms/step - loss: 0.1745 - accuracy: 0.5987 - val_loss: 0.2060 - val_accuracy: 0.4161\n",
      "Epoch 150/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1739 - accuracy: 0.5851\n",
      "Epoch 150: val_accuracy did not improve from 0.67883\n",
      "10/10 [==============================] - 1s 50ms/step - loss: 0.1737 - accuracy: 0.5862 - val_loss: 0.1867 - val_accuracy: 0.5328\n",
      "Epoch 151/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1703 - accuracy: 0.5959\n",
      "Epoch 151: val_accuracy did not improve from 0.67883\n",
      "10/10 [==============================] - 1s 52ms/step - loss: 0.1704 - accuracy: 0.5952 - val_loss: 0.2037 - val_accuracy: 0.4599\n",
      "Epoch 152/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1713 - accuracy: 0.6020\n",
      "Epoch 152: val_accuracy did not improve from 0.67883\n",
      "10/10 [==============================] - 1s 50ms/step - loss: 0.1713 - accuracy: 0.6013 - val_loss: 0.1913 - val_accuracy: 0.5182\n",
      "Epoch 153/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1715 - accuracy: 0.5938\n",
      "Epoch 153: val_accuracy did not improve from 0.67883\n",
      "10/10 [==============================] - 1s 52ms/step - loss: 0.1716 - accuracy: 0.5935 - val_loss: 0.1774 - val_accuracy: 0.5766\n",
      "Epoch 154/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1720 - accuracy: 0.6016\n",
      "Epoch 154: val_accuracy did not improve from 0.67883\n",
      "10/10 [==============================] - 1s 53ms/step - loss: 0.1721 - accuracy: 0.6017 - val_loss: 0.2036 - val_accuracy: 0.5109\n",
      "Epoch 155/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1709 - accuracy: 0.5977\n",
      "Epoch 155: val_accuracy did not improve from 0.67883\n",
      "10/10 [==============================] - 1s 52ms/step - loss: 0.1712 - accuracy: 0.5965 - val_loss: 0.1949 - val_accuracy: 0.5036\n",
      "Epoch 156/500\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1711 - accuracy: 0.6030\n",
      "Epoch 156: val_accuracy did not improve from 0.67883\n",
      "10/10 [==============================] - 1s 51ms/step - loss: 0.1711 - accuracy: 0.6030 - val_loss: 0.1868 - val_accuracy: 0.5182\n",
      "Epoch 157/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1743 - accuracy: 0.5864\n",
      "Epoch 157: val_accuracy did not improve from 0.67883\n",
      "10/10 [==============================] - 1s 50ms/step - loss: 0.1743 - accuracy: 0.5862 - val_loss: 0.2082 - val_accuracy: 0.3942\n",
      "Epoch 158/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1706 - accuracy: 0.5920\n",
      "Epoch 158: val_accuracy did not improve from 0.67883\n",
      "10/10 [==============================] - 1s 51ms/step - loss: 0.1704 - accuracy: 0.5927 - val_loss: 0.1963 - val_accuracy: 0.4818\n",
      "Epoch 159/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1714 - accuracy: 0.5916\n",
      "Epoch 159: val_accuracy did not improve from 0.67883\n",
      "10/10 [==============================] - 0s 50ms/step - loss: 0.1715 - accuracy: 0.5914 - val_loss: 0.1924 - val_accuracy: 0.5036\n",
      "Epoch 160/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1721 - accuracy: 0.5846\n",
      "Epoch 160: val_accuracy did not improve from 0.67883\n",
      "10/10 [==============================] - 1s 51ms/step - loss: 0.1722 - accuracy: 0.5840 - val_loss: 0.1883 - val_accuracy: 0.5182\n",
      "Epoch 161/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1730 - accuracy: 0.5894\n",
      "Epoch 161: val_accuracy did not improve from 0.67883\n",
      "10/10 [==============================] - 1s 50ms/step - loss: 0.1728 - accuracy: 0.5909 - val_loss: 0.1619 - val_accuracy: 0.6715\n",
      "Epoch 162/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1709 - accuracy: 0.5920\n",
      "Epoch 162: val_accuracy did not improve from 0.67883\n",
      "10/10 [==============================] - 1s 51ms/step - loss: 0.1711 - accuracy: 0.5918 - val_loss: 0.2129 - val_accuracy: 0.5109\n",
      "Epoch 163/500\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1726 - accuracy: 0.5806\n",
      "Epoch 163: val_accuracy did not improve from 0.67883\n",
      "10/10 [==============================] - 1s 51ms/step - loss: 0.1726 - accuracy: 0.5806 - val_loss: 0.1891 - val_accuracy: 0.4818\n",
      "Epoch 164/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1724 - accuracy: 0.5994\n",
      "Epoch 164: val_accuracy did not improve from 0.67883\n",
      "10/10 [==============================] - 1s 50ms/step - loss: 0.1723 - accuracy: 0.5991 - val_loss: 0.2014 - val_accuracy: 0.4964\n",
      "Epoch 165/500\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1753 - accuracy: 0.5849\n",
      "Epoch 165: val_accuracy did not improve from 0.67883\n",
      "10/10 [==============================] - 1s 50ms/step - loss: 0.1753 - accuracy: 0.5849 - val_loss: 0.2118 - val_accuracy: 0.5109\n",
      "Epoch 166/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1713 - accuracy: 0.5972\n",
      "Epoch 166: val_accuracy improved from 0.67883 to 0.70073, saving model to best_model_CNNLSTM.h5\n",
      "10/10 [==============================] - 1s 55ms/step - loss: 0.1712 - accuracy: 0.5978 - val_loss: 0.1638 - val_accuracy: 0.7007\n",
      "Epoch 167/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1712 - accuracy: 0.5946\n",
      "Epoch 167: val_accuracy did not improve from 0.70073\n",
      "10/10 [==============================] - 1s 52ms/step - loss: 0.1714 - accuracy: 0.5940 - val_loss: 0.1888 - val_accuracy: 0.4891\n",
      "Epoch 168/500\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1701 - accuracy: 0.6099\n",
      "Epoch 168: val_accuracy did not improve from 0.70073\n",
      "10/10 [==============================] - 0s 50ms/step - loss: 0.1701 - accuracy: 0.6099 - val_loss: 0.2166 - val_accuracy: 0.3650\n",
      "Epoch 169/500\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1757 - accuracy: 0.5758\n",
      "Epoch 169: val_accuracy did not improve from 0.70073\n",
      "10/10 [==============================] - 1s 50ms/step - loss: 0.1757 - accuracy: 0.5758 - val_loss: 0.1834 - val_accuracy: 0.4307\n",
      "Epoch 170/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1749 - accuracy: 0.5881\n",
      "Epoch 170: val_accuracy did not improve from 0.70073\n",
      "10/10 [==============================] - 1s 53ms/step - loss: 0.1751 - accuracy: 0.5879 - val_loss: 0.2048 - val_accuracy: 0.4380\n",
      "Epoch 171/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1716 - accuracy: 0.5972\n",
      "Epoch 171: val_accuracy did not improve from 0.70073\n",
      "10/10 [==============================] - 1s 53ms/step - loss: 0.1717 - accuracy: 0.5974 - val_loss: 0.2032 - val_accuracy: 0.4234\n",
      "Epoch 172/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1712 - accuracy: 0.5872\n",
      "Epoch 172: val_accuracy did not improve from 0.70073\n",
      "10/10 [==============================] - 1s 52ms/step - loss: 0.1710 - accuracy: 0.5883 - val_loss: 0.1993 - val_accuracy: 0.4015\n",
      "Epoch 173/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1693 - accuracy: 0.5964\n",
      "Epoch 173: val_accuracy did not improve from 0.70073\n",
      "10/10 [==============================] - 1s 50ms/step - loss: 0.1696 - accuracy: 0.5961 - val_loss: 0.1913 - val_accuracy: 0.5182\n",
      "Epoch 174/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1734 - accuracy: 0.5990\n",
      "Epoch 174: val_accuracy did not improve from 0.70073\n",
      "10/10 [==============================] - 1s 51ms/step - loss: 0.1737 - accuracy: 0.5983 - val_loss: 0.1706 - val_accuracy: 0.6277\n",
      "Epoch 175/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1742 - accuracy: 0.5872\n",
      "Epoch 175: val_accuracy did not improve from 0.70073\n",
      "10/10 [==============================] - 1s 51ms/step - loss: 0.1741 - accuracy: 0.5875 - val_loss: 0.2069 - val_accuracy: 0.3650\n",
      "Epoch 176/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1755 - accuracy: 0.5872\n",
      "Epoch 176: val_accuracy did not improve from 0.70073\n",
      "10/10 [==============================] - 1s 52ms/step - loss: 0.1755 - accuracy: 0.5875 - val_loss: 0.2045 - val_accuracy: 0.3577\n",
      "Epoch 177/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1701 - accuracy: 0.6033\n",
      "Epoch 177: val_accuracy did not improve from 0.70073\n",
      "10/10 [==============================] - 1s 52ms/step - loss: 0.1703 - accuracy: 0.6026 - val_loss: 0.2211 - val_accuracy: 0.3066\n",
      "Epoch 178/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1739 - accuracy: 0.5898\n",
      "Epoch 178: val_accuracy did not improve from 0.70073\n",
      "10/10 [==============================] - 1s 52ms/step - loss: 0.1738 - accuracy: 0.5901 - val_loss: 0.1921 - val_accuracy: 0.4234\n",
      "Epoch 179/500\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1727 - accuracy: 0.5780\n",
      "Epoch 179: val_accuracy did not improve from 0.70073\n",
      "10/10 [==============================] - 1s 51ms/step - loss: 0.1727 - accuracy: 0.5780 - val_loss: 0.1962 - val_accuracy: 0.4526\n",
      "Epoch 180/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1702 - accuracy: 0.6007\n",
      "Epoch 180: val_accuracy did not improve from 0.70073\n",
      "10/10 [==============================] - 1s 52ms/step - loss: 0.1702 - accuracy: 0.6009 - val_loss: 0.1900 - val_accuracy: 0.5839\n",
      "Epoch 181/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1716 - accuracy: 0.5877\n",
      "Epoch 181: val_accuracy did not improve from 0.70073\n",
      "10/10 [==============================] - 1s 52ms/step - loss: 0.1718 - accuracy: 0.5875 - val_loss: 0.2285 - val_accuracy: 0.2920\n",
      "Epoch 182/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1715 - accuracy: 0.5946\n",
      "Epoch 182: val_accuracy did not improve from 0.70073\n",
      "10/10 [==============================] - 0s 49ms/step - loss: 0.1715 - accuracy: 0.5944 - val_loss: 0.1944 - val_accuracy: 0.5620\n",
      "Epoch 183/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1713 - accuracy: 0.5968\n",
      "Epoch 183: val_accuracy did not improve from 0.70073\n",
      "10/10 [==============================] - 0s 49ms/step - loss: 0.1715 - accuracy: 0.5957 - val_loss: 0.2416 - val_accuracy: 0.2555\n",
      "Epoch 184/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1710 - accuracy: 0.6011\n",
      "Epoch 184: val_accuracy did not improve from 0.70073\n",
      "10/10 [==============================] - 1s 51ms/step - loss: 0.1713 - accuracy: 0.6004 - val_loss: 0.2057 - val_accuracy: 0.4745\n",
      "Epoch 185/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1730 - accuracy: 0.5872\n",
      "Epoch 185: val_accuracy did not improve from 0.70073\n",
      "10/10 [==============================] - 1s 51ms/step - loss: 0.1727 - accuracy: 0.5883 - val_loss: 0.2144 - val_accuracy: 0.4234\n",
      "Epoch 186/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1705 - accuracy: 0.6011\n",
      "Epoch 186: val_accuracy did not improve from 0.70073\n",
      "10/10 [==============================] - 1s 53ms/step - loss: 0.1710 - accuracy: 0.5996 - val_loss: 0.1983 - val_accuracy: 0.5036\n",
      "Epoch 187/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1737 - accuracy: 0.5768\n",
      "Epoch 187: val_accuracy did not improve from 0.70073\n",
      "10/10 [==============================] - 1s 52ms/step - loss: 0.1738 - accuracy: 0.5767 - val_loss: 0.1924 - val_accuracy: 0.5328\n",
      "Epoch 188/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1713 - accuracy: 0.5951\n",
      "Epoch 188: val_accuracy did not improve from 0.70073\n",
      "10/10 [==============================] - 1s 53ms/step - loss: 0.1714 - accuracy: 0.5948 - val_loss: 0.2220 - val_accuracy: 0.3431\n",
      "Epoch 189/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1692 - accuracy: 0.6033\n",
      "Epoch 189: val_accuracy did not improve from 0.70073\n",
      "10/10 [==============================] - 1s 50ms/step - loss: 0.1692 - accuracy: 0.6030 - val_loss: 0.1731 - val_accuracy: 0.5036\n",
      "Epoch 190/500\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1701 - accuracy: 0.6039\n",
      "Epoch 190: val_accuracy did not improve from 0.70073\n",
      "10/10 [==============================] - 1s 50ms/step - loss: 0.1701 - accuracy: 0.6039 - val_loss: 0.2040 - val_accuracy: 0.4891\n",
      "Epoch 191/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1702 - accuracy: 0.5977\n",
      "Epoch 191: val_accuracy did not improve from 0.70073\n",
      "10/10 [==============================] - 1s 52ms/step - loss: 0.1703 - accuracy: 0.5978 - val_loss: 0.2047 - val_accuracy: 0.4891\n",
      "Epoch 192/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1714 - accuracy: 0.5946\n",
      "Epoch 192: val_accuracy did not improve from 0.70073\n",
      "10/10 [==============================] - 1s 52ms/step - loss: 0.1713 - accuracy: 0.5948 - val_loss: 0.2164 - val_accuracy: 0.4745\n",
      "Epoch 193/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1697 - accuracy: 0.6055\n",
      "Epoch 193: val_accuracy did not improve from 0.70073\n",
      "10/10 [==============================] - 1s 50ms/step - loss: 0.1696 - accuracy: 0.6052 - val_loss: 0.1637 - val_accuracy: 0.6642\n",
      "Epoch 194/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1696 - accuracy: 0.5968\n",
      "Epoch 194: val_accuracy did not improve from 0.70073\n",
      "10/10 [==============================] - 1s 51ms/step - loss: 0.1698 - accuracy: 0.5961 - val_loss: 0.1766 - val_accuracy: 0.5985\n",
      "Epoch 195/500\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1725 - accuracy: 0.5888\n",
      "Epoch 195: val_accuracy did not improve from 0.70073\n",
      "10/10 [==============================] - 0s 49ms/step - loss: 0.1725 - accuracy: 0.5888 - val_loss: 0.1949 - val_accuracy: 0.5474\n",
      "Epoch 196/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1710 - accuracy: 0.6024\n",
      "Epoch 196: val_accuracy did not improve from 0.70073\n",
      "10/10 [==============================] - 1s 51ms/step - loss: 0.1708 - accuracy: 0.6030 - val_loss: 0.2084 - val_accuracy: 0.4161\n",
      "Epoch 197/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1677 - accuracy: 0.5985\n",
      "Epoch 197: val_accuracy did not improve from 0.70073\n",
      "10/10 [==============================] - 1s 51ms/step - loss: 0.1679 - accuracy: 0.5987 - val_loss: 0.1962 - val_accuracy: 0.4234\n",
      "Epoch 198/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1705 - accuracy: 0.5855\n",
      "Epoch 198: val_accuracy did not improve from 0.70073\n",
      "10/10 [==============================] - 1s 53ms/step - loss: 0.1706 - accuracy: 0.5853 - val_loss: 0.1928 - val_accuracy: 0.4453\n",
      "Epoch 199/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1709 - accuracy: 0.5977\n",
      "Epoch 199: val_accuracy did not improve from 0.70073\n",
      "10/10 [==============================] - 1s 51ms/step - loss: 0.1711 - accuracy: 0.5970 - val_loss: 0.2038 - val_accuracy: 0.5036\n",
      "Epoch 200/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1687 - accuracy: 0.6011\n",
      "Epoch 200: val_accuracy did not improve from 0.70073\n",
      "10/10 [==============================] - 1s 52ms/step - loss: 0.1688 - accuracy: 0.6009 - val_loss: 0.1854 - val_accuracy: 0.5474\n",
      "Epoch 201/500\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1721 - accuracy: 0.5851\n",
      "Epoch 201: val_accuracy did not improve from 0.70073\n",
      "10/10 [==============================] - 0s 49ms/step - loss: 0.1722 - accuracy: 0.5853 - val_loss: 0.1990 - val_accuracy: 0.5182\n",
      "Epoch 202/500\n",
      " 1/10 [==>...........................] - ETA: 0s - loss: 0.1627 - accuracy: 0.6172"
     ]
    }
   ],
   "source": [
    "#load data from ../EEG folder, all csv files\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "\n",
    "def get_data():\n",
    "    data = []\n",
    "    scores = []\n",
    "    order = []\n",
    "    filedir = '/mnt/Ryans Study/EEG'\n",
    "    for file in [f for f in os.listdir(filedir) if f.endswith(\".fif\") and not f.endswith(\"resting.fif\")]:\n",
    "        filepath = filedir + \"/\" + file\n",
    "        print(file)\n",
    "        # get number from file name\n",
    "        order.append(int(file.split(\"_\")[0]))\n",
    "        # load raw file\n",
    "        raw = mne.io.read_raw_fif(filepath, preload=True)\n",
    "        # get data\n",
    "        data.append(raw.get_data(picks=['Fp1','Fp2'])[:, 7500:-15000])\n",
    "        # get scores from file names, 1 = watching, 2 = normal, 3 = hard\n",
    "        if \"watching\" in file or \"watch\" in file:\n",
    "            scores.append(0)\n",
    "        elif \"normal\" in file or \"correct\" in file:\n",
    "            scores.append(1)\n",
    "        elif \"hard\" in file:\n",
    "            scores.append(2)\n",
    "\n",
    "    return data, scores, order\n",
    "\n",
    "\n",
    "def remove_participant(data, scores, order, participant):\n",
    "    newdata = []\n",
    "    newscores = []\n",
    "    removed_participant = []\n",
    "    removed_scores = []\n",
    "\n",
    "    for x, y, z in zip(data, scores, order):\n",
    "        if z != participant:\n",
    "            newdata.append(x)\n",
    "            newscores.append(y)\n",
    "        else:\n",
    "            removed_participant.append(x)\n",
    "            removed_scores.append(y)\n",
    "\n",
    "    return np.array(newdata), np.array(newscores), np.array(removed_participant), np.array(removed_scores)\n",
    "\n",
    "\n",
    "def split_timeseries(series, window_size=1000, overlap=100):\n",
    "    segments = []\n",
    "    for i in range(0, series.shape[-1] - window_size + 1, window_size - overlap):\n",
    "        segment = series[..., i:i + window_size]\n",
    "        # add extra dimension for channel\n",
    "        x_max = np.max(segment)\n",
    "        x_avg = np.mean(segment)\n",
    "        segment = (segment - x_avg) / x_max\n",
    "        segment = np.expand_dims(segment, axis=-1)\n",
    "        segments.append(segment)\n",
    "    return segments\n",
    "\n",
    "\n",
    "# split data into 1000 sample sliding window with 100 sample overlap\n",
    "def split_data(data, scores, order, window_size=1000, overlap=100):\n",
    "    X = []\n",
    "    Y = []\n",
    "    neworder = []\n",
    "    for x, y, z in zip(data, scores, order):\n",
    "        x = split_timeseries(x, window_size, overlap)\n",
    "        X.extend(x)\n",
    "        Y.extend([y] * len(x))\n",
    "        neworder.extend([z] * len(x))\n",
    "    return X, Y, neworder\n",
    "\n",
    "\n",
    "def remove_nan(data, scores, order):\n",
    "    # if series contains nan, remove it\n",
    "    newdata = []\n",
    "    newscores = []\n",
    "    neworder = []\n",
    "    for x, y, z in zip(data, scores, order):\n",
    "        if np.isnan(x).any():\n",
    "            continue\n",
    "        else:\n",
    "            newdata.append(x)\n",
    "            newscores.append(y)\n",
    "            neworder.append(z)\n",
    "    return newdata, newscores, neworder\n",
    "\n",
    "\n",
    "# def model\n",
    "def EEGNet_seq(nb_classes, Chans=64, Samples=128,\n",
    "               dropoutRate=0.5, kernLength=64, F1=8,\n",
    "               D=2, F2=16, norm_rate=0.25, dropoutType='Dropout',\n",
    "               learning_rate=3e-3, loss=\"mse\"):\n",
    "    \"\"\"Create a Sequential EEGNet model.\n",
    "\n",
    "      nb_classes      : int, number of classes to classify\n",
    "      Chans, Samples  : number of channels and time points in the EEG data\n",
    "      dropoutRate     : dropout fraction\n",
    "      kernLength      : length of temporal convolution in first layer. We found\n",
    "                        that setting this to be half the sampling rate worked\n",
    "                        well in practice. For the SMR dataset in particular\n",
    "                        since the data was high-passed at 4Hz we used a kernel\n",
    "                        length of 32.\n",
    "      F1, F2          : number of temporal filters (F1) and number of pointwise\n",
    "                        filters (F2) to learn. Default: F1 = 8, F2 = F1 * D.\n",
    "      D               : number of spatial filters to learn within each temporal\n",
    "                        convolution. Default: D = 2\n",
    "      dropoutType     : Either SpatialDropout2D or Dropout, passed as a string.\n",
    "\n",
    "    :param nb_classes: int, number of classes to classify\n",
    "    :param Chans: Number of channels in the EEG data\n",
    "    :param Samples: Number of time poitns in EEG data\n",
    "    :param dropoutRate: dropout fraction\n",
    "    :param kernLength: Length of temporal convolution in first layer\n",
    "    :param F1: Number of temporal features to learn\n",
    "    :param D: Number of spatial filters to learn within each temporal\n",
    "    convolution\n",
    "    :param F2: Number of pointwise filters to learn\n",
    "    :param norm_rate: Normalisation rate\n",
    "    :param dropoutType: Dropout method to use\n",
    "    :param learning_rate: Learning rate of classifier\n",
    "    :param loss: Loss function of classifier\n",
    "    :returns: Keras Sequential model\n",
    "\n",
    "    \"\"\"\n",
    "    from tensorflow.keras.models import Model\n",
    "    from tensorflow.keras.models import Sequential\n",
    "    from tensorflow.keras.layers import Dense, Activation, Dropout\n",
    "    from tensorflow.keras.layers import Conv2D, AveragePooling2D\n",
    "    from tensorflow.keras.layers import SeparableConv2D, DepthwiseConv2D\n",
    "    from tensorflow.keras.layers import BatchNormalization\n",
    "    from tensorflow.keras.layers import SpatialDropout2D\n",
    "    from tensorflow.keras.layers import Input, Flatten\n",
    "    from tensorflow.keras.constraints import max_norm\n",
    "    from tensorflow import keras\n",
    "\n",
    "    if dropoutType == 'SpatialDropout2D':\n",
    "        dropoutType = SpatialDropout2D\n",
    "    elif dropoutType == 'Dropout':\n",
    "        dropoutType = Dropout\n",
    "    else:\n",
    "        raise ValueError('dropoutType must be one of SpatialDropout2D '\n",
    "                         'or Dropout, passed as a string.')\n",
    "\n",
    "    model = Sequential([\n",
    "        # Input(shape = (Chans, Samples, 1)),\n",
    "\n",
    "        # Block 1\n",
    "        Conv2D(F1, (1, kernLength), padding='same',\n",
    "               input_shape=(Chans, Samples, 1),\n",
    "               use_bias=False),\n",
    "        BatchNormalization(),\n",
    "        DepthwiseConv2D((Chans, 1), use_bias=False,\n",
    "                        depth_multiplier=D,\n",
    "                        depthwise_constraint=max_norm(1.)),\n",
    "        BatchNormalization(),\n",
    "        Activation('elu'),\n",
    "        AveragePooling2D((1, 4)),\n",
    "        dropoutType(dropoutRate),\n",
    "\n",
    "        # Block 2\n",
    "        SeparableConv2D(F2, (1, 16), use_bias=False, padding='same'),\n",
    "        BatchNormalization(),\n",
    "        Activation('elu'),\n",
    "        AveragePooling2D((1, 8)),\n",
    "        dropoutType(dropoutRate),\n",
    "\n",
    "        Flatten(name='flatten'),\n",
    "        Dense(nb_classes, name='dense',\n",
    "              kernel_constraint=max_norm(norm_rate)),\n",
    "        Activation('softmax', name='softmax')\n",
    "    ])\n",
    "\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "    model.compile(loss=loss, optimizer=optimizer, metrics=[\"accuracy\"])\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "window_size = 2500\n",
    "channels = 2\n",
    "\n",
    "\n",
    "data, scores, order = get_data();\n",
    "n_participants = len(set(order))\n",
    "data, scores, order = split_data(data, scores, order, window_size=window_size, overlap=100)\n",
    "#data, scores, order = remove_nan(data, scores, order)\n",
    "\n",
    "#scored = scores\n",
    "# one hot encode scores sklearn\n",
    "scores = preprocessing.OneHotEncoder().fit_transform(np.array(scores).reshape(-1, 1))\n",
    "scores = scores.toarray()\n",
    "\n",
    "# use test train split inc order\n",
    "train_data, test_data, train_scores, test_scores, train_order, test_order = train_test_split(data, scores, order,test_size=0.2, random_state=42, shuffle=True)\n",
    "# test data into array\n",
    "test_data = np.array(test_data)\n",
    "#test_scores = test_scores.tolist()\n",
    "history = []\n",
    "\n",
    "# define the checkpoint path and filename\n",
    "checkpoint_path = \"best_model_CNNLSTM.h5\"\n",
    "\n",
    "\n",
    "\n",
    "# leave one out cross validation\n",
    "for i in range(n_participants):\n",
    "    train_datas, train_scoress, val_data, val_scores = remove_participant(train_data, train_scores, train_order, i + 1)\n",
    "    # model\n",
    "    # define model checkpoint callback\n",
    "    checkpoint = ModelCheckpoint(checkpoint_path, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
    "\n",
    "    # define early stopping callback\n",
    "    early_stop = EarlyStopping(monitor='val_accuracy', patience=50, mode='max')\n",
    "\n",
    "    models = EEGNet_seq(nb_classes=3, Chans=channels, Samples=window_size, dropoutRate=0.5, kernLength=64, F1=8, D=2, F2=16, norm_rate=0.25, dropoutType='Dropout', learning_rate=3e-3, loss=\"mse\")\n",
    "    hist = models.fit(train_datas, train_scoress, epochs=500, batch_size=256, validation_data=(val_data, val_scores),callbacks=[early_stop, checkpoint])\n",
    "    hist = load_model(checkpoint_path)\n",
    "    history.append(hist);\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 1: 0.433\n",
      "Model 2: 0.508\n",
      "Model 3: 0.552\n",
      "Model 4: 0.544\n",
      "Model 5: 0.350\n",
      "Model 6: 0.520\n",
      "Model 7: 0.534\n",
      "Model 8: 0.471\n",
      "Model 9: 0.537\n",
      "Model 10: 0.536\n",
      "Model 11: 0.500\n",
      "Model 12: 0.518\n",
      "Model 13: 0.565\n",
      "Model 14: 0.500\n",
      "Model 15: 0.510\n",
      "Model 16: 0.570\n",
      "Model 17: 0.420\n",
      "Model 18: 0.349\n"
     ]
    }
   ],
   "source": [
    "# evaluate all models on test set and save best model\n",
    "best_model = None\n",
    "best_acc = 0\n",
    "# change test_scores to list instead of array\n",
    "# set no logging\n",
    "tf.get_logger().setLevel(3)\n",
    "\n",
    "for i, model in enumerate(history):\n",
    "    # evaluate model on test set\n",
    "    _, acc = model.evaluate(test_data, test_scores, verbose=0)\n",
    "    print('Model %d: %.3f' % (i + 1, acc))\n",
    "    # check if best model\n",
    "    if acc > best_acc:\n",
    "        best_acc = acc\n",
    "        best_model = model\n",
    "\n",
    "# save best model\n",
    "best_model.save(\"best_model_CNNBILSTM.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Model Accuracy: 0.570\n",
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model to work.\n",
      "20/20 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 1000x1000 with 2 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# import plot_model, confusion_matrix, plt, sns\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# print best model accuracy\n",
    "print('Best Model Accuracy: %.3f' % best_acc)\n",
    "\n",
    "\n",
    "# plot best model\n",
    "plot_model(best_model, to_file='best_model_CNNBILSTM_binary.png', show_shapes=True, show_layer_names=True)\n",
    "# confusion matrix\n",
    "y_pred = best_model.predict(test_data)\n",
    "y_pred = np.argmax(y_pred, axis=1)\n",
    "y_true = np.argmax(test_scores, axis=1)\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "# plot confusion matrix\n",
    "plt.figure(figsize=(10, 10))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\")\n",
    "plt.title(\"Confusion matrix\")\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "vscode": {
   "interpreter": {
    "hash": "50a23ccb2a46e4f3c10b656e01e221a451ca18d9a0bb1860468c4ede0c087d11"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
